{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', size=18,family='serif')\n",
    "import matplotlib.gridspec as gridspec\n",
    "from emcee import EnsembleSampler\n",
    "from emcee.backends import HDFBackend\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from corner import corner\n",
    "from Cosmology import *\n",
    "import sys\n",
    "\n",
    "\n",
    "#load autoreload, which automatically reloads the cosmology.py upon execution\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport Cosmology\n",
    "\n",
    "\n",
    "#Parameters for BAO -- CHECK THESE VALUES\n",
    "z_d = 1089\n",
    "h = .6727\n",
    "cLight=3E5\n",
    "omega_baryon_preset = 0.02236/h**2\n",
    "omega_gamma_preset = 2.469E-5/h**2\n",
    "\n",
    "#Cosmological parameters\n",
    "Omega_m_preset = 0.3166\n",
    "Omega_r_preset = 2.469E-5/h**2 # this is the photon density\n",
    "Omega_c_preset = 0.6834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check versions of packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda list matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda list ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supernova data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSN = np.loadtxt('data/jla_lcparams.txt', usecols=(2,4,6,8,10))\n",
    "errSN = np.loadtxt('data/jla_lcparams.txt', usecols=(5,7,9))[np.argsort(dataSN.T[0])]\n",
    "dataSN = dataSN[np.argsort(dataSN.T[0])]\n",
    "\n",
    "#best fit values found in JLA analysis arXiv:1401.4064\n",
    "a = 0.14\n",
    "b = 3.14\n",
    "MB = -19.04\n",
    "delta_Mhost = -.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNdata = Supernova_data(dataSN, errSN, np.array([a,b,MB, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quasar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataQ = np.loadtxt('data/quasar_data_RL.txt', usecols=(0,1,2,3,4))\n",
    "errQ = np.loadtxt('data/quasar_data_RL.txt', usecols=5)[np.argsort(dataQ.T[0])]\n",
    "dataQ = dataQ[np.argsort(dataQ.T[0])]\n",
    "\n",
    "#best fit values found in Risaliti & Lusso, Nature Astronomy, 2018\n",
    "beta_prime, s = 7.4, 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qdata = Quasar_data(dataQ, errQ, np.array([beta_prime, s]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load BOSS data points\n",
    "dataBAO = np.loadtxt('data/BOSS.txt', usecols=(1,3))\n",
    "#load BOSS errors & measurement quantity\n",
    "errBAO  = np.diag(np.loadtxt('data/BOSS.txt', usecols=4))\n",
    "typeBAO = np.genfromtxt('data/BOSS.txt',dtype=str, usecols=2)\n",
    "\n",
    "#BOSS DR12 covariance matrix from 1607.03155\n",
    "sigmaDR12 = np.diag(np.diag(errBAO)[np.where(np.loadtxt('data/BOSS.txt', usecols=0, dtype=str) == 'BOSS_DR12')])\n",
    "corrDR12 = np.tril(np.loadtxt('data/BOSS_DR12_cov.txt', usecols=(1,2,3,4,5,6))*1E-4)\n",
    "corrDR12 += corrDR12.T\n",
    "corrDR12 /= 2\n",
    "CovDR12 = np.dot(sigmaDR12, np.dot(corrDR12, sigmaDR12))\n",
    "\n",
    "#eBOSS Quasar covariance matrix from 1801.03043\n",
    "sigmaeBOSS = np.diag(np.diag(errBAO)[np.where(np.loadtxt('data/BOSS.txt', usecols=0, dtype=str) == 'eBOSS_QSO')])\n",
    "correBOSS = np.triu(np.loadtxt('data/eBOSS_QSO_cov.txt', usecols=(1,2,3,4,5,6,7,8))*1E-4)\n",
    "correBOSS += correBOSS.T\n",
    "correBOSS /= 2\n",
    "CoveBOSS = np.dot(sigmaeBOSS, np.dot(correBOSS, sigmaeBOSS))\n",
    "\n",
    "#assemble the full covariance matrix\n",
    "load_cov = np.diag([1 if i else 0 for i in np.loadtxt('data/BOSS.txt',usecols=5)==1]) \n",
    "CovBAO = (errBAO - np.dot(load_cov,errBAO))**2\n",
    "CovBAO += np.pad(CovDR12,[(2,len(errBAO)-2-len(CovDR12)),(2,len(errBAO)-2-len(CovDR12))], mode='constant', constant_values=0)\n",
    "CovBAO += np.pad(CoveBOSS,[(2 + len(CovDR12) + 1,len(errBAO)- 3 - len(CovDR12) - len(CoveBOSS)),(2 + len(CovDR12) + 1,len(errBAO)- 3 - len(CovDR12) - len(CoveBOSS))], mode='constant', constant_values=0)\n",
    "\n",
    "#Finally, add the correlations given in 1904.03430 \n",
    "add_cov = np.array([i if i<0 else 0 for i in np.loadtxt('data/BOSS.txt',usecols=5)])\n",
    "Cov = np.pad(np.diag(add_cov[1:]), [(1,0),(0,1)], mode='constant', constant_values=0) + np.pad(np.diag(add_cov[1:]), [(0,1), (1,0)], mode='constant', constant_values=0)\n",
    "for ind in np.array([np.where(add_cov<0)[0]-1., np.where(add_cov<0)[0]], dtype=int).T:\n",
    "    Cov[ind] = Cov[ind] * np.diag(errBAO)[ind[0]] * np.diag(errBAO)[ind[1]]\n",
    "    \n",
    "CovBAO += Cov\n",
    "\n",
    "BAOdata = BAO_data(dataBAO, CovBAO, typeBAO)\n",
    "LCDM = cosmology(Omega_m_preset, Omega_c_preset, omegab=omega_baryon_preset, omegar=omega_gamma_preset, w=-1, Hzero=100.*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load all data points except for WiggleZ\n",
    "# dataBAO = np.loadtxt('data/BOSS.txt', usecols=(1,3))\n",
    "# # dataBAO = np.loadtxt('data/bao_1806-06781.txt', usecols=(1,3))\n",
    "# # add WiggleZ\n",
    "# dataBAO = np.append(dataBAO, np.loadtxt('data/WiggleZ.txt', usecols=(1,3)), axis=0)\n",
    "\n",
    "# # the error for BAO is a cov mat, due to the addition of the WiggleZ data.\n",
    "# errBAO  = np.pad(np.diag(np.loadtxt('data/BOSS.txt', usecols=4)), [(0, 3), (0, 3)], mode='constant', constant_values=0)\n",
    "# # errBAO  = np.pad(np.diag(np.loadtxt('data/bao_1806-06781.txt', usecols=4)), [(0, 3), (0, 3)], mode='constant', constant_values=0)\n",
    "\n",
    "# # now add the WiggleZ cov mat. Note that this is the sqrt, as all the other errors are given in this format, too.\n",
    "# errBAO += np.pad(np.sqrt(np.loadtxt('data/WiggleZ_cov.txt', usecols=(3,4,5))), [(len(errBAO)-3, 0), (len(errBAO)-3, 0)], mode='constant', constant_values=0)\n",
    "\n",
    "# typeBAO = np.genfromtxt('data/BOSS.txt',dtype=str, usecols=2)\n",
    "# # typeBAO = np.genfromtxt('data/bao_1806-06781.txt',dtype=str, usecols=2)\n",
    "# typeBAO = np.append(typeBAO, np.genfromtxt('data/WiggleZ.txt',dtype=str, usecols=2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAOdata = BAO_data(dataBAO,errBAO**2, np.array([omega_baryon_preset, omega_gamma_preset]), typeBAO)\n",
    "# LCDM = cosmology(Omega_m_preset, Omega_c_preset, w=-1, Hzero=69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma00, kappa0 = 0.0093, 95\n",
    "RCdata = RC_data([gamma00, kappa0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planck 2018 CMB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMBdata = CMB_data('Planck18')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 0: $\\Lambda$LCDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which data sets to include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_LCDM_min=[0, 0, 60., -5, -10, -30, -.5, 0, 0]\n",
    "ranges_LCDM_max=[1, 0.1, 80., 5, 10, -10, .5, 10, 3]\n",
    "def lnprob_LCDM(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_LCDM_min, ranges_LCDM_max, model = 'LCDM')\n",
    "    return l.logprobability_gauss_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_LCDM = [Omega_m_preset, omega_baryon_preset, 67.27, a, b, MB, -0.05, beta_prime, s]\n",
    "\n",
    "# calculates the BIC for LCDM: in this case, we compare to the preset values. The BIC is a function of the data set:\n",
    "BIC_LCDM = lambda theta, data_sets_var: np.log(sum([len(d.get_data()) for d in data_sets_var])) * len(theta) -2*lnprob_LCDM(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = 9, 512, 500\n",
    "pos0 = np.random.uniform(ranges_LCDM_min, ranges_LCDM_max, (nwalkers,len(ranges_LCDM_max)))\n",
    "\n",
    "# pool = Pool(cpu_count())\n",
    "# write = HDFBackend('chains/LCDM_' + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "# sampler = EnsembleSampler(nwalkers, ndim, lnprob_LCDM, pool=pool)#, backend=write)\n",
    "\n",
    "# sampler.run_mcmc(pos0, nsteps, progress=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCDM_sampler = HDFBackend('chains/LCDM' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "# LCDM_sampler = sampler\n",
    "\n",
    "nsteps, nwalkers, ndim = LCDM_sampler.get_chain().shape\n",
    "\n",
    "labs = [r'$\\Omega_m$', r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$\\alpha$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "while Nmin < nsteps and np.all(LCDM_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCDM_samples = LCDM_sampler.get_chain()\n",
    "\n",
    "f, ax = plt.subplots(len(LCDM_samples.T), 1, figsize=(6,3*len(LCDM_samples.T)))\n",
    "\n",
    "for i in range(len(LCDM_samples.T)):\n",
    "    ax[i].plot(LCDM_samples.T[i].T, lw=0.5)\n",
    "    ax[i].plot([Nmin, Nmin], [min(LCDM_samples.T[i].flatten()), max(LCDM_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "    ax[i].text(Nmin, min(LCDM_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/convergence_LCDM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete walkers which haven't moved from initial position:\n",
    "\n",
    "dellist = np.unique(np.where(np.isclose(LCDM_samples[-1] - LCDM_samples[0], 0))[0])\n",
    "\n",
    "LCDM_samples = np.delete(LCDM_samples, np.unique(dellist), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCDM_samples = LCDM_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "meanLCDM = np.mean(LCDM_samples, axis=0)\n",
    "stdLCDM = np.var(LCDM_samples, axis=0)\n",
    "maxLCDM=[]\n",
    "for i in range(len(meanLCDM)):\n",
    "    like = np.histogram(LCDM_samples.T[i], bins=1000)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxLCDM.append(max_val)\n",
    "\n",
    "# LCDM_samples[:,0] = LCDM_samples[:,0] * LCDM_samples[:,2]**2 / 100**2\n",
    "# LCDM_samples[:,1] = LCDM_samples[:,1] * LCDM_samples[:,2]**2 / 100**2\n",
    "\n",
    "\n",
    "fig = corner(LCDM_samples[:,:3], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),# range=[(0,0.8),(0.01,0.08), (60,80)],\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=20, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "#              truths=maxLCDM)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_LCDM' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(LCDM_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "omegam, stdmp, stdmm = v[0]\n",
    "\n",
    "omegab, stdbp, stdbm = v[1]\n",
    "H0, stdhp, stdhm = v[2]\n",
    "    \n",
    "    \n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "best_fit_cosmo_LCDM = cosmology(omegam=maxLCDM[0],omegac=1-maxLCDM[0], omegab = maxLCDM[1], omegar=omega_gamma_preset, Hzero=maxLCDM[2])\n",
    "SNdata.set_param(v.T[0][-6:-2])\n",
    "Qdata.set_param(v.T[0][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_lcdm = BIC_LCDM(v.T[0],data_sets)\n",
    "\n",
    "print('BIC(LCDM) = ' + str(bic_lcdm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "\n",
    "if 'BAO'  in data_set_names or 'CMB' in data_set_names:    \n",
    "    ax1.set_title(r'$\\Omega_m = {%1.3f}^{+%1.3f}_{-%1.3f},\\, H_0 = {%1.1f}^{+%1.1f}_{-%1.1f}\\,\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}$' % (omegam, stdmp,stdmm, H0, stdhm, stdhp))\n",
    "else:\n",
    "    ax1.set_title(r'$\\Omega_m = {%1.3f}^{+%1.3f}_{-%1.3f}$' % (omegam, stdmp,stdmm))\n",
    "    \n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=0, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(best_fit_cosmo_LCDM).T[0], BAOdata.distance_modulus(best_fit_cosmo_LCDM).T[1], yerr=BAOdata.delta_distance_modulus(best_fit_cosmo_LCDM), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_cosmo_LCDM.distance_modulus(zPlot), c='k', label=r'best fit')\n",
    "ax1.fill_between(zPlot, cosmology(omegam+stdmp,1-omegam-stdmp, omegab=omegab+stdbp, Hzero=H0+stdhp).distance_modulus(zPlot), cosmology(omegam-stdmm,1-omegam+stdmm, omegab=omegab-stdbm, Hzero=H0-stdhm).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset, Hzero=100*h).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_cosmo_LCDM.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .06, r'$\\mathrm{BIC}(\\Lambda\\mathrm{CDM}) = %1.0f$' % (BIC_LCDM(v.T[0],data_sets)), ha='right', va='bottom', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/Hubble_LCDM' + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCDM_chains = {}\n",
    "LCDM_chains['SN'] = HDFBackend('chains/LCDM_SN_512x1000.h5')\n",
    "LCDM_chains['SN_Q'] = HDFBackend('chains/LCDM_SN_Quasars_512x1000.h5')\n",
    "LCDM_chains['SN_Q_BAO'] = HDFBackend('chains/LCDM_SN_Quasars_BAO_512x1000.h5')\n",
    "LCDM_chains['SN_BAO_CMB'] = HDFBackend('chains/LCDM_SN_CMB_512x1000.h5')\n",
    "LCDM_chains['SN_Q_BAO_CMB'] = HDFBackend('chains/LCDM_SN_Quasars_BAO_CMB_512x1000.h5')\n",
    "LCDM_chains['BAO'] = HDFBackend('chains/LCDM_BAO_512x1000.h5')\n",
    "LCDM_chains['CMB'] = HDFBackend('chains/LCDM_CMB_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_combinations = ['SN','SN_Q','SN_Q_BAO','SN_BAO_CMB','SN_Q_BAO_CMB','BAO','CMB']\n",
    "data_set_combin_obs = {}\n",
    "data_set_combin_obs['SN'] = [SNdata]\n",
    "data_set_combin_obs['SN_Q'] = [SNdata,Qdata]\n",
    "data_set_combin_obs['SN_Q_BAO'] = [SNdata,Qdata,BAOdata]\n",
    "data_set_combin_obs['SN_BAO_CMB'] = [SNdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['SN_Q_BAO_CMB'] = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['BAO'] = [BAOdata]\n",
    "data_set_combin_obs['CMB'] = [CMBdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_lcdmlist = {}\n",
    "\n",
    "for set_name in data_set_combinations:\n",
    "    sample = LCDM_chains[set_name].get_chain()\n",
    "    Nmin = 300\n",
    "    while Nmin < nsteps and np.all(LCDM_chains[set_name].get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "    dellist = np.unique(np.where(np.isclose(sample[-1] - sample[0], 0))[0])\n",
    "    sample = np.delete(sample, np.unique(dellist), axis=1)[Nmin:, :].reshape((-1, ndim))\n",
    "    \n",
    "    data_sets = data_set_combin_obs[set_name]\n",
    "    \n",
    "    vtemp = np.percentile(sample,[16, 50, 84], axis = 0)\n",
    "    vtemp = np.asarray([vtemp[1], vtemp[2]-vtemp[1],vtemp[1]-vtemp[0]]).T\n",
    "    \n",
    "    bic_lcdmlist[set_name] = BIC_LCDM(vtemp.T[0], data_set_combin_obs[set_name])\n",
    "    \n",
    "    print(set_name + ':')\n",
    "    print('   Om_m:' + str(np.round(vtemp[0],4)))\n",
    "    print('   Om_b:' + str(np.round(vtemp[1],4)*100))\n",
    "    print('   H0:  ' + str(np.round(vtemp[2],2)))\n",
    "    print('   BIC: ' + str(np.round(bic_lcdmlist[set_name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "for sampler in LCDM_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print('Nmin=',Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_LCDM_min=[0, 0, 60., -5, -10, -30, -.5, 0, 0]\n",
    "ranges_LCDM_max=[1, 0.1, 80., 5, 10, -10, .5, 10, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = LCDM_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['SN'])),:].reshape((-1, LCDM_chains['SN'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:3], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "            range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "samples = LCDM_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['SN_Q'])),:].reshape((-1, LCDM_chains['SN_Q'].get_chain().shape[-1]))\n",
    "corner(samples[:,:3], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='blue', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "samples = LCDM_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['BAO'])),:].reshape((-1, LCDM_chains['BAO'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:3], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "samples = LCDM_chains['CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['CMB'])),:].reshape((-1, LCDM_chains['CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:3], levels=(1-np.exp( -0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange'], alpha=0.4),\n",
    "            fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "samples = LCDM_chains['SN_Q_BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['SN_Q_BAO_CMB'])),:].reshape((-1, LCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:3], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='cyan', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "\n",
    "# samples = LCDM_chains['SN_BAO_CMB'].get_chain()[Nmin:,:].reshape((-1, LCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "# corner(samples[:,:3], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='k', \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgray', 'gray'], alpha=0.4),\n",
    "#             fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_LCDM.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LCDM, we also generate the full posterior distribution plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = LCDM_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['SN'])),:].reshape((-1, LCDM_chains['SN'].get_chain().shape[-1]))\n",
    "fig=corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "            range=[(0.15,.5), (0.03,0.07), (62,75), (0,0.3), (0,5), (-22,-18), (-1,1) ,(5,10), (1,2)])\n",
    "\n",
    "samples = LCDM_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['SN_Q'])),:].reshape((-1, LCDM_chains['SN_Q'].get_chain().shape[-1]))\n",
    "corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='blue', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75), (0,0.3), (0,5), (-22,-18), (-1,1) ,(5,10), (1,2)])\n",
    "\n",
    "samples = LCDM_chains['SN_Q_BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['SN_Q_BAO_CMB'])),:].reshape((-1, LCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples, levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='cyan', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75), (0,0.3), (0,5), (-22,-18), (-1,1) ,(5,10), (1,2)])\n",
    "\n",
    "\n",
    "# samples = LCDM_chains['SN_BAO_CMB'].get_chain()[Nmin:,:].reshape((-1, LCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "# corner(samples[:,:3], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='k', \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgray', 'gray'], alpha=0.4),\n",
    "#             fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "#plt.tick_params(axis='both', which='minor', labelsize=8)\n",
    "\n",
    "\n",
    "plt.savefig('plots/posterior_LCDM_full.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: o$\\Lambda$LCDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which data sets to include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_oLCDM_min=[0, 0, 0, 60., -5, -10, -30, -.5, 0, 0]\n",
    "ranges_oLCDM_max=[1, 1.5, .1, 80., 5, 10, -10, .5, 10, 3]\n",
    "def lnprob_oLCDM(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_oLCDM_min, ranges_oLCDM_max, model = 'oLCDM')\n",
    "    return l.logprobability_flat_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_oLCDM = [Omega_m_preset, Omega_c_preset, omega_baryon_preset, 67.27, a, b, MB, -0.05, beta_prime, s]\n",
    "\n",
    "BIC_oLCDM = lambda theta, data_sets_var: np.log(sum([len(d.get_data()) for d in data_sets_var])) * len(theta) -2*lnprob_oLCDM(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = 10, 50, 100\n",
    "pos0 = np.random.uniform(ranges_oLCDM_min, ranges_oLCDM_max, (nwalkers,len(ranges_oLCDM_max)))\n",
    "\n",
    "# pool = Pool(cpu_count())\n",
    "# write = HDFBackend('chains/LCDM_' + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "# sampler = EnsembleSampler(nwalkers, ndim, lnprob_LCDM, pool=pool)#, backend=write)\n",
    "\n",
    "# sampler.run_mcmc(pos0, nsteps, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oLCDM_sampler = HDFBackend('chains/oLCDM' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "# oLCDM_sampler = sampler\n",
    "\n",
    "nsteps, nwalkers, ndim = oLCDM_sampler.get_chain().shape\n",
    "\n",
    "labs = [r'$\\Omega_m$', r'$\\Omega_\\Lambda$', r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$\\alpha$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "while Nmin < nsteps and np.all(oLCDM_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oLCDM_samples = oLCDM_sampler.get_chain()\n",
    "\n",
    "f, ax = plt.subplots(len(oLCDM_samples.T), 1, figsize=(6,3*len(oLCDM_samples.T)))\n",
    "\n",
    "for i in range(len(oLCDM_samples.T)):\n",
    "    ax[i].plot(oLCDM_samples.T[i].T, lw=0.5)\n",
    "    ax[i].plot([Nmin, Nmin], [min(oLCDM_samples.T[i].flatten()), max(oLCDM_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "    ax[i].text(Nmin, min(oLCDM_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/convergence_oLCDM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dellist = np.unique(np.where(np.isclose(oLCDM_samples[-1] - oLCDM_samples[0], 0))[0])\n",
    "\n",
    "oLCDM_samples = np.delete(oLCDM_samples, np.unique(dellist), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oLCDM_samples = oLCDM_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "meanoLCDM = np.mean(oLCDM_samples, axis=0)\n",
    "stdoLCDM = np.var(oLCDM_samples, axis=0)\n",
    "maxoLCDM=[]\n",
    "for i in range(len(meanoLCDM)):\n",
    "    like = np.histogram(oLCDM_samples.T[i], bins=500)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxoLCDM.append(max_val)\n",
    "\n",
    "fig = corner(oLCDM_samples[:,:4], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),# range=[(0,0.8),(0,1),(0,.1), (60,75)],\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "#              truths=maxoLCDM)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_oLCDM' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(oLCDM_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "omegam, stdmp, stdmm = v[0]\n",
    "omegac, stdcp, stdcm = v[1]\n",
    "\n",
    "omegab, stdbp, stdbm = v[2]\n",
    "H0, stdhp, stdhm = v[3]\n",
    "    \n",
    "    \n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "best_fit_cosmo_oLCDM = cosmology(*maxoLCDM[:2], omegab = maxoLCDM[2], Hzero=maxoLCDM[3])\n",
    "SNdata.set_param(v.T[0][4:8])\n",
    "Qdata.set_param(v.T[0][8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[0],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[1],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[2],5)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[3],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_olcdm = BIC_oLCDM(v.T[0],data_sets)\n",
    "\n",
    "print('BIC(oLCDM) = ' + str(bic_olcdm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_olcdm-bic_lcdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "\n",
    "if 'BAO'  in data_set_names or 'CMB' in data_set_names:    \n",
    "    ax1.set_title(r'$\\Omega_m = {%1.2f}^{+%1.2f}_{-%1.2f},\\, \\Omega_\\Lambda = {%1.2f}^{+%1.2f}_{-%1.2f},\\, H_0 = {%1.1f}^{+%1.1f}_{-%1.1f} \\,\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}$' % (omegam, stdmp,stdmm, omegac, stdcp, stdcm, H0, stdhm, stdhp))\n",
    "else:\n",
    "    ax1.set_title(r'$\\Omega_m = {%1.2f}^{+%1.2f}_{-%1.2f},\\, \\Omega_\\Lambda = {%1.2f}^{+%1.2f}_{-%1.2f}$' % (omegam, stdmp,stdmm, omegac, stdcp, stdcm))\n",
    "\n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=0, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(best_fit_cosmo_oLCDM).T[0], BAOdata.distance_modulus(best_fit_cosmo_oLCDM).T[1], yerr=BAOdata.delta_distance_modulus(best_fit_cosmo_oLCDM), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_cosmo_oLCDM.distance_modulus(zPlot), c='k', label=r'best fit')\n",
    "ax1.fill_between(zPlot, cosmology(omegam+stdmp,omegac+stdcp, omegab=omegab+stdbp, Hzero=H0+stdhp).distance_modulus(zPlot), cosmology(omegam-stdmm,omegac-stdcm, omegab=omegab-stdbm, Hzero=H0-stdhm).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_cosmo_oLCDM.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .06, r'$\\Delta \\mathrm{BIC}(o\\Lambda\\mathrm{CDM}) = %1.0f$' % (BIC_oLCDM(v.T[0],data_sets) - bic_lcdm), ha='right', va='bottom', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/Hubble_oLCDM' + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oLCDM_chains = {}\n",
    "oLCDM_chains['SN'] = HDFBackend('chains/oLCDM_SN_512x1000.h5')\n",
    "oLCDM_chains['SN_Q'] = HDFBackend('chains/oLCDM_SN_Quasars_512x1000.h5')\n",
    "oLCDM_chains['SN_Q_BAO'] = HDFBackend('chains/oLCDM_SN_Quasars_BAO_512x1000.h5')\n",
    "oLCDM_chains['SN_BAO_CMB'] = HDFBackend('chains/oLCDM_SN_BAO_CMB_512x1000.h5')\n",
    "oLCDM_chains['SN_Q_BAO_CMB'] = HDFBackend('chains/oLCDM_SN_Quasars_BAO_CMB_512x1000.h5')\n",
    "oLCDM_chains['BAO'] = HDFBackend('chains/oLCDM_BAO_512x1000.h5')\n",
    "oLCDM_chains['CMB'] = HDFBackend('chains/oLCDM_CMB_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_combinations = ['SN','SN_Q','SN_Q_BAO','SN_BAO_CMB','SN_Q_BAO_CMB','BAO','CMB']\n",
    "data_set_combin_obs = {}\n",
    "data_set_combin_obs['SN'] = [SNdata]\n",
    "data_set_combin_obs['SN_Q'] = [SNdata,Qdata]\n",
    "data_set_combin_obs['SN_Q_BAO'] = [SNdata,Qdata,BAOdata]\n",
    "data_set_combin_obs['SN_BAO_CMB'] = [SNdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['SN_Q_BAO_CMB'] = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['BAO'] = [BAOdata]\n",
    "data_set_combin_obs['CMB'] = [CMBdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_name in data_set_combinations:\n",
    "    sample = oLCDM_chains[set_name].get_chain()\n",
    "    Nmin = 300\n",
    "    while Nmin < nsteps and np.all(oLCDM_chains[set_name].get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "    dellist = np.unique(np.where(np.isclose(sample[-1] - sample[0], 0))[0])\n",
    "    sample = np.delete(sample, np.unique(dellist), axis=1)[Nmin:, :].reshape((-1, ndim))\n",
    "    \n",
    "    data_sets = data_set_combin_obs[set_name]\n",
    "    \n",
    "    vtemp = np.percentile(sample,[16, 50, 84], axis = 0)\n",
    "    vtemp = np.asarray([vtemp[1], vtemp[2]-vtemp[1],vtemp[1]-vtemp[0]]).T\n",
    "    print(set_name + ':')\n",
    "    print('   Om_m:' + str(np.round(vtemp[0],4)))\n",
    "    print('   Om_c:' + str(np.round(vtemp[1],4)))\n",
    "    print('   Om_b:' + str(np.round(vtemp[2],5)*100))\n",
    "    print('   H0:  ' + str(np.round(vtemp[3],2)))\n",
    "    print('   dBIC:' + str(np.round(BIC_oLCDM(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "for sampler in oLCDM_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print('Nmin=',Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = oLCDM_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(oLCDM_chains['SN'])),:].reshape((-1, oLCDM_chains['SN'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:4], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "            range=[(0,.6), (0,1.25), (0.03,0.07), (62,75)])\n",
    "\n",
    "samples = oLCDM_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(oLCDM_chains['SN_Q'])),:].reshape((-1, oLCDM_chains['SN_Q'].get_chain().shape[-1]))\n",
    "corner(samples[:,:4], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='blue', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            fig=fig, range=[(0,.6), (0,1.25), (0.03,0.07), (62,75)])\n",
    "\n",
    "samples = oLCDM_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(oLCDM_chains['BAO'])),:].reshape((-1, oLCDM_chains['BAO'].get_chain().shape[-1]))\n",
    "corner(samples[:,:4], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            fig=fig, range=[(0,.6), (0,1.25), (0.03,0.07), (62,75)])\n",
    "\n",
    "samples = oLCDM_chains['CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(oLCDM_chains['CMB'])),:].reshape((-1, oLCDM_chains['CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:4], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange'], alpha=0.4),\n",
    "            fig=fig, range=[(0,.6), (0,1.25), (0.03,0.07), (62,75)])\n",
    "\n",
    "samples = oLCDM_chains['SN_Q_BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(oLCDM_chains['SN_Q_BAO_CMB'])),:].reshape((-1, oLCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:4], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='cyan', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            fig=fig, range=[(0,.6), (0,1.25), (0.03,0.07), (62,75)])\n",
    "\n",
    "\n",
    "# samples = oLCDM_chains['SN_BAO_CMB'].get_chain()[Nmin:,:].reshape((-1, oLCDM_chains['SN_BAO_CMB'].get_chain().shape[-1]))\n",
    "# corner(samples[:,:4], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='k', \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgray', 'gray'], alpha=0.4),\n",
    "#             fig=fig, range=[(0,.6), (0,1.25), (0.03,0.07), (62,75)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_oLCDM.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: $w\\Lambda$LCDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which data sets to include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [SNdata, Qdata, BAOdata, CMBdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_wLCDM_min=[0, 0, 0, 60., -2.5, -5, -10, -30, -.5, 0, 0]\n",
    "ranges_wLCDM_max=[1, 1.5, 0.1, 80., -1/3., 5, 10, -10, .5, 10, 3]\n",
    "def lnprob_wLCDM(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_wLCDM_min, ranges_wLCDM_max, model = 'wLCDM')\n",
    "    return l.logprobability_gauss_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_wLCDM = lambda theta, data_sets_var: np.log(sum([len(d.get_data()) for d in data_sets_var])) * len(theta) -2*lnprob_wLCDM(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = 10, 20, 100\n",
    "pos0 = np.random.uniform(ranges_wLCDM_min, ranges_wLCDM_max, (nwalkers,len(ranges_wLCDM_max)))\n",
    "\n",
    "# pool = Pool(cpu_count())\n",
    "# write = HDFBackend('chains/LCDM_' + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "# sampler = EnsembleSampler(nwalkers, ndim, lnprob_wLCDM, pool=pool)#, backend=write)\n",
    "# \n",
    "# sampler.run_mcmc();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wLCDM_sampler = HDFBackend('chains/wLCDM' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "#LCDM_sampler = sampler\n",
    "\n",
    "nsteps, nwalkers, ndim = wLCDM_sampler.get_chain().shape\n",
    "\n",
    "labs = [r'$\\Omega_m$', r'$\\Omega_\\Lambda$', r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$w$', r'$\\alpha$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "while Nmin < nsteps and np.all(wLCDM_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wLCDM_samples = wLCDM_sampler.get_chain()\n",
    "\n",
    "f, ax = plt.subplots(len(wLCDM_samples.T), 1, figsize=(6,3*len(wLCDM_samples.T)))\n",
    "\n",
    "for i in range(len(wLCDM_samples.T)):\n",
    "    ax[i].plot(wLCDM_samples.T[i].T, lw=0.5)\n",
    "    ax[i].plot([Nmin, Nmin], [min(wLCDM_samples.T[i].flatten()), max(wLCDM_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "    ax[i].text(Nmin, min(wLCDM_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/convergence_wLCDM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wLCDM_samples = wLCDM_samples.get_chain()\n",
    "\n",
    "dellist = np.unique(np.where(np.isclose(wLCDM_samples[-1] - wLCDM_samples[0], 0))[0])\n",
    "\n",
    "wLCDM_samples = np.delete(wLCDM_samples, np.unique(dellist), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wLCDM_samples = wLCDM_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "meanwLCDM = np.mean(wLCDM_samples, axis=0)\n",
    "stdwLCDM = np.var(wLCDM_samples, axis=0)\n",
    "maxwLCDM=[]\n",
    "for i in range(len(meanwLCDM)):\n",
    "    like = np.histogram(wLCDM_samples.T[i], bins=50)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxwLCDM.append(max_val)\n",
    "\n",
    "fig = corner(wLCDM_samples[:,:5], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=30, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "# #              truths=maxwLCDM)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_wLCDM' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(wLCDM_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "omegam, stdmp, stdmm = v[0]\n",
    "omegac, stdcp, stdcm = v[1]\n",
    "omegab, stdbp, stdbm = v[2]\n",
    "H0, stdhp, stdhm = v[3]\n",
    "w, wp, wm = v[4]\n",
    "\n",
    "\n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "# omegam, omegac, w = maxwLCDM[0], maxwLCDM[1], maxwLCDM[2]\n",
    "best_fit_cosmo_wLCDM = cosmology(*maxwLCDM[:2], omegab = maxwLCDM[2], Hzero=maxwLCDM[3], w=maxwLCDM[4])\n",
    "SNdata.set_param(v.T[0][-6:-2])\n",
    "Qdata.set_param(v.T[0][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[1], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[2], 4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[4], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_wlcdm = BIC_wLCDM(v.T[0],data_sets)\n",
    "\n",
    "print('BIC(wLCDM) = ' + str(bic_wlcdm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_wlcdm -bic_lcdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "\n",
    "if 'BAO'  in data_set_names or 'CMB' in data_set_names:    \n",
    "    ax1.set_title(r'$\\Omega_m = {%1.2f}^{+%1.2f}_{-%1.2f},\\, \\Omega_\\Lambda = {%1.2f}^{+%1.2f}_{-%1.2f},\\, w = {%1.2f}^{+%1.2f}_{-%1.2f},\\, H_0 =  {%1.1f}^{+%1.1f}_{-%1.1f}\\,\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}$' % (omegam, stdmp,stdmm, omegac, stdcp,stdcm, w, wp, wm, H0, stdhp,stdhm), fontsize=17)\n",
    "else:\n",
    "    ax1.set_title(r'$\\Omega_m = {%1.2f}^{+%1.2f}_{-%1.2f},\\, \\Omega_\\Lambda = {%1.2f}^{+%1.2f}_{-%1.2f},\\, w = ,%1.2f}^{+%1.2f}_{-%1.2f}$' % (omegam, stdmp,stdmm, omegac, stdcp,stdcm, w, wp, wm))\n",
    "\n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=-1, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=-1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(best_fit_cosmo_wLCDM).T[0], BAOdata.distance_modulus(best_fit_cosmo_wLCDM).T[1], yerr=BAOdata.delta_distance_modulus(best_fit_cosmo_wLCDM), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=1, label=r'BAO')\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_cosmo_wLCDM.distance_modulus(zPlot), c='k', label=r'best fit')\n",
    "ax1.fill_between(zPlot, cosmology(omegam+stdmp,omegac+stdcp, omegab=omegab+stdbp, w = w+wp, Hzero=H0+stdhp).distance_modulus(zPlot), cosmology(omegam-stdmm,omegac-stdcm, omegab=omegab-stdbm, Hzero=H0-stdhm, w=w-wm).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend(loc=4)\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_cosmo_LCDM.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .06, r'$\\Delta\\mathrm{BIC}(w\\Lambda\\mathrm{CDM}) = %1.0f$' % (BIC_wLCDM(v.T[0],data_sets) - bic_lcdm), ha='right', va='bottom', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/Hubble_wLCDM' + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wLCDM_chains = {}\n",
    "wLCDM_chains['SN'] = HDFBackend('chains/wLCDM_SN_512x1000.h5')\n",
    "wLCDM_chains['SN_Q'] = HDFBackend('chains/wLCDM_SN_Quasars_512x1000.h5')\n",
    "wLCDM_chains['SN_Q_BAO'] = HDFBackend('chains/wLCDM_SN_Quasars_BAO_512x1000.h5')\n",
    "wLCDM_chains['SN_Q_BAO_CMB'] = HDFBackend('chains/wLCDM_SN_Quasars_BAO_CMB_512x1000.h5')\n",
    "wLCDM_chains['SN_BAO_CMB'] = HDFBackend('chains/wLCDM_SN_BAO_CMB_512x1000.h5')\n",
    "wLCDM_chains['BAO'] = HDFBackend('chains/wLCDM_BAO_512x1000.h5')\n",
    "wLCDM_chains['CMB'] = HDFBackend('chains/wLCDM_CMB_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_combinations = ['SN','SN_Q','SN_Q_BAO','SN_BAO_CMB','SN_Q_BAO_CMB','BAO','CMB']\n",
    "data_set_combin_obs = {}\n",
    "data_set_combin_obs['SN'] = [SNdata]\n",
    "data_set_combin_obs['SN_Q'] = [SNdata,Qdata]\n",
    "data_set_combin_obs['SN_Q_BAO'] = [SNdata,Qdata,BAOdata]\n",
    "data_set_combin_obs['SN_BAO_CMB'] = [SNdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['SN_Q_BAO_CMB'] = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['BAO'] = [BAOdata]\n",
    "data_set_combin_obs['CMB'] = [CMBdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_name in data_set_combinations:\n",
    "    sample = wLCDM_chains[set_name].get_chain()\n",
    "    Nmin = 300\n",
    "    while Nmin < nsteps and np.all(wLCDM_chains[set_name].get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "    dellist = np.unique(np.where(np.isclose(sample[-1] - sample[0], 0))[0])\n",
    "    sample = np.delete(sample, np.unique(dellist), axis=1)[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "    data_sets = data_set_combin_obs[set_name]\n",
    "    \n",
    "    vtemp = np.percentile(sample,[16, 50, 84], axis = 0)\n",
    "    vtemp = np.asarray([vtemp[1], vtemp[2]-vtemp[1],vtemp[1]-vtemp[0]]).T\n",
    "    print(set_name + ':')\n",
    "    print('   Om_m:' + str(np.round(vtemp[0],4)))\n",
    "    print('   Om_c:' + str(np.round(vtemp[1],4)))\n",
    "    print('   Om_b:' + str(np.round(vtemp[2],4)*100))\n",
    "    print('   H0:  ' + str(np.round(vtemp[3],2)))\n",
    "    print('   w:   ' + str(np.round(vtemp[4],3)))\n",
    "    print('   dBIC:' + str(np.round(BIC_wLCDM(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "for sampler in wLCDM_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print('Nmin=',Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = wLCDM_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(wLCDM_chains['SN'])),:].reshape((-1, wLCDM_chains['SN'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:5], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "            range=[(0,.6), (0,1.5), (0.03,0.07), (62,75), (-1.5, -0.5)])\n",
    "\n",
    "samples = wLCDM_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(wLCDM_chains['SN_Q'])),:].reshape((-1, wLCDM_chains['SN_Q'].get_chain().shape[-1]))\n",
    "corner(samples[:,:5], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='blue', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            fig=fig, range=[(0,.6), (0,1.5), (0.03,0.07), (62,75), (-1.5, -0.5)])\n",
    "\n",
    "samples = wLCDM_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(wLCDM_chains['BAO'])),:].reshape((-1, wLCDM_chains['BAO'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:5], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            fig=fig, range=[(0,.6), (0,1.5), (0.03,0.07), (62,75), (-1.5, -0.5)])\n",
    "\n",
    "samples = wLCDM_chains['CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(wLCDM_chains['CMB'])),:].reshape((-1, wLCDM_chains['CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:5], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange'], alpha=0.4),\n",
    "            fig=fig, range=[(0,.6), (0,1.5), (0.03,0.07), (62,75), (-1.5, -0.5)])\n",
    "\n",
    "samples = wLCDM_chains['SN_Q_BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(wLCDM_chains['SN_Q_BAO_CMB'])),:].reshape((-1, wLCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:5], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='cyan', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            fig=fig, range=[(0,.6), (0,1.5), (0.03,0.07), (62,75), (-1.5, -0.5)])\n",
    "\n",
    "\n",
    "\n",
    "# samples = wLCDM_chains['SN_BAO_CMB'].get_chain()[Nmin:,:].reshape((-1, wLCDM_chains['SN_BAO_CMB'].get_chain().shape[-1]))\n",
    "# corner(samples[:,:5], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='k', \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgray', 'gray'], alpha=0.4),\n",
    "#             fig=fig, range=[(0,.6), (0,1.5), (0.03,0.07), (62,75), (-1.5, -0.5)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_wLCDM.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Bigravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [SNdata, Qdata, BAOdata, CMBdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Bigravity scale factor function\n",
    "#bigravity_cosmology(-33,1.5,1,2,3,Omega_m_preset,Omega_c_preset).Bianchi(.3)\n",
    "#bigravity_cosmology(-33,1.5,1,2,-3,Omega_m_preset,Omega_c_preset).Bianchi(.3)\n",
    "#bigravity_cosmology(-32,1,1,2,3,Omega_m_preset,Omega_c_preset).Bianchi(.1)\n",
    "#bigravity_cosmology(-34,2,1,2,-3,Omega_m_preset,Omega_c_preset).Bianchi(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_bigravity_min=[-3,-3,-3, 0, .1, 0, 60, -5, -10, -30, -.5, 0, 0]\n",
    "ranges_bigravity_max=[3, 3, 3, np.pi/2, .5, .1, 80, 5, 10, -10, .5, 10, 3]\n",
    "def lnprob_bigravity(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_bigravity_min, ranges_bigravity_max, model = 'bigravity')\n",
    "    return l.logprobability_gauss_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_bigravity = lambda theta, data_sets_var: np.log(sum([len(d.get_data()) for d in data_sets_var])) * len(theta) -2*lnprob_bigravity(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = len(ranges_bigravity_max), 50, 100\n",
    "pos0 = np.random.uniform(ranges_bigravity_min, ranges_bigravity_max, (nwalkers,len(ranges_bigravity_max)))\n",
    "\n",
    "\n",
    "#pool = Pool(cpu_count())\n",
    "#write = HDFBackend('chains/bigravity_' + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "#bigravity_sampler = EnsembleSampler(nwalkers, ndim, lnprob_bigravity, pool=pool)#, backend=write)\n",
    "\n",
    "#bigravity_sampler.run_mcmc(pos0, nsteps, progress=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigravity_sampler = HDFBackend('chains/bigravity' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "\n",
    "nsteps, nwalkers, ndim = bigravity_sampler.get_chain().shape\n",
    "\n",
    "labs = [r'$B_1$', r'$B_2$', r'$B_3$', r'$\\theta$', r'$\\Omega_m$',r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$\\alpha$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 800\n",
    "while Nmin < nsteps and np.all(bigravity_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigravity_samples = bigravity_sampler.get_chain()\n",
    "\n",
    "dellist = np.unique(np.where(np.isclose(bigravity_samples[-1] - bigravity_samples[0], 0))[0])\n",
    "\n",
    "bigravity_samples = np.delete(bigravity_samples, np.unique(dellist), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(len(bigravity_samples.T), 1, figsize=(6,3*len(bigravity_samples.T)))\n",
    "\n",
    "for i in range(len(bigravity_samples.T)):\n",
    "    ax[i].plot(bigravity_samples.T[i].T, lw=0.5)\n",
    "#     ax[i].plot([Nmin, Nmin], [min(bigravity_samples.T[i].flatten()), max(bigravity_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "#     ax[i].text(Nmin, min(bigravity_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/convergence_bigravity.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 800\n",
    "while Nmin < nsteps and np.all(bigravity_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if this fails w/ error \"more dimensions than samples!\", replace Nmin by a lower number for testing\n",
    "#bigravity_samples = bigravity_samples[0:, :].reshape((-1, ndim))\n",
    "bigravity_samples = bigravity_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "meanbigravity = np.mean(bigravity_samples, axis=0)\n",
    "stdbigravity = np.var(bigravity_samples, axis=0)\n",
    "maxbigravity=[]\n",
    "for i in range(len(meanbigravity)):\n",
    "    like = np.histogram(bigravity_samples.T[i], bins=1000)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxbigravity.append(max_val)\n",
    "\n",
    "fig = corner(bigravity_samples[:,:7], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),# range=[(0,0.8),(0.01,0.08), (60,80)],\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=20, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "#              truths=maxLCDM)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_bigravity' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(bigravity_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "log10m, stdmgp, stdmgm = -32., 0, 0\n",
    "b1, stdb1p, stdb1m = v[0]\n",
    "b2, stdb2p, stdb2m = v[1]\n",
    "b3, stdb3p, stdb3m = v[2]\n",
    "theta, stdtp, stdtm = v[3]\n",
    "omegam, stdmp, stdmm = v[4]\n",
    "omegab, stdbp, stdbm = v[5]\n",
    "H0, stdhp, stdhm = v[6]\n",
    "\n",
    "if ndim == 9:\n",
    "    b1, b2, b3 = 1.,1.,-1.,1.\n",
    "elif ndim >=9:\n",
    "    b1, b2, b3 = v[0:3].T[0]\n",
    "\n",
    "\n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "best_fit_bigravitycosmo = bigravity_cosmology(log10m, theta, b1, b2, b3, omegam,1-omegam-omega_gamma_preset, omegar=omega_gamma_preset, omegab=omegab, Hzero=H0)\n",
    "SNdata.set_param(v.T[0][-6:-2])\n",
    "Qdata.set_param(v.T[0][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[0:3],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[3], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[4], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[5], 5)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[6], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_bi = BIC_bigravity(v.T[0],data_sets)\n",
    "\n",
    "print('BIC(Bigravity) = ' + str(bic_bi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_bi - bic_lcdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "\n",
    "if 'BAO'  in data_set_names or 'CMB' in data_set_names:    \n",
    "    ax1.set_title(r'$\\Omega_m = {%1.2f}^{+%1.2f}_{-%1.2f},\\, H_0 =  {%1.1f}^{+%1.1f}_{-%1.1f}\\,\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}$' % (omegam, stdmp,stdmm, H0, stdhp,stdhm), fontsize=18)\n",
    "else:\n",
    "    ax1.set_title(r'$\\Omega_m = {%1.2f}^{+%1.2f}_{-%1.2f}$' % (omegam, stdmp,stdmm), fontsize=18)\n",
    "\n",
    "\n",
    "ax1.text(0.5, 0.96, r'$B_{1,2,3} = \\left({%1.1f}^{+%1.1f}_{-%1.1f}, {%1.1f}^{+%1.1f}_{-%1.1f},{%1.1f}^{+%1.1f}_{-%1.1f}\\right),\\, m_g = 1\\cdot 10^{-32}\\,\\mathrm{eV}$' % (b1, stdb1p, stdb1m, b2, stdb2p, stdb2m, b3, stdb3p, stdb3m), ha='center', va='top', fontsize=16, transform=ax1.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "   \n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=-1, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=-1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(best_fit_bigravitycosmo).T[0], BAOdata.distance_modulus(best_fit_bigravitycosmo).T[1], yerr=BAOdata.delta_distance_modulus(best_fit_bigravitycosmo), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=-1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_bigravitycosmo.distance_modulus(zPlot), c='k', label=r'fit')\n",
    "ax1.fill_between(zPlot, bigravity_cosmology(log10m+stdmp, theta + stdtp, b1+stdb1p,b2+stdb2p,b3+stdb3p, omegam + stdmp, 1- omegam - stdmp, omegab=omegab+stdbp, Hzero=H0+stdhp).distance_modulus(zPlot), bigravity_cosmology(log10m-stdmm, theta - stdtm, b1 - stdb1m,b2 - stdb2m, b3 - stdb3m, omegam - stdmm, 1-omegam + stdmm, omegab=omegab-stdbm, Hzero=H0-stdhm).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset, Hzero=H0).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend(loc=4, fontsize=16)\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_bigravitycosmo.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .93, r'$\\Delta \\mathrm{BIC}(\\mathrm{bigravity}) = %1.0f$' % (BIC_bigravity(v.T[0],data_sets) - bic_lcdm), ha='right', va='top', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/Hubble_bigravity' + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all chains\n",
    "bigravity_chains = {}\n",
    "bigravity_chains['SN'] = HDFBackend('chains/bigravity_SN_512x1000.h5')\n",
    "bigravity_chains['SN_Q'] = HDFBackend('chains/bigravity_SN_Quasars_512x1000.h5')\n",
    "bigravity_chains['SN_Q_BAO'] = HDFBackend('chains/bigravity_SN_Quasars_BAO_512x1000.h5')\n",
    "bigravity_chains['SN_Q_BAO_CMB'] = HDFBackend('chains/bigravity_SN_Quasars_BAO_CMB_512x1000.h5')\n",
    "bigravity_chains['CMB'] = HDFBackend('chains/bigravity_CMB_512x1000.h5')\n",
    "bigravity_chains['BAO'] = HDFBackend('chains/bigravity_BAO_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_combinations = ['SN','SN_Q','SN_Q_BAO','SN_Q_BAO_CMB','BAO','CMB']\n",
    "data_set_combin_obs = {}\n",
    "data_set_combin_obs['SN'] = [SNdata]\n",
    "data_set_combin_obs['SN_Q'] = [SNdata,Qdata]\n",
    "data_set_combin_obs['SN_Q_BAO'] = [SNdata,Qdata,BAOdata]\n",
    "#data_set_combin_obs['SN_BAO_CMB'] = [SNdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['SN_Q_BAO_CMB'] = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['BAO'] = [BAOdata]\n",
    "data_set_combin_obs['CMB'] = [CMBdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_name in data_set_combinations:\n",
    "    sample = bigravity_chains[set_name].get_chain()\n",
    "    Nmin = 800\n",
    "    while Nmin < nsteps and np.all(bigravity_chains[set_name].get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "    dellist = np.unique(np.where(np.isclose(sample[-1] - sample[0], 0))[0])\n",
    "    sample = np.delete(sample, np.unique(dellist), axis=1)[Nmin:, :].reshape((-1, ndim))\n",
    "    \n",
    "    data_sets = data_set_combin_obs[set_name]\n",
    "    \n",
    "    vtemp = np.percentile(sample,[16, 50, 84], axis = 0)\n",
    "    vtemp = np.asarray([vtemp[1], vtemp[2]-vtemp[1],vtemp[1]-vtemp[0]]).T\n",
    "    print(set_name + ':')\n",
    "    print('   Om_m:   ' + str(np.round(vtemp[4],4)))\n",
    "    print('   Om_b:   ' + str(np.round(vtemp[5],4)*100))\n",
    "    print('   H0:     ' + str(np.round(vtemp[6],2)))\n",
    "    print('   Theta:  ' + str(np.round(vtemp[3],3)))\n",
    "    print('   b1:     ' + str(np.round(vtemp[0],3)))\n",
    "    print('   b2:     ' + str(np.round(vtemp[1],3)))\n",
    "    print('   b3:     ' + str(np.round(vtemp[2],3)))\n",
    "    print('   dBIC:   ' + str(np.round(BIC_bigravity(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name])))\n",
    "    #print(vtemp.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 600\n",
    "for sampler in bigravity_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print(\"Nmin = \", Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = bigravity_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(bigravity_chains['SN'])),:].reshape((-1, bigravity_chains['SN'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,4:7], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs[4:7], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "            range=[(0,1), (0.03,0.07), (60,73)])\n",
    "\n",
    "samples = bigravity_chains['SN_Q_BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(bigravity_chains['SN_Q_BAO_CMB'])),:].reshape((-1, bigravity_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,4:7], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs[4:7], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='cyan',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green'], alpha=0.4),\n",
    "            fig=fig, range=[(0,1), (0.03,0.07), (60,73)])\n",
    "\n",
    "samples = bigravity_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(bigravity_chains['SN_Q'])),:].reshape((-1, bigravity_chains['SN_Q'].get_chain().shape[-1]))\n",
    "corner(samples[:,4:7], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs[4:7], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='blue', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            fig=fig, range=[(0,1), (0.03,0.07), (60,73)])\n",
    "\n",
    "samples = bigravity_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(bigravity_chains['BAO'])),:].reshape((-1, bigravity_chains['BAO'].get_chain().shape[-1]))\n",
    "corner(samples[:,4:7], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs[4:7], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            fig=fig, range=[(0,1), (0.03,0.07), (60,73)])\n",
    "\n",
    "samples = bigravity_chains['CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(bigravity_chains['CMB'])),:].reshape((-1, bigravity_chains['CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,4:7], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "           labels=labs[4:7], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange', \n",
    "           fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange'], alpha=0.4),\n",
    "           fig=fig, range=[(0,1), (0.03,0.07), (60,73)])\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_bigravity.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: oBigravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [SNdata, Qdata, BAOdata, CMBdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_obigravity_min=[-3,-3,-3, 0, 0, 0, 0, 60, -5, -10, -30, -.5, 0, 0]\n",
    "ranges_obigravity_max=[3, 3, 3, np.pi/2, 1, 1.5, .1, 80, 5, 10, -10, .5, 10, 3]\n",
    "def lnprob_obigravity(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_obigravity_min, ranges_obigravity_max, model = 'obigravity')\n",
    "    return l.logprobability_gauss_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_obigravity = lambda theta, data_sets_var: np.log(sum([len(d.get_data()) for d in data_sets_var])) * len(theta) -2*lnprob_obigravity(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = len(ranges_obigravity_max), 50, 100\n",
    "pos0 = np.random.uniform(ranges_obigravity_min, ranges_obigravity_max, (nwalkers,len(ranges_obigravity_max)))\n",
    "\n",
    "\n",
    "#pool = Pool(cpu_count())\n",
    "#write = HDFBackend('chains/obigravity_' + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "#obigravity_sampler = EnsembleSampler(nwalkers, ndim, lnprob_obigravity, pool=pool)#, backend=write)\n",
    "\n",
    "#obigravity_sampler.run_mcmc(pos0, nsteps, progress=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obigravity_sampler = HDFBackend('chains/obigravity' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "\n",
    "nsteps, nwalkers, ndim = obigravity_sampler.get_chain().shape\n",
    "\n",
    "labs = [r'$B_1$', r'$B_2$', r'$B_3$', r'$\\theta$', r'$\\Omega_m$',  r'$\\Omega_\\Lambda$', r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$\\alpha$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 800\n",
    "while Nmin < nsteps and np.all(obigravity_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obigravity_samples = obigravity_sampler.get_chain()\n",
    "\n",
    "dellist = np.unique(np.where(np.isclose(obigravity_samples[-1] - obigravity_samples[0], 0))[0])\n",
    "\n",
    "obigravity_samples = np.delete(obigravity_samples, np.unique(dellist), axis=1)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(len(obigravity_samples.T), 1, figsize=(6,3*len(obigravity_samples.T)))\n",
    "\n",
    "for i in range(len(obigravity_samples.T)):\n",
    "    ax[i].plot(obigravity_samples.T[i].T, lw=0.5)\n",
    "#     ax[i].plot([Nmin, Nmin], [min(obigravity_samples.T[i].flatten()), max(obigravity_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "#     ax[i].text(Nmin, min(obigravity_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/convergence_obigravity.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dellist = np.unique(np.where(np.isclose(obigravity_samples[-1] - obigravity_samples[0], 0))[0])\n",
    "\n",
    "obigravity_samples = np.delete(obigravity_samples, np.unique(dellist), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obigravity_samples = obigravity_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "meanobigravity = np.mean(obigravity_samples, axis=0)\n",
    "stdobigravity = np.var(obigravity_samples, axis=0)\n",
    "maxobigravity=[]\n",
    "for i in range(len(meanobigravity)):\n",
    "    like = np.histogram(obigravity_samples.T[i], bins=1000)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxobigravity.append(max_val)\n",
    "\n",
    "fig = corner(obigravity_samples[:,:8], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "# #              truths=maxobigravity)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_obigravity' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(obigravity_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "log10m, stdmgp, stdmgm = -32., 0, 0\n",
    "b1, stdb1p, stdb1m = v[0]\n",
    "b2, stdb2p, stdb2m = v[1]\n",
    "b3, stdb3p, stdb3m = v[2]\n",
    "theta, stdtp, stdtm = v[3]\n",
    "omegam, stdmp, stdmm = v[4]\n",
    "omegac, stdcp, stdcm = v[5]\n",
    "omegab, stdbp, stdbm = v[6]\n",
    "H0, stdhp, stdhm = v[7]\n",
    "\n",
    "if ndim == 9:\n",
    "    b1, b2, b3 = 1.,1.,-1.,1.\n",
    "elif ndim >=9:\n",
    "    b1, b2, b3 = v[0:3].T[0]\n",
    "\n",
    "\n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "best_fit_obigravitycosmo = bigravity_cosmology(log10m, theta, b1, b2, b3, omegam, omegac, omegar=omega_gamma_preset, omegab=omegab, Hzero=H0)\n",
    "SNdata.set_param(v.T[0][-6:-2])\n",
    "Qdata.set_param(v.T[0][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[0:3],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[4], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[5], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[6], 4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[7], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_obi = BIC_obigravity(v.T[0],data_sets)\n",
    "\n",
    "print('BIC(oBigravity) = ' + str(bic_obi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_obi -bic_lcdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "\n",
    "if 'BAO'  in data_set_names or 'CMB' in data_set_names:    \n",
    "    ax1.set_title(r'$\\Omega_m = {%1.2f}^{+%1.2f}_{-%1.2f},\\, \\Omega_\\Lambda = {%1.2f}^{+%1.2f}_{-%1.2f},\\, H_0 =  {%1.1f}^{+%1.1f}_{-%1.1f}\\,\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}$' % (omegam, stdmp,stdmm, omegac, stdcp,stdcm, H0, stdhp,stdhm), fontsize=18)\n",
    "else:\n",
    "    ax1.set_title(r'$\\Omega_m = {%1.2f}^{+%1.2f}_{-%1.2f}\\,,\\Omega_\\Lambda = {%1.2f}^{+%1.2f}_{-%1.2f}$' % (omegam, stdmp,stdmm, omegac, stdcp,stdcm), fontsize=18)\n",
    "\n",
    "\n",
    "ax1.text(0.5, 0.96, r'$B_{1,2,3} = \\left({%1.1f}^{+%1.1f}_{-%1.1f}, {%1.1f}^{+%1.1f}_{-%1.1f},{%1.1f}^{+%1.1f}_{-%1.1f}\\right),\\, m_g = 1\\cdot 10^{-32}\\,\\mathrm{eV}$' % (b1, stdb1p, stdb1m, b2, stdb2p, stdb2m, b3, stdb3p, stdb3m), ha='center', va='top', fontsize=16, transform=ax1.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "   \n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=-1, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=-1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(best_fit_obigravitycosmo).T[0], BAOdata.distance_modulus(best_fit_obigravitycosmo).T[1], yerr=BAOdata.delta_distance_modulus(best_fit_obigravitycosmo), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=-1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_obigravitycosmo.distance_modulus(zPlot), c='k', label=r'fit')\n",
    "ax1.fill_between(zPlot, bigravity_cosmology(log10m+stdmp, theta + stdtp, b1+stdb1p,b2+stdb2p,b3+stdb3p, omegam + stdmp, omegac + stdcp, omegab=omegab+stdbp, Hzero=H0+stdhp).distance_modulus(zPlot), bigravity_cosmology(log10m-stdmm, theta - stdtm, b1 - stdb1m,b2 - stdb2m, b3 - stdb3m, omegam - stdmm, omegac - stdcm, omegab=omegab-stdbm, Hzero=H0-stdhm).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset, Hzero=H0).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "ax1.plot(zPlot, cosmology(omegam, omegac, Hzero=H0).distance_modulus(zPlot), ls = ':', c='lightgray', label=r'$\\Lambda\\mathrm{CDM}(\\Omega_m, \\Omega_\\Lambda)$')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend(loc=4, fontsize=16)\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_obigravitycosmo.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .06, r'$\\Delta \\mathrm{BIC}(\\mathrm{oBigravity}) = %1.0f$' % (BIC_obigravity(v.T[0],data_sets) - bic_lcdm), ha='right', va='bottom', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/Hubble_obigravity' + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obigravity_chains = {}\n",
    "obigravity_chains['SN'] = HDFBackend('chains/obigravity_SN_512x1000.h5')\n",
    "obigravity_chains['SN_Q'] = HDFBackend('chains/obigravity_SN_Quasars_512x1000.h5')\n",
    "obigravity_chains['SN_Q_BAO'] = HDFBackend('chains/obigravity_SN_Quasars_BAO_512x1000.h5')\n",
    "obigravity_chains['SN_Q_BAO_CMB'] = HDFBackend('chains/obigravity_SN_Quasars_BAO_CMB_512x1000.h5')\n",
    "obigravity_chains['CMB'] = HDFBackend('chains/obigravity_CMB_512x1000.h5')\n",
    "obigravity_chains['BAO'] = HDFBackend('chains/obigravity_BAO_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_combinations = ['SN','SN_Q','SN_Q_BAO','SN_Q_BAO_CMB','BAO','CMB']\n",
    "data_set_combin_obs = {}\n",
    "data_set_combin_obs['SN'] = [SNdata]\n",
    "data_set_combin_obs['SN_Q'] = [SNdata,Qdata]\n",
    "data_set_combin_obs['SN_Q_BAO'] = [SNdata,Qdata,BAOdata]\n",
    "#data_set_combin_obs['SN_BAO_CMB'] = [SNdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['SN_Q_BAO_CMB'] = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['BAO'] = [BAOdata]\n",
    "data_set_combin_obs['CMB'] = [CMBdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_name in data_set_combinations:\n",
    "    sample = obigravity_chains[set_name].get_chain()\n",
    "    Nmin = 800\n",
    "    while Nmin < nsteps and np.all(obigravity_chains[set_name].get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "    dellist = np.unique(np.where(np.isclose(sample[-1] - sample[0], 0))[0])\n",
    "    sample = np.delete(sample, np.unique(dellist), axis=1)[Nmin:, :].reshape((-1, ndim))\n",
    "    \n",
    "    data_sets = data_set_combin_obs[set_name]\n",
    "    \n",
    "    vtemp = np.percentile(sample,[16, 50, 84], axis = 0)\n",
    "    vtemp = np.asarray([vtemp[1], vtemp[2]-vtemp[1],vtemp[1]-vtemp[0]]).T\n",
    "    print(set_name + ':')\n",
    "    print('   Om_m:   ' + str(np.round(vtemp[4],4)))\n",
    "    print('   Om_c:   ' + str(np.round(vtemp[5],4)))\n",
    "    print('   Om_b:   ' + str(np.round(vtemp[6],4)*100))\n",
    "    print('   H0:     ' + str(np.round(vtemp[7],2)))\n",
    "    print('   Theta:  ' + str(np.round(vtemp[3],3)))\n",
    "    print('   b1:     ' + str(np.round(vtemp[0],3)))\n",
    "    print('   b2:     ' + str(np.round(vtemp[1],3)))\n",
    "    print('   b3:     ' + str(np.round(vtemp[2],3)))\n",
    "    print('   dBIC:   ' + str(np.round(BIC_obigravity(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name])))\n",
    "    #print(Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 800\n",
    "for sampler in obigravity_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print(\"Nmin = \", Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = obigravity_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(obigravity_chains['SN'])),:].reshape((-1, obigravity_chains['SN'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,4:8], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs[4:8], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "            range=[(0,1), (0,1.25), (0.03,0.07), (60,75)])\n",
    "\n",
    "samples = obigravity_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(obigravity_chains['SN_Q'])),:].reshape((-1, obigravity_chains['SN_Q'].get_chain().shape[-1]))\n",
    "corner(samples[:,4:8], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs[4:8], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='blue', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            fig=fig, range=[(0,1), (0,1.25), (0.03,0.07), (60,75)])\n",
    "\n",
    "samples = obigravity_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(obigravity_chains['BAO'])),:].reshape((-1, obigravity_chains['BAO'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,4:8], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs[4:8], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            fig=fig, range=[(0,1), (0,1.25), (0.03,0.07), (60,75)])\n",
    "\n",
    "samples = obigravity_chains['CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(obigravity_chains['CMB'])),:].reshape((-1, obigravity_chains['CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,4:8], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs[4:8], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange'], alpha=0.4),\n",
    "            fig=fig, range=[(0,1), (0,1.25), (0.03,0.07), (60,75)])\n",
    "\n",
    "samples = obigravity_chains['SN_Q_BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(obigravity_chains['SN_Q_BAO_CMB'])),:].reshape((-1, obigravity_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,4:8], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs[4:8], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='cyan', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            fig=fig, range=[(0,.6), (0,1.25), (0.03,0.07), (60,75)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_obigravity.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: Conformal Gravity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which data sets to include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [SNdata, Qdata, BAOdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_conformal_min=[0, 0, 0, 60, -5, -10, -30, -.5, 0, 0]\n",
    "ranges_conformal_max=[1, 100, 0.1, 80, 5, 10, -10, .5, 10, 3]\n",
    "def lnprob_conformal(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_conformal_min, ranges_conformal_max, model = 'conformal')\n",
    "    return l.logprobability_gauss_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_conformal = lambda theta, data_sets_var: np.log(sum([len(d.get_data()) for d in data_sets_var])) * len(theta) -2*lnprob_conformal(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = len(ranges_conformal_min), 500, 1000\n",
    "pos0 = np.random.uniform(ranges_conformal_min, ranges_conformal_max, (nwalkers,len(ranges_conformal_max)))\n",
    "\n",
    "# pool = Pool(cpu_count())\n",
    "# write = HDFBackend('chains/conformal_' + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "# sampler = EnsembleSampler(nwalkers, ndim, lnprob_conformal, pool=pool)#, backend=write)\n",
    "\n",
    "# sampler.run_mcmc(pos0, nsteps, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_sampler = HDFBackend('chains/conformal' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "# LCDM_sampler = sampler\n",
    "\n",
    "nsteps, nwalkers, ndim = conformal_sampler.get_chain().shape\n",
    "\n",
    "labs_k=[r'$\\Omega_k$', r'$(\\kappa/\\mathrm{Gpc}^{-2})$', r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$\\alpha$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']\n",
    "labs=[r'$(\\gamma_0/\\mathrm{Gpc}^{-1})$', r'$(\\kappa/\\mathrm{Gpc}^{-2})$', r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$\\alpha$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 900\n",
    "while Nmin < nsteps and np.all(conformal_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_samples = conformal_sampler.get_chain()\n",
    "conformal_samples = conformal_samples[:,np.where(conformal_samples[0].T[0] < .5)[0],:]\n",
    "\n",
    "f, ax = plt.subplots(len(conformal_samples.T), 1, figsize=(6,3*len(conformal_samples.T)))\n",
    "\n",
    "for i in range(len(conformal_samples.T)):\n",
    "    ax[i].plot(conformal_samples.T[i].T, lw=0.5)\n",
    "    ax[i].plot([Nmin, Nmin], [min(conformal_samples.T[i].flatten()), max(conformal_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "    ax[i].text(Nmin, min(conformal_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/convergence_conformal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dellist = np.unique(np.where(np.isclose(conformal_samples[-1] - conformal_samples[0], 0))[0])\n",
    "\n",
    "conformal_samples = np.delete(conformal_samples, np.unique(dellist), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_samples = conformal_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "meanconformal = np.mean(conformal_samples, axis=0)\n",
    "stdconformal = np.var(conformal_samples, axis=0)\n",
    "maxconformal=[]\n",
    "for i in range(len(meanconformal)):\n",
    "    like = np.histogram(conformal_samples.T[i], bins=50)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxconformal.append(max_val)\n",
    "\n",
    "    \n",
    "# conformal_samples.T[0] = (conformal_samples.T[0])**2 / 2 * cLight**2/(70./1E-3)**2\n",
    "fig = corner(conformal_samples, quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=20, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "# #              truths=maxconformal)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_conformal' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(conformal_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "gamma0, gamm0p, gamma0m = v[0]\n",
    "kappa, kappap, kappam = v[1]\n",
    "\n",
    "omegak = (gamma0)**2 / 2 * cosmology.cLight**2/(70./1E-3)**2\n",
    "stdkp, stdkm = np.array([gamm0p, gamma0m]) * (gamma0) * cosmology.cLight**2/(70./1E-3)**2#Gpc^-1\n",
    "\n",
    "\n",
    "omegab, stdbp, stdbm = v[2]\n",
    "H0, stdhp, stdhm = v[3]\n",
    "\n",
    "omegac = 1 - omegak\n",
    "stdcp = stdkm\n",
    "stdcm = stdkp\n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "\n",
    "best_fit_conformalcosmo = cosmology(0, omegac, omegab=omegab, omegar=omega_gamma_preset, Hzero=H0)\n",
    "SNdata.set_param(v.T[0][-6:-2])\n",
    "Qdata.set_param(v.T[0][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round([omegak, stdkp, stdkm],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[2],4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(v[3],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_CG = BIC_conformal(v.T[0],data_sets)\n",
    "\n",
    "print('BIC(CG) = ' + str(bic_CG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = sum([len(galaxy) for galaxy in RCdata.get_data()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_conformal(v.T[0],data_sets) - 141759 + n*np.log(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "\n",
    "if 'RC' in data_set_names:\n",
    "    ax1.set_title(r'$\\Omega_\\Lambda = {%1.3f}^{+%1.3f}_{-%1.3f},\\, 1000\\,\\Omega_k = {%1.3f}^{+%1.3f}_{-%1.3f},\\, H_0 =  {%1.1f}^{+%1.1f}_{-%1.1f}\\,\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}$' % (omegac, stdcp,stdcm, 1000*omegak, 1000*stdkm, 1000*stdkp, H0, stdhp, stdhm), fontsize=18)\n",
    "else:\n",
    "    ax1.set_title(r'$\\Omega_\\Lambda = {%1.3f}^{+%1.3f}_{-%1.3f},\\, \\Omega_k = {%1.3f}^{+%1.3f}_{-%1.3f},\\, H_0 =  {%1.1f}^{+%1.1f}_{-%1.1f}\\,\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}$' % (omegac, stdcp,stdcm, omegak, stdkm, stdkp, H0, stdhp, stdhm), fontsize=18)\n",
    "\n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=-1, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=-1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(best_fit_conformalcosmo).T[0], BAOdata.distance_modulus(best_fit_conformalcosmo).T[1], yerr=BAOdata.delta_distance_modulus(best_fit_conformalcosmo), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_conformalcosmo.distance_modulus(zPlot), c='k', label=r'best fit')\n",
    "ax1.fill_between(zPlot, cosmology(0,omegac+stdcp, omegab=omegab+stdbp, Hzero=H0 + stdhp).distance_modulus(zPlot), cosmology(0,omegac-stdcm, omegab=omegab-stdbm, Hzero=H0 - stdhm).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_conformalcosmo.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .06, r'$\\Delta\\mathrm{BIC}(\\mathrm{CG}) = %1.0f$' % (BIC_conformal(v.T[0],data_sets) - bic_lcdm), ha='right', va='bottom', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/Hubble_conformal' + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_chains = {}\n",
    "conformal_chains['SN'] = HDFBackend('chains/conformal_SN_512x1000.h5')\n",
    "conformal_chains['SN_Q'] = HDFBackend('chains/conformal_SN_Quasars_512x1000.h5')\n",
    "conformal_chains['BAO'] = HDFBackend('chains/conformal_BAO_512x1000.h5')\n",
    "# conformal_chains['CMB'] = HDFBackend('chains/conformal_CMB_512x1000.h5')\n",
    "conformal_chains['SN_Q_BAO'] = HDFBackend('chains/conformal_SN_Quasars_BAO_512x1000.h5')\n",
    "#conformal_chains['RC'] = HDFBackend('chains/conformal_RC_512x1000.h5')\n",
    "#conformal_chains['SN_RC'] = HDFBackend('chains/conformal_RC_SN_512x1000.h5')\n",
    "#conformal_chains['SN_Q_RC'] = HDFBackend('chains/conformal_RC_SN_Quasars_512x1000.h5')\n",
    "#conformal_chains['SN_Q_BAO_RC'] = HDFBackend('chains/conformal_RC_SN_Quasars_BAO_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_combinations = ['SN','SN_Q','SN_Q_BAO']\n",
    "data_set_combin_obs = {}\n",
    "data_set_combin_obs['SN'] = [SNdata]\n",
    "data_set_combin_obs['SN_Q'] = [SNdata,Qdata]\n",
    "data_set_combin_obs['SN_Q_BAO'] = [SNdata,Qdata,BAOdata]\n",
    "#data_set_combin_obs['SN_BAO_CMB'] = [SNdata,BAOdata,CMBdata]\n",
    "#data_set_combin_obs['SN_Q_BAO_CMB'] = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "#data_set_combin_obs['BAO'] = [BAOdata]\n",
    "#data_set_combin_obs['CMB'] = [CMBdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_name in data_set_combinations:\n",
    "    sample = conformal_chains[set_name].get_chain()\n",
    "    Nmin = 900\n",
    "    while Nmin < nsteps and np.all(conformal_chains[set_name].get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "    dellist = np.unique(np.where(np.isclose(sample[-1] - sample[0], 0))[0])\n",
    "    sample = np.delete(sample, np.unique(dellist), axis=1)[Nmin:, :].reshape((-1, ndim))\n",
    "    \n",
    "    data_sets = data_set_combin_obs[set_name]\n",
    "    \n",
    "    vtemp = np.percentile(sample,[16, 50, 84], axis = 0)\n",
    "    vtemp = np.asarray([vtemp[1], vtemp[2]-vtemp[1],vtemp[1]-vtemp[0]]).T\n",
    "    \n",
    "    gamma0, gamm0p, gamma0m = vtemp[0]\n",
    "\n",
    "    omegak = (gamma0)**2 / 2 * cosmology.cLight**2/(70./1E-3)**2\n",
    "    stdkp, stdkm = np.array([gamm0p, gamma0m]) * (gamma0) * cosmology.cLight**2/(70./1E-3)**2#Gpc^-1\n",
    "\n",
    "    print(set_name + ':')\n",
    "    print('   Om_k:   ' + str(np.round([omegak,stdkp,stdkm],4)))\n",
    "    print('   Om_b:   ' + str(np.round(vtemp[2],4)*100))\n",
    "    print('   kappa:  ' + str(np.round(vtemp[1],4)))\n",
    "    print('   H0:     ' + str(np.round(vtemp[3],1)))\n",
    "    print('   dBIC:   ' + str(np.round(BIC_conformal(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name])))\n",
    "    #print(vtemp.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 900\n",
    "for sampler in conformal_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print('Nmin=',Nmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Rot curves -> exclude $\\kappa$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = conformal_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(conformal_chains['SN'])),:].reshape((-1, conformal_chains['SN'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples.T[0] = (samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2\n",
    "samples = np.array([samples.T[i] for i in (0,2,3)]).T\n",
    "fig=corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=np.delete(labs_k, 1), smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "            range=[(0,1), (0, .1), (62,75)])\n",
    "\n",
    "samples = conformal_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(conformal_chains['SN_Q'])),:].reshape((-1, conformal_chains['SN_Q'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples.T[0] = (samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2\n",
    "samples = np.array([samples.T[i] for i in (0,2,3)]).T\n",
    "corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)), color='blue',\n",
    "            labels=np.delete(labs_k, 1), smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            fig=fig, range=[(0,1), (0, .1), (62,75)])\n",
    "\n",
    "\n",
    "samples = conformal_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(conformal_chains['BAO'])),:].reshape((-1, conformal_chains['BAO'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples.T[0] = (samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2\n",
    "samples = np.array([samples.T[i] for i in (0,2,3)]).T\n",
    "fig=corner(samples, levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=np.delete(labs_k, 1), smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            fig=fig, range=[(0,1), (0, .1), (62,75)])\n",
    "\n",
    "\n",
    "# samples = conformal_chains['CMB'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['CMB'].get_chain().shape[-1]))\n",
    "# samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "# samples = np.array([samples.T[i] for i in (0,2,3)]).T\n",
    "# corner(samples, levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#             labels=np.delete(labs_k, 1), smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange', \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange'], alpha=0.4),\n",
    "#             fig=fig)#, range=[(0,1), (50,300), (0, .1), (62,75)])\n",
    "\n",
    "samples = conformal_chains['SN_Q_BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(conformal_chains['SN_Q_BAO'])),:].reshape((-1, conformal_chains['SN_Q_BAO'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples.T[0] = (samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2\n",
    "samples = np.array([samples.T[i] for i in (0,2,3)]).T\n",
    "corner(samples, levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=np.delete(labs_k, 1), smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='cyan', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            fig=fig, range=[(0,1), (0, .1), (62,75)])\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_conformal.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Rot curves -> include $\\kappa$ :\n",
    "Because CG is already severely restricted without RC, we do not eveninclude this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_k[0] = r'$\\log_{10}(\\Omega_k)$'\n",
    "\n",
    "samples = conformal_chains['SN_Q_BAO'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['SN_Q_BAO'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples = np.array([samples.T[i] for i in (0,1)]).T\n",
    "samples.T[0] = np.log10((samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2)\n",
    "fig=corner(samples, levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs_k, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='cyan', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            range=[(-3,0), (50,250)])\n",
    "\n",
    "samples = conformal_chains['RC'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['RC'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples = np.array([samples.T[i] for i in (0,1)]).T\n",
    "samples.T[0] = np.log10((samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2)\n",
    "corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs_k, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange']),\n",
    "            fig=fig, range=[(-3,0), (50,250)])\n",
    "\n",
    "\n",
    "samples = conformal_chains['SN_RC'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['SN_RC'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples = np.array([samples.T[i] for i in (0,1)]).T\n",
    "samples.T[0] = np.log10((samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2)\n",
    "corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs_k, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "            fig=fig, range=[(-3,0), (50,250)])\n",
    "\n",
    "samples = conformal_chains['SN_Q_RC'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['SN_Q_RC'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples = np.array([samples.T[i] for i in (0,1)]).T\n",
    "samples.T[0] = np.log10((samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2)\n",
    "corner(samples,  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)), color='blue',\n",
    "            labels=labs_k, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            fig=fig, range=[(-3,0), (50,250)])\n",
    "\n",
    "samples = conformal_chains['SN_Q_BAO_RC'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['SN_Q_BAO_RC'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples = np.array([samples.T[i] for i in (0,1)]).T\n",
    "samples.T[0] = np.log10((samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2)\n",
    "corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)), color='red',\n",
    "            labels=labs_k, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.6),\n",
    "            fig=fig, range=[(-3,0), (50,250)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_conformal_RC.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma0, kappa = v[0:2,0]\n",
    "print(gamma0, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GN =  4.301E3 #GN * 10^9 Msol / 1kpc in (km/s)^2\n",
    "\n",
    "def vhalo_square(r, Ms, rs): # units of 1E9 Msol\n",
    "    return GN * Ms * (np.log(1+r/rs) - r/(r+rs))/r\n",
    "\n",
    "def vCG_square(r, gamma0=gamma0, kappa=kappa): # units of 1E9 Msol\n",
    "    r = r / 1E6 #Gpc\n",
    "    return cLight**2 * gamma0 * r / 2 - kappa * cLight**2 * r**2\n",
    "\n",
    "def vlocal_square (r, r0, M0, gamma):\n",
    "        return GN * M0 * (r/r0)**2 * (i0(r/2/r0) * k0(r/2/r0) - i1(r/2/r0) * k1(r/2/r0)) + gamma * (r/r0)**2 * i1(r/2/r0) * k1(r/2/r0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(int(np.ceil(len(RCdata.get_data())/5)),5, figsize=(12,2.5*len(RCdata.get_data())/5))\n",
    "# f, ax = plt.subplots(1,5, figsize=(15,4))\n",
    "\n",
    "ax = ax.flatten()\n",
    "\n",
    "pDMList=[]\n",
    "chiDM=[]\n",
    "pCGList=[]\n",
    "chiCG=[]\n",
    "\n",
    "galaxies = RCdata.get_data()\n",
    "names = RCdata.get_names()\n",
    "\n",
    "for i in range(len(galaxies)):\n",
    "    visible = lambda r, YD, YB: interp1d(galaxies[i][:,0], galaxies[i][:,3]**2 + YD*galaxies[i][:,4]**2 + YB*galaxies[i][:,5]**2, kind='cubic')(r)\n",
    "    fitf_DM =  lambda r, YD, YB, Ms, rs,: visible(r, YD, YB) + vhalo_square(r, Ms,rs) \n",
    "    pDM, _ = curve_fit(fitf_DM, galaxies[i][:,0], galaxies[i][:,1]**2, sigma=galaxies[i][:,2]**2, p0=[1,1, 5, 2*max(galaxies[i][:,0])], bounds = ([.1,.1,0,1], [5,5,250,10*max(galaxies[i][:,0])]))\n",
    "    \n",
    "    \n",
    "    pGas, _ = curve_fit(vlocal_square,  galaxies[i][:,0], galaxies[i][:,3]**2, p0=[1,10,1], bounds=(0, 500))\n",
    "    pDisk, _ = curve_fit(vlocal_square,  galaxies[i][:,0], galaxies[i][:,4]**2, p0=[1,10,1], bounds=(0, 500))\n",
    "    visibleCG = lambda r, YD, YB: vlocal_square(r, *pGas) + YD * vlocal_square(r, *pDisk) + YD * interp1d(galaxies[i][:,0], galaxies[i][:,5]**2, kind='cubic')(r)\n",
    "    fitf_CG = lambda r, YD, YB: visibleCG(r, YD, YB) + vCG_square(r) \n",
    "    pCG, _ = curve_fit(fitf_CG, galaxies[i][:,0], galaxies[i][:,1]**2, sigma=galaxies[i][:,2]**2, p0=[1, 1])#, bounds = ([0.1,.1,0,0], [5,5,10,10]))\n",
    "\n",
    "    pDMList.append(pDM)\n",
    "    pCGList.append(pCG)\n",
    "    chiDM.append(np.sum( (galaxies[i][:,1] - fitf_DM(galaxies[i][:,0],*pDM)**.5)**2 / galaxies[i][:,2]**2))\n",
    "    chiCG.append(np.sum( (galaxies[i][:,1] - fitf_CG(galaxies[i][:,0],*pCG)**.5)**2 / galaxies[i][:,2]**2))\n",
    "    \n",
    "    \n",
    "    ax[i].set_title(names[i])\n",
    "    ax[i].set_xlabel(r'$r\\ [\\mathrm{kpc}]$')\n",
    "    ax[i].set_ylabel(r'$v\\ [\\mathrm{km}/ \\mathrm{s}]$')\n",
    "    ax[i].plot(galaxies[i][:,0], galaxies[i][:,3], c='lightgreen', lw=0.6, label='gas')\n",
    "    ax[i].plot(galaxies[i][:,0], np.sqrt(pDM[0])*galaxies[i][:,4], c='blue', lw=0.6, label='disk')\n",
    "    ax[i].plot(galaxies[i][:,0], np.sqrt(pDM[1])*galaxies[i][:,5], c='m', lw=0.6, label='bulge')\n",
    "    ax[i].plot(galaxies[i][:,0], vhalo_square(galaxies[i][:,0], *pDM[2:])**.5, c='maroon', ls=':') \n",
    "    ax[i].plot(galaxies[i][:,0], vCG_square(galaxies[i][:,0])**.5, c='y', ls='-.') \n",
    "    ax[i].plot(galaxies[i][:,0], np.sqrt(galaxies[i][:,3]**2 + pDM[0]*galaxies[i][:,4]**2 + pDM[1]*galaxies[i][:,5]**2 + vhalo_square(galaxies[i][:,0], *pDM[2:])), c='r')\n",
    "    ax[i].plot(galaxies[i][:,0], np.sqrt(galaxies[i][:,3]**2 +  pCG[0]*galaxies[i][:,4]**2 +  pCG[1]*galaxies[i][:,5]**2+ vCG_square(galaxies[i][:,0], *pCG[2:])), c='orange')\n",
    "    ax[i].errorbar(galaxies[i][:,0], galaxies[i][:,1], yerr=galaxies[i][:,2], c='k', fmt='o', markersize=3)\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/SPARC_DM.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_CG_RT = np.sum(np.array(chiCG)[~np.isnan(chiCG)])\n",
    "# bic_CG_RT += (3*n + 2)*np.log(n)\n",
    "bic_CG_RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_lcdm_RT =  np.sum(np.array(chiDM)[~np.isnan(chiCG)])\n",
    "# bic_lcdm_RT += 4*n*np.log(n)\n",
    "bic_lcdm_RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bic_CG_RT - bic_lcdm_RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
