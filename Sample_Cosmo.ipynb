{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', size=16,family='serif')\n",
    "import matplotlib.gridspec as gridspec\n",
    "from emcee import EnsembleSampler\n",
    "from emcee.backends import HDFBackend\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from corner import corner\n",
    "from Cosmology import *\n",
    "import sys\n",
    "\n",
    "\n",
    "#load autoreload, which automatically reloads the cosmology.py upon execution\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport Cosmology\n",
    "\n",
    "\n",
    "#Parameters for BAO -- CHECK THESE VALUES\n",
    "z_d = 1089\n",
    "h = .6688\n",
    "omega_baryon_preset = 0.02212/h**2\n",
    "omega_gamma_preset = 2.469E-5/h**2\n",
    "\n",
    "#Cosmological parameters\n",
    "Omega_m_preset = 0.3089\n",
    "Omega_r_preset = 2.469E-5/h**2\n",
    "Omega_c_preset = 0.6911"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supernova data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSN = np.loadtxt('data/jla_lcparams.txt', usecols=(2,4,6,8,10))\n",
    "errSN = np.loadtxt('data/jla_lcparams.txt', usecols=(5,7,9))[np.argsort(dataSN.T[0])]\n",
    "dataSN = dataSN[np.argsort(dataSN.T[0])]\n",
    "\n",
    "#best fit values found in JLA analysis arXiv:1401.4064\n",
    "a = 0.14\n",
    "b = 3.14\n",
    "MB = -19.04\n",
    "delta_Mhost = -.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNdata = Supernova_data(dataSN, errSN, np.array([a,b,MB, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quasar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataQ = np.loadtxt('data/quasar_data_RL.txt', usecols=(0,1,2,3,4))\n",
    "errQ = np.loadtxt('data/quasar_data_RL.txt', usecols=5)[np.argsort(dataQ.T[0])]\n",
    "dataQ = dataQ[np.argsort(dataQ.T[0])]\n",
    "\n",
    "#best fit values found in Risaliti & Lusso, Nature Astronomy, 2018\n",
    "beta_prime, s = 7.4, 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qdata = Quasar_data(dataQ, errQ, np.array([beta_prime, s]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data points except for WiggleZ\n",
    "dataBAO = np.loadtxt('data/BOSS.txt', usecols=(1,3))\n",
    "# dataBAO = np.loadtxt('data/bao_1806-06781.txt', usecols=(1,3))\n",
    "# add WiggleZ\n",
    "dataBAO = np.append(dataBAO, np.loadtxt('data/WiggleZ.txt', usecols=(1,3)), axis=0)\n",
    "\n",
    "# the error for BAO is a cov mat, due to the addition of the WiggleZ data.\n",
    "errBAO  = np.pad(np.diag(np.loadtxt('data/BOSS.txt', usecols=4)), [(0, 3), (0, 3)], mode='constant', constant_values=0)\n",
    "# errBAO  = np.pad(np.diag(np.loadtxt('data/bao_1806-06781.txt', usecols=4)), [(0, 3), (0, 3)], mode='constant', constant_values=0)\n",
    "\n",
    "# now add the WiggleZ cov mat. Note that this is the sqrt, as all the other errors are given in this format, too.\n",
    "errBAO += np.pad(np.sqrt(np.loadtxt('data/WiggleZ_cov.txt', usecols=(3,4,5))), [(len(errBAO)-3, 0), (len(errBAO)-3, 0)], mode='constant', constant_values=0)\n",
    "\n",
    "typeBAO = np.genfromtxt('data/BOSS.txt',dtype=str, usecols=2)\n",
    "# typeBAO = np.genfromtxt('data/bao_1806-06781.txt',dtype=str, usecols=2)\n",
    "typeBAO = np.append(typeBAO, np.genfromtxt('data/WiggleZ.txt',dtype=str, usecols=2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAOdata = BAO_data(dataBAO, errBAO, np.array([omega_baryon_preset, omega_gamma_preset]), typeBAO)\n",
    "LCDM = cosmology(Omega_m_preset, Omega_c_preset, w=-1, Hzero=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate sound horizon r_s in MPc in comoving coords\n",
    "# -- that is the maximum distance an acoustic wave can travel up to at time of decoupling\n",
    "# depends weakly on omega_b, omega_gamma, and the cosmology\n",
    "BAOdata.com_sound_horizon(1090,LCDM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma00, kappa0 = 0.0093, 95\n",
    "RCdata = RC_data([gamma00, kappa0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: $\\Lambda$LCDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which data sets to include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [SNdata, Qdata, BAOdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_LCDM_min=[0, 0, 125, -5, -10, -30, -.5, 0, 0]\n",
    "ranges_LCDM_max=[1, 1.5, 175, 5, 10, -10, .5, 10, 3]\n",
    "def lnprob_LCDM(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_LCDM_min, ranges_LCDM_max, model = 'LCDM')\n",
    "    return l.logprobability_flat_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_LCDM = [Omega_m_preset, Omega_c_preset, a, b, MB, -0.05, beta_prime, s]\n",
    "\n",
    "BIC_LCDM = lambda theta: np.log(sum([len(d.get_data()) for d in data_sets])) * len(theta) -2*lnprob_LCDM(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = 9, 50, 100\n",
    "pos0 = np.random.uniform(ranges_LCDM_min, ranges_LCDM_max, (nwalkers,len(ranges_LCDM_max)))\n",
    "\n",
    "# pool = Pool(cpu_count())\n",
    "# write = HDFBackend('chains/LCDM_' + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "# sampler = EnsembleSampler(nwalkers, ndim, lnprob_LCDM, pool=pool)#, backend=write)\n",
    "\n",
    "# sampler.run_mcmc(pos0, nsteps, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCDM_sampler = HDFBackend('chains/LCDM' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "# LCDM_sampler = sampler\n",
    "\n",
    "nsteps, nwalkers, ndim = LCDM_sampler.get_chain().shape\n",
    "\n",
    "labs = [r'$\\Omega_m$', r'$\\Omega_\\Lambda$', r'$r_d$', r'$\\alpha$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "while Nmin < nsteps and np.all(LCDM_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCDM_samples = LCDM_sampler.get_chain()\n",
    "\n",
    "f, ax = plt.subplots(len(LCDM_samples.T), 1, figsize=(6,3*len(LCDM_samples.T)))\n",
    "\n",
    "for i in range(len(LCDM_samples.T)):\n",
    "    ax[i].plot(LCDM_samples.T[i].T, lw=0.5)\n",
    "#     ax[i].plot([Nmin, Nmin], [min(LCDM_samples.T[i].flatten()), max(LCDM_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "#     ax[i].text(Nmin, min(LCDM_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/convergence_LCDM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCDM_samples = LCDM_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "meanLCDM = np.mean(LCDM_samples, axis=0)\n",
    "stdLCDM = np.var(LCDM_samples, axis=0)\n",
    "maxLCDM=[]\n",
    "for i in range(len(meanLCDM)):\n",
    "    like = np.histogram(LCDM_samples.T[i], bins=50)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxLCDM.append(max_val)\n",
    "\n",
    "fig = corner(LCDM_samples[:,:2], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "# #              truths=maxLCDM)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/posterior_LCDM' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(LCDM_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "omegam, stdmp, stdmm = v[0]\n",
    "omegac, stdcp, stdcm = v[1]\n",
    "\n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "best_fit_cosmo_LCDM = cosmology(*maxLCDM[:2])\n",
    "SNdata.set_param(v.T[0][2:6])\n",
    "Qdata.set_param(v.T[0][6:])\n",
    "BAOdata.set_param([omega_baryon_preset, omega_gamma_preset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "ax1.set_title('$\\Omega_m = {%1.2f}^{+%1.2f}_{-%1.2f},\\, \\Omega_\\Lambda = {%1.2f}^{+%1.2f}_{-%1.2f}$' % (omegam, stdmp,stdmm, omegac, stdcp,stdcm))#, stdkm, stdkp))\n",
    "\n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=-1, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=-1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)).T[0], BAOdata.distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)).T[1], yerr=BAOdata.delta_distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=-1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_cosmo_LCDM.distance_modulus(zPlot), c='k', label=r'fit')\n",
    "ax1.fill_between(zPlot, cosmology(omegam+stdmp,omegac+stdcp).distance_modulus(zPlot), cosmology(omegam-stdmm,omegac-stdcm).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_cosmo_LCDM.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .94, r'$\\Delta \\mathrm{BIC}(\\Lambda\\mathrm{CDM}) = %1.0f$' % (BIC_LCDM(maxLCDM) - BIC_LCDM(theta_LCDM)), ha='right', va='top', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/Hubble_LCDM' + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCDM_chains = {}\n",
    "LCDM_chains['SN'] = HDFBackend('chains/LCDM_SN_512x1000.h5')\n",
    "LCDM_chains['SN_Q'] = HDFBackend('chains/LCDM_SN_Quasars_512x1000.h5')\n",
    "LCDM_chains['SN_Q_BAO'] = HDFBackend('chains/LCDM_SN_Quasars_BAO_512x1000.h5')\n",
    "LCDM_chains['BAO'] = HDFBackend('chains/LCDM_BAO_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "for sampler in LCDM_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print('Nmin=',Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = LCDM_chains['SN'].get_chain()[Nmin:,:].reshape((-1, LCDM_chains['SN'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:2], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "                labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "                fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "                range=[(0,.6), (0,1.5)])\n",
    "\n",
    "samples = LCDM_chains['SN_Q'].get_chain()[Nmin:,:].reshape((-1, LCDM_chains['SN_Q'].get_chain().shape[-1]))\n",
    "corner(samples[:,:2], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            fig=fig, range=[(0,.6), (0,1.5)])\n",
    "\n",
    "\n",
    "samples = LCDM_chains['SN_Q_BAO'].get_chain()[Nmin:,:].reshape((-1, LCDM_chains['SN_Q_BAO'].get_chain().shape[-1]))\n",
    "corner(samples[:,:2], quantiles=(.16,.84),  levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            fig=fig, range=[(0,.6), (0,1.5)])\n",
    "\n",
    "\n",
    "# samples = LCDM_chains['BAO'].get_chain()[Nmin:,:].reshape((-1, LCDM_chains['SN_Q_BAO'].get_chain().shape[-1]))\n",
    "# corner(samples[:,:2], quantiles=(.16,.84),  levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgray', 'gray'], alpha=0.4),\n",
    "#             fig=fig, range=[(0,.6), (0,1.5)])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/posterior_LCDM.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: $w\\Lambda$LCDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which data sets to include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [SNdata, Qdata, BAOdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_wLCDM_min=[0, 0, 125,  -2.5, -5, -10, -30, -.5, 0, 0]\n",
    "ranges_wLCDM_max=[1, 1.5, 175, -1/3., 5, 10, -10, .5, 10, 3]\n",
    "def lnprob_wLCDM(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_wLCDM_min, ranges_wLCDM_max, model = 'wLCDM')\n",
    "    return l.logprobability_flat_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_wLCDM = lambda theta: np.log(sum([len(d.get_data()) for d in data_sets])) * len(theta) -2*lnprob_wLCDM(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = 10, 20, 100\n",
    "pos0 = np.random.uniform(ranges_wLCDM_min, ranges_wLCDM_max, (nwalkers,len(ranges_wLCDM_max)))\n",
    "\n",
    "pool = Pool(cpu_count())\n",
    "write = HDFBackend('chains/LCDM_' + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "sampler = EnsembleSampler(nwalkers, ndim, lnprob_LCDM, pool=pool)#, backend=write)\n",
    "\n",
    "# tau, accepted = [], []\n",
    "\n",
    "# # Now we'll sample for up to nsteps steps\n",
    "# for i, sample in enumerate(sampler.sample(pos0, iterations=nsteps, progress=True)):\n",
    "#     # Only check convergence every 10 steps\n",
    "#     if sampler.iteration % 10:\n",
    "#         continue\n",
    "\n",
    "#     # Compute the autocorrelation time so far\n",
    "#     # Using tol=0 means that we'll always get an estimate even\n",
    "#     # if it isn't trustworthy\n",
    "#     tau.append(np.mean(sampler.get_autocorr_time(tol=0)))\n",
    "#     accepted.append(np.mean(sampler.acceptance_fraction))\n",
    "# pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wLCDM_sampler = HDFBackend('chains/wLCDM' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "#LCDM_sampler = sampler\n",
    "\n",
    "nsteps, nwalkers, ndim = wLCDM_sampler.get_chain().shape\n",
    "\n",
    "labs = [r'$\\Omega_m$', r'$\\Omega_\\Lambda$', r'$w$', r'$\\alpha$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "while Nmin < nsteps and np.all(wLCDM_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wLCDM_samples = wLCDM_sampler.get_chain()\n",
    "\n",
    "f, ax = plt.subplots(len(wLCDM_samples.T), 1, figsize=(6,3*len(wLCDM_samples.T)))\n",
    "\n",
    "for i in range(len(wLCDM_samples.T)):\n",
    "    ax[i].plot(wLCDM_samples.T[i].T, lw=0.5)\n",
    "    ax[i].plot([Nmin, Nmin], [min(wLCDM_samples.T[i].flatten()), max(wLCDM_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "    ax[i].text(Nmin, min(wLCDM_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/convergence_wLCDM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wLCDM_samples = wLCDM_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "meanwLCDM = np.mean(wLCDM_samples, axis=0)\n",
    "stdwLCDM = np.var(wLCDM_samples, axis=0)\n",
    "maxwLCDM=[]\n",
    "for i in range(len(meanwLCDM)):\n",
    "    like = np.histogram(wLCDM_samples.T[i], bins=50)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxwLCDM.append(max_val)\n",
    "\n",
    "fig = corner(wLCDM_samples[:,:3], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "# #              truths=maxwLCDM)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/posterior_wLCDM' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(wLCDM_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "omegam, stdmp, stdmm = v[0]\n",
    "omegac, stdcp, stdcm = v[1]\n",
    "w, wp, wm = v[4]\n",
    "\n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "omegam, omegac, w = maxwLCDM[0], maxwLCDM[1], maxwLCDM[2]\n",
    "best_fit_cosmo = cosmology(omegam, omegac, w=w)\n",
    "SNdata.set_param(v.T[0][-6:-2])\n",
    "Qdata.set_param(v.T[0][-2:])\n",
    "BAOdata.set_param([omega_baryon_preset, omega_gamma_preset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "ax1.set_title(r'$\\Omega_m = {%1.2f}^{+%1.2f}_{-%1.2f},\\, \\Omega_\\Lambda = {%1.2f}^{+%1.2f}_{-%1.2f},\\, w = {%1.2f}^{+%1.2f}_{-%1.2f}$' % (omegam, stdmp,stdmm, omegac, stdcp,stdcm, w, wp, wm))#, stdkm, stdkp))\n",
    "\n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=-1, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=-1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)).T[0], BAOdata.distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)).T[1], yerr=BAOdata.delta_distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=-1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_cosmo.distance_modulus(zPlot), c='k', label=r'fit')\n",
    "ax1.fill_between(zPlot, cosmology(omegam+stdmp,omegac+stdcp, w=w + wp).distance_modulus(zPlot), cosmology(omegam-stdmm,omegac-stdcm,w=w - wm).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_cosmo_LCDM.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .94, r'$\\mathrm{BIC}(\\Lambda\\mathrm{CDM}) = %1.0f$' % (BIC_wLCDM(maxwLCDM) - BIC_LCDM(theta_LCDM)), ha='right', va='top', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/Hubble_wLCDM' + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wLCDM_chains = {}\n",
    "wLCDM_chains['SN'] = HDFBackend('chains/wLCDM_SN_512x1000.h5')\n",
    "wLCDM_chains['SN_Q'] = HDFBackend('chains/wLCDM_SN_Quasars_512x1000.h5')\n",
    "wLCDM_chains['SN_Q_BAO'] = HDFBackend('chains/wLCDM_SN_Quasars_BAO_512x1000.h5')\n",
    "wLCDM_chains['BAO'] = HDFBackend('chains/wLCDM_BAO_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "for sampler in wLCDM_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print('Nmin=',Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = wLCDM_chains['SN'].get_chain()[Nmin:,:].reshape((-1, wLCDM_chains['SN'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:3], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "                labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "                fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "                range=[(0,1), (0,1.6), (-2,-.5)])\n",
    "\n",
    "samples = wLCDM_chains['SN_Q'].get_chain()[Nmin:,:].reshape((-1, wLCDM_chains['SN_Q'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:3], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            fig=fig, range=[(0,1), (0,1.6), (-2,-.5)])\n",
    "\n",
    "\n",
    "samples = wLCDM_chains['SN_Q_BAO'].get_chain()[Nmin:,:].reshape((-1, wLCDM_chains['SN_Q_BAO'].get_chain().shape[-1]))\n",
    "corner(samples[:,:3], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            fig=fig, range=[(0,1), (0,1.6), (-2,-.5)])\n",
    "\n",
    "# samples = wLCDM_chains['BAO'].get_chain()[Nmin:,:].reshape((-1, wLCDM_chains['SN_Q_BAO'].get_chain().shape[-1]))\n",
    "# corner(samples[:,:3], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgray', 'gray'], alpha=0.4),\n",
    "#             fig=fig, range=[(0,1), (0,1.6), (-2,-.5)])\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/posterior_wLCDM.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Bigravity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which data sets to include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [SNdata, Qdata, BAOdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_bigravity_min=[-33., 0,0, 125, -5, -10, -30, -.5, 0, 0]\n",
    "ranges_bigravity_max=[-28., np.pi/2., 1, 175, 5, 10, -10, .5, 10, 3]\n",
    "def lnprob_bigravity(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_bigravity_min, ranges_bigravity_max, model = 'bigravity')\n",
    "    return l.logprobability_flat_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_bigravity = lambda theta: np.log(sum([len(d.get_data()) for d in data_sets])) * len(theta) -2*lnprob_bigravity(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = len(ranges_bigravity_min), 20, 100\n",
    "pos0 = np.random.uniform(ranges_bigravity_min, ranges_bigravity_max, (nwalkers,len(ranges_bigravity_max)))\n",
    "\n",
    "pool = Pool(cpu_count())\n",
    "write = HDFBackend('chains/bigravity_' + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "sampler = EnsembleSampler(nwalkers, ndim, lnprob_bigravity, pool=pool)#, backend=write)\n",
    "\n",
    "# tau, accepted = [], []\n",
    "\n",
    "# # Now we'll sample for up to nsteps steps\n",
    "# for i, sample in enumerate(sampler.sample(pos0, iterations=nsteps, progress=True)):\n",
    "#     # Only check convergence every 10 steps\n",
    "#     if sampler.iteration % 10:\n",
    "#         continue\n",
    "\n",
    "#     # Compute the autocorrelation time so far\n",
    "#     # Using tol=0 means that we'll always get an estimate even\n",
    "#     # if it isn't trustworthy\n",
    "#     tau.append(np.mean(sampler.get_autocorr_time(tol=0)))\n",
    "#     accepted.append(np.mean(sampler.acceptance_fraction))\n",
    "# pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigravity_sampler = HDFBackend('chains/bigravity' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "#LCDM_sampler = sampler\n",
    "\n",
    "nsteps, nwalkers, ndim = bigravity_sampler.get_chain().shape\n",
    "\n",
    "if ndim == 9:\n",
    "    labs = [r'$\\log_{10} (m_g/\\mathrm{eV})$', r'$\\theta$', r'$\\Omega_m$', r'$\\alpha$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']\n",
    "elif ndim >9:\n",
    "    labs = np.insert(labs, 2, [r'$\\beta_0$', r'$\\beta_1$', r'$\\beta_2$', r'$\\beta_3$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "while Nmin < nsteps and np.all(bigravity_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit_bigravitycosmo.get_energy_densities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigravity_samples = bigravity_sampler.get_chain()\n",
    "\n",
    "f, ax = plt.subplots(len(bigravity_samples.T), 1, figsize=(6,3*len(bigravity_samples.T)))\n",
    "\n",
    "for i in range(len(bigravity_samples.T)):\n",
    "    ax[i].plot(bigravity_samples.T[i].T, lw=0.5)\n",
    "    ax[i].plot([Nmin, Nmin], [min(bigravity_samples.T[i].flatten()), max(bigravity_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "    ax[i].text(Nmin, min(bigravity_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/convergence_bigravity.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigravity_samples = bigravity_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "meanbigravity = np.mean(bigravity_samples, axis=0)\n",
    "stdbigravity = np.var(bigravity_samples, axis=0)\n",
    "maxbigravity=[]\n",
    "for i in range(len(meanbigravity)):\n",
    "    like = np.histogram(bigravity_samples.T[i], bins=50)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxbigravity.append(max_val)\n",
    "\n",
    "fig = corner(bigravity_samples[:,:3], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "# #              truths=maxbigravity)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/posterior_bigravity' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(bigravity_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "log10m, stdmp, stdmm = v[0]\n",
    "theta, stdtp, stdtm = v[1]\n",
    "if ndim == 9:\n",
    "    b0, b1, b2, b3 = 1.,1.,-1.,1.\n",
    "elif ndim >=9:\n",
    "    b0, b1, b2, b3 = v[2:6].T[0]\n",
    "\n",
    "omegam, stdmp, stdmm = v[-7]\n",
    "\n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "best_fit_bigravitycosmo = bigravity_cosmology(maxbigravity[0], maxbigravity[1], b0, b1, b2, b3, maxbigravity[-7])\n",
    "SNdata.set_param(v.T[0][-6:-2])\n",
    "Qdata.set_param(v.T[0][-2:])\n",
    "BAOdata.set_param([omega_baryon_preset, omega_gamma_preset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "ax1.set_title(r'$\\Omega_m = {%1.2f}^{+%1.2f}_{-%1.2f},\\, m_g = 10^{{%1.2f}^{+%1.2f}_{-%1.2f}}\\mathrm{eV},\\, \\theta = {%1.2f}^{+%1.2f}_{-%1.2f}$' % (omegam, stdmp, stdmm, log10m, stdmm, stdmp, theta, stdtm, stdtp))#, stdkm, stdkp))\n",
    "\n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=-1, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=-1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)).T[0], BAOdata.distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)).T[1], yerr=BAOdata.delta_distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=-1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_bigravitycosmo.distance_modulus(zPlot), c='k', label=r'fit')\n",
    "ax1.fill_between(zPlot, bigravity_cosmology(log10m+stdmp, theta + stdtp, b0,b1,b2,b3, omegam + stdmp).distance_modulus(zPlot), bigravity_cosmology(log10m-stdmm, theta - stdtm, b0,b1,b2,b3, omegam - stdmm).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_bigravitycosmo.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .94, r'$\\Delta \\mathrm{BIC}(\\mathrm{bigravity}) = %1.0f$' % (BIC_bigravity(maxbigravity) - BIC_LCDM(theta_LCDM)), ha='right', va='top', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/Hubble_bigravity' + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigravity_chains = {}\n",
    "bigravity_chains['SN'] = HDFBackend('chains/bigravity_SN_512x1000.h5')\n",
    "bigravity_chains['SN_Q'] = HDFBackend('chains/bigravity_SN_Quasars_512x1000.h5')\n",
    "# bigravity_chains['SN_Q_BAO'] = HDFBackend('chains/bigravity_SN_Quasars_BAO_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "for sampler in bigravity_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print(\"Nmin = \", Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = bigravity_samples#bigravity_chains['SN'].get_chain()[Nmin:,:].reshape((-1, bigravity_chains['SN'].get_chain().shape[-1]))\n",
    "fig=corner(samples, quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "                labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "                fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']))\n",
    "#                 range=[(0,1), (0,1.3), (-2,-.5)])\n",
    "\n",
    "# samples = bigravity_chains['SN_Q'].get_chain()[Nmin:,:].reshape((-1, bigravity_chains['SN_Q'].get_chain().shape[-1]))\n",
    "# corner(samples[:,:3], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6))\n",
    "# #             fig=fig, range=[(0,1), (0,1.3), (-2,-.5)])\n",
    "\n",
    "\n",
    "# samples = bigravity_chains['SN_Q_BAO'].get_chain()[Nmin:,:].reshape((-1, bigravity_chains['SN_Q_BAO'].get_chain().shape[-1]))\n",
    "# corner(samples[:,:3], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "#             fig=fig, range=[(0,1), (0,1.3), (-2,-.5)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/posterior_bigravity.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: Conformal Gravity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which data sets to include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [SNdata, Qdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_conformal_min=[0, 50, 125, -5, -10, -30, -.5, 0, 0]\n",
    "ranges_conformal_max=[.01, 300, 175, 5, 10, -10, .5, 10, 3]\n",
    "def lnprob_conformal(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_conformal_min, ranges_conformal_max, model = 'conformal')\n",
    "    return l.logprobability_flat_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_conformal = lambda theta: np.log(sum([len(d.get_data()) for d in data_sets])) * len(theta) -2*lnprob_conformal(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = len(ranges_conformal_min), 20, 100\n",
    "pos0 = np.random.uniform(ranges_conformal_min, ranges_conformal_max, (nwalkers,len(ranges_conformal_max)))\n",
    "\n",
    "pool = Pool(cpu_count())\n",
    "write = HDFBackend('chains/LCDM_' + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "sampler = EnsembleSampler(nwalkers, ndim, lnprob_conformal, pool=pool)#, backend=write)\n",
    "\n",
    "# tau, accepted = [], []\n",
    "\n",
    "# # Now we'll sample for up to nsteps steps\n",
    "# for i, sample in enumerate(sampler.sample(pos0, iterations=nsteps, progress=True)):\n",
    "#     # Only check convergence every 10 steps\n",
    "#     if sampler.iteration % 10:\n",
    "#         continue\n",
    "\n",
    "#     # Compute the autocorrelation time so far\n",
    "#     # Using tol=0 means that we'll always get an estimate even\n",
    "#     # if it isn't trustworthy\n",
    "#     tau.append(np.mean(sampler.get_autocorr_time(tol=0)))\n",
    "#     accepted.append(np.mean(sampler.acceptance_fraction))\n",
    "# pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_sampler = HDFBackend('chains/conformal' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "#LCDM_sampler = sampler\n",
    "\n",
    "nsteps, nwalkers, ndim = conformal_sampler.get_chain().shape\n",
    "\n",
    "labs=[r'$(\\gamma_0/\\mathrm{Gpc}^{-1})$', r'$(\\kappa/\\mathrm{Gpc}^{-2})$',r'$\\alpha$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "while Nmin < nsteps and np.all(conformal_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_samples = conformal_sampler.get_chain()\n",
    "\n",
    "f, ax = plt.subplots(len(conformal_samples.T), 1, figsize=(6,3*len(conformal_samples.T)))\n",
    "\n",
    "for i in range(len(conformal_samples.T)):\n",
    "    ax[i].plot(conformal_samples.T[i].T, lw=0.5)\n",
    "    ax[i].plot([Nmin, Nmin], [min(conformal_samples.T[i].flatten()), max(conformal_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "    ax[i].text(Nmin, min(conformal_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/convergence_conformal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_samples = conformal_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "meanconformal = np.mean(conformal_samples, axis=0)\n",
    "stdconformal = np.var(conformal_samples, axis=0)\n",
    "maxconformal=[]\n",
    "for i in range(len(meanconformal)):\n",
    "    like = np.histogram(conformal_samples.T[i], bins=50)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxconformal.append(max_val)\n",
    "\n",
    "fig = corner(conformal_samples, quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "# #              truths=maxconformal)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/posterior_conformal' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(conformal_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "gamma0, gamm0p, gamma0m = v[0]\n",
    "kappa, kappap, kappam = v[1]\n",
    "\n",
    "omegak =  (gamma0)**2 / 2 * cosmology.cLight**2/(70./1E-3)**2#Gpc^-1\n",
    "stdkp, stdkm = np.array([gamm0p, gamma0m]) * (gamma0) * cosmology.cLight**2/(70./1E-3)**2#Gpc^-1\n",
    "\n",
    "omegac = 1 - omegak\n",
    "stdcp = stdkm\n",
    "stdcm = stdkp\n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "\n",
    "best_fit_conformalcosmo = cosmology(0, omegac)\n",
    "SNdata.set_param(v.T[0][2:6])\n",
    "Qdata.set_param(v.T[0][6:8])\n",
    "BAOdata.set_param([omega_baryon_preset, omega_gamma_preset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "ax1.set_title(r'$\\Omega_\\Lambda = {%1.3f}^{+%1.3f}_{-%1.3f},\\, \\Omega_K = {%1.3f}^{+%1.3f}_{-%1.3f}$' % (omegac, stdcp,stdcm, omegak, stdkm, stdkp))\n",
    "\n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=-1, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=-1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)).T[0], BAOdata.distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)).T[1], yerr=BAOdata.delta_distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=-1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_conformalcosmo.distance_modulus(zPlot), c='k', label=r'fit')\n",
    "ax1.fill_between(zPlot, cosmology(0,omegac+stdcp).distance_modulus(zPlot), cosmology(0,omegac-stdcm).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_conformalcosmo.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .94, r'$\\mathrm{BIC}(\\Lambda\\mathrm{CDM}) = %1.0f$' % (BIC_conformal(maxconformal) - BIC_LCDM(theta_LCDM)), ha='right', va='top', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/Hubble_wLCDM' + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_chains = {}\n",
    "conformal_chains['SN'] = HDFBackend('chains/conformal_SN_512x1000.h5')\n",
    "conformal_chains['SN_Q'] = HDFBackend('chains/conformal_SN_Quasars_512x1000.h5')\n",
    "# conformal_chains['SN_Q_BAO'] = HDFBackend('chains/conformal_SN_Quasars_BAO_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "for sampler in conformal_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print('Nmin=',Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = conformal_chains['SN'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['SN'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:3], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "                labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "                fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "                range=[(0,1), (0,1.3), (-2,-.5)])\n",
    "\n",
    "samples = conformal_chains['SN_Q'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['SN_Q'].get_chain().shape[-1]))\n",
    "corner(samples[:,:3], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            fig=fig, range=[(0,1), (0,1.3), (-2,-.5)])\n",
    "\n",
    "\n",
    "# samples = conformal_chains['SN_Q_BAO'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['SN_Q_BAO'].get_chain().shape[-1]))\n",
    "# corner(samples[:,:3], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "#             fig=fig, range=[(0,1), (0,1.3), (-2,-.5)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/posterior_conformal.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation curve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log10gamma0, log10kappa0 = -6, -4\n",
    "RCdata = RC_data([10**log10gamma0, 10**log10kappa0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#likelihood function\n",
    "def lnlikeCG(theta, SNdata, Qdata, RCdata, BAOdata):\n",
    "    Omegam, gamma0, kappa, a, b, MB, delta_Mhost, beta_prime, s = theta\n",
    "    \n",
    "    Omegak =  (gamma0)**2 / 2 *cosmology.cLight**2/(70/1E-3)**2\n",
    "    Omegac = 1-Omegam-Omegak\n",
    "    \n",
    "    LCDM = cosmology(Omegam, Omegac)\n",
    "    SNdata.set_param(np.array([a,b,MB, delta_Mhost]))\n",
    "    Qdata.set_param(np.array([beta_prime, s]))\n",
    "    \n",
    "    log_prob = LCDM.log_likelihood(SNdata)\n",
    "    log_prob += LCDM.log_likelihood(Qdata)\n",
    "    log_prob += LCDM.log_likelihood(BAOdata)\n",
    "    \n",
    "    if np.isnan(log_prob):\n",
    "        return -np.inf\n",
    "\n",
    "    RCdata.set_param([gamma0, kappa])\n",
    "    RCdata.fit()\n",
    "    log_prob += RCdata.get_loglike()\n",
    "\n",
    "\n",
    "    return log_prob\n",
    "\n",
    "\n",
    "def lnpriorCG(theta):\n",
    "    Omegam, gamma0, kappa, a, b, MB, delta_Mhost, beta_prime, s = theta\n",
    "    \n",
    "    Omegak =  (gamma0)**2 / 2 *cosmology.cLight**2/(70./1E-3)**2\n",
    "    Omegac = 1-Omegam-Omegak\n",
    "\n",
    "    if -.1 < Omegam < 0 and 0 < Omegak < 1.0 and gamma0 > 0 and 0 < kappa < 1000 and -5 <= a < 5 and -10 < b < 10 and -50 < MB < 0 and -0.5 < delta_Mhost < 0.5 and 0 < s <= 3:\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "def lnprobCG(theta, SNdata, Qdata, RCdata):\n",
    "    lp = lnpriorCG(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlikeCG(theta, SNdata, Qdata, RCdata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Conformal Gravity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG_sampler = HDFBackend('chains/CG_nonlog_500x1000.h5', read_only=True)\n",
    "\n",
    "nsteps, nwalkers, ndim = CG_sampler.get_chain().shape\n",
    "labs=[r'$\\Omega_m$', r'$(\\gamma_0/\\mathrm{Gpc}^{-1})$', r'$(\\kappa/\\mathrm{Gpc}^{-2})$',r'$\\alpha$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 0\n",
    "while Nmin < nsteps and np.all(CG_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*50 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG_samples = CG_sampler.get_chain()\n",
    "\n",
    "f, ax = plt.subplots(len(CG_samples.T), 1, figsize=(6,3*len(CG_samples.T)))\n",
    "\n",
    "for i in range(len(CG_samples.T)):\n",
    "    ax[i].plot(CG_samples.T[i].T, lw=0.5)\n",
    "    ax[i].plot([Nmin, Nmin], [min(CG_samples.T[i].flatten()), max(CG_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "    ax[i].text(Nmin, min(CG_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/convergence_CG.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG_samples = CG_sampler.get_chain()[Nmin:, :, :].reshape((-1, ndim))\n",
    "\n",
    "#plot Omega_k instead of gamma0\n",
    "CG_samples[:,1] = CG_samples[:,1]**2 / 2 *cosmology.cLight**2/(70./1E-3)**2\n",
    "labs[1] = r'$\\Omega_k$'\n",
    "\n",
    "\n",
    "meanCG = np.mean(CG_samples, axis=0)\n",
    "stdCG = np.var(CG_samples, axis=0)\n",
    "maxCG=[]\n",
    "for i in range(len(meanCG)):\n",
    "    likelihood = np.histogram(CG_samples.T[i], bins=50)\n",
    "    i_max=np.argmax(likelihood[0])\n",
    "    max_val = (likelihood[1][i_max]+likelihood[1][i_max+1])/2\n",
    "    maxCG.append(max_val)\n",
    "\n",
    "fig = corner(CG_samples, quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),# range=[(-.005, 0), (.0222,.0226), (71,73)],\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'),\n",
    "             truths=maxCG)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/posterior_CG.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(CG_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "omegam, stdmp, stdmm = v[0]\n",
    "omegak, stdkp, stdkm  = v[1]\n",
    "\n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "best_fit_cosmo = cosmology(omegam, 1- omegam - omegak)\n",
    "SNdata.set_param(maxCG[3:7])\n",
    "Qdata.set_param(maxCG[7:])\n",
    "RC_data.set_param(maxCG[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "ax1.set_title(r'$\\Omega_m = ({%1.2f}^{+%1.2f}_{-%1.2f})\\cdot 10^{-3},\\, \\Omega_k = ({%1.2f}^{+%1.2f}_{-%1.2f})\\cdot 10^{-4},\\, \\kappa = {%1.1f}^{+%1.1f}_{-%1.1f}\\, \\mathrm{Gpc}^{-2}$' % (1E3*omegam, 1E3*stdmp,1E3*stdmm, 1E4*omegak, 1E4*stdkp,1E4*stdkm, *v[2]), fontsize=16)#, stdkm, stdkp))\n",
    "\n",
    "ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=-1, label=r'quasars')\n",
    "ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=np.diag(SNdata.delta_distance_modulus()), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=-1, label=r'SNe')\n",
    "ax1.errorbar(BAOdata.distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)).T[0], BAOdata.distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)).T[1], yerr=BAOdata.delta_distance_modulus(cosmology(Omega_m_preset, Omega_c_preset, Omega_r_preset)), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=-1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_cosmo.distance_modulus(zPlot), c='k', label=r'fit')\n",
    "ax1.fill_between(zPlot, cosmology(omegam+stdmp,1- (omegam - stdmm) - (omegak-stdkm)).distance_modulus(zPlot), cosmology(omegam-stdmm,1- (omegam + stdmp) - (omegak+stdkp)).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "# ax1.set_xlim(0.01,6)\n",
    "# ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_cosmo.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.04, .94, r'$\\mathrm{BIC}(\\mathrm{CG}) = %1.0f$' % (np.log(len(SNdata.get_data()) + len(Qdata.get_data()))*ndim-2*(lnlikeCG(maxCG,SNdata,Qdata,RC_data,BAOdata) - RC_data.get_loglike())), ha='left', va='top', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/Hubble_CG.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:emcee3]",
   "language": "python",
   "name": "conda-env-emcee3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
