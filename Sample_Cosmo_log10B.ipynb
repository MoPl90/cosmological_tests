{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', size=18,family='serif')\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from emcee import EnsembleSampler\n",
    "from emcee.backends import HDFBackend\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from corner import corner\n",
    "from Cosmology_log10B import *\n",
    "import sys\n",
    "\n",
    "\n",
    "#load autoreload, which automatically reloads the cosmology.py upon execution\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport Cosmology_log10B\n",
    "\n",
    "\n",
    "#Parameters for BAO and CMB\n",
    "h = .6727\n",
    "cLight=3E5\n",
    "omega_baryon_preset = 0.02235/h**2\n",
    "omega_gamma_preset = 2.469E-5/h**2\n",
    "\n",
    "#Cosmological parameters\n",
    "Omega_m_preset = 0.3166\n",
    "#Omega_r_preset = 2.469E-5/h**2 # this is the photon density\n",
    "Omega_c_preset = 0.6834\n",
    "\n",
    "#Whether to use the numerical approximation for the comoving sound horizon, see arXiv:1411.1074:\n",
    "#(we use rd analytical)\n",
    "rd_num = False\n",
    "#Whether to use the numerical approximation for the redshift of recombination,\n",
    "#cf arXiv:1808.05724, or use z_d = z_star = 1089:\n",
    "#(we use the numerical approx for z_star and z_d)\n",
    "z_num = True\n",
    "\n",
    "LCDM = cosmology(Omega_m_preset, Omega_c_preset, omegab=omega_baryon_preset, Hzero=100.*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check versions of packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda list matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda list ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JLA Supernova data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSN = np.loadtxt('data/jla_lcparams.txt', usecols=(2,4,6,8,10))\n",
    "errSN = np.loadtxt('data/jla_lcparams.txt', usecols=(5,7,9))[np.argsort(dataSN.T[0])]\n",
    "dataSN = dataSN[np.argsort(dataSN.T[0])]\n",
    "\n",
    "#best fit values found in JLA analysis arXiv:1401.4064\n",
    "a = 0.14\n",
    "b = 3.14\n",
    "MB = -19.04\n",
    "delta_Mhost = -.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNdata = Supernova_data(dataSN, errSN, np.array([a,b,MB, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quasar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataQ = np.loadtxt('data/quasar_data_RL.txt', usecols=(0,1,2,3,4))\n",
    "errQ = np.loadtxt('data/quasar_data_RL.txt', usecols=5)[np.argsort(dataQ.T[0])]\n",
    "dataQ = dataQ[np.argsort(dataQ.T[0])]\n",
    "\n",
    "#best fit values found in Risaliti & Lusso, Nature Astronomy, 2018\n",
    "beta_prime, s = 7.4, 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qdata = Quasar_data(dataQ, errQ, np.array([beta_prime, s]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load BOSS data points\n",
    "dataBAO = np.loadtxt('data/BOSS.txt', usecols=(1,3))\n",
    "#load BOSS errors & measurement quantity\n",
    "errBAO  = np.diag(np.loadtxt('data/BOSS.txt', usecols=4))\n",
    "typeBAO = np.genfromtxt('data/BOSS.txt',dtype=str, usecols=2)\n",
    "zdBAO = np.genfromtxt('data/BOSS.txt', usecols=6)\n",
    "\n",
    "#BOSS DR12 covariance matrix from 1607.03155\n",
    "sigmaDR12 = np.diag(np.diag(errBAO)[np.where(np.loadtxt('data/BOSS.txt', usecols=0, dtype=str) == 'BOSS_DR12')])\n",
    "corrDR12 = np.tril(np.loadtxt('data/BOSS_DR12_cov.txt', usecols=(1,2,3,4,5,6))*1E-4)\n",
    "corrDR12 += corrDR12.T\n",
    "corrDR12 -= np.eye(len(corrDR12))\n",
    "CovDR12 = np.dot(sigmaDR12, np.dot(corrDR12, sigmaDR12))\n",
    "\n",
    "#eBOSS Quasar covariance matrix from 1801.03043\n",
    "sigmaeBOSS = np.diag(np.diag(errBAO)[np.where(np.loadtxt('data/BOSS.txt', usecols=0, dtype=str) == 'eBOSS_QSO')])\n",
    "correBOSS = np.triu(np.loadtxt('data/eBOSS_QSO_cov.txt', usecols=(1,2,3,4,5,6,7,8))*1E-4)\n",
    "correBOSS += correBOSS.T\n",
    "correBOSS -= np.eye(len(correBOSS[0]))\n",
    "CoveBOSS = np.dot(sigmaeBOSS, np.dot(correBOSS, sigmaeBOSS))\n",
    "\n",
    "#assemble the full covariance matrix\n",
    "load_cov = np.diag([1 if i else 0 for i in np.loadtxt('data/BOSS.txt',usecols=5)==1]) \n",
    "CovBAO = (errBAO - np.dot(load_cov,errBAO))**2\n",
    "#CovBAO = (errBAO)**2\n",
    "CovBAO += np.pad(CovDR12,[(2,len(errBAO)-2-len(CovDR12)),(2,len(errBAO)-2-len(CovDR12))], mode='constant', constant_values=0)\n",
    "CovBAO += np.pad(CoveBOSS,[(2 + len(CovDR12) + 1,len(errBAO)- 3 - len(CovDR12) - len(CoveBOSS)),(2 + len(CovDR12) + 1,len(errBAO)- 3 - len(CovDR12) - len(CoveBOSS))], mode='constant', constant_values=0)\n",
    "\n",
    "#Finally, add the correlations given in 1904.03430 \n",
    "add_cov = np.array([i if i<0 else 0 for i in np.loadtxt('data/BOSS.txt',usecols=5)])\n",
    "Cov = np.pad(np.diag(add_cov[1:]), [(1,0),(0,1)], mode='constant', constant_values=0) + np.pad(np.diag(add_cov[1:]), [(0,1), (1,0)], mode='constant', constant_values=0)\n",
    "for ind in np.array([np.where(add_cov<0)[0]-1., np.where(add_cov<0)[0]], dtype=int).T:\n",
    "    Cov[ind] = Cov[ind] * np.diag(errBAO)[ind[0]] * np.diag(errBAO)[ind[1]]\n",
    "    \n",
    "CovBAO += Cov\n",
    "\n",
    "BAOdata = BAO_data(dataBAO, CovBAO, typeBAO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load all data points except for WiggleZ\n",
    "# dataBAO = np.loadtxt('data/BOSS.txt', usecols=(1,3))\n",
    "# # dataBAO = np.loadtxt('data/bao_1806-06781.txt', usecols=(1,3))\n",
    "# # add WiggleZ\n",
    "# dataBAO = np.append(dataBAO, np.loadtxt('data/WiggleZ.txt', usecols=(1,3)), axis=0)\n",
    "\n",
    "# # the error for BAO is a cov mat, due to the addition of the WiggleZ data.\n",
    "# errBAO  = np.pad(np.diag(np.loadtxt('data/BOSS.txt', usecols=4)), [(0, 3), (0, 3)], mode='constant', constant_values=0)\n",
    "# # errBAO  = np.pad(np.diag(np.loadtxt('data/bao_1806-06781.txt', usecols=4)), [(0, 3), (0, 3)], mode='constant', constant_values=0)\n",
    "\n",
    "# # now add the WiggleZ cov mat. Note that this is the sqrt, as all the other errors are given in this format, too.\n",
    "# errBAO += np.pad(np.sqrt(np.loadtxt('data/WiggleZ_cov.txt', usecols=(3,4,5))), [(len(errBAO)-3, 0), (len(errBAO)-3, 0)], mode='constant', constant_values=0)\n",
    "\n",
    "# typeBAO = np.genfromtxt('data/BOSS.txt',dtype=str, usecols=2)\n",
    "# # typeBAO = np.genfromtxt('data/bao_1806-06781.txt',dtype=str, usecols=2)\n",
    "# typeBAO = np.append(typeBAO, np.genfromtxt('data/WiggleZ.txt',dtype=str, usecols=2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma00, kappa0 = 0.0093, 95\n",
    "RCdata = RC_data([gamma00, kappa0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planck 2018 CMB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planck18 distance priors are model dependent. Therefore they are defined in the model sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 0: $\\Lambda$LCDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which data sets to include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'LCDM'\n",
    "CMBdata = CMB_data(model, 'Planck18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the data sets to use (from SNdata, Qdata, BAOdata, CMBdata)\n",
    "data_sets = [SNdata, Qdata, BAOdata, CMBdata]\n",
    "#data_sets = [CMBdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the likelihood and priors\n",
    "ranges_LCDM_min=[0, 0, 60., -5, -10, -30, -.5, 0, 0]\n",
    "ranges_LCDM_max=[1, 0.1, 80., 5, 10, -10, .5, 10, 3]\n",
    "def lnprob_LCDM(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_LCDM_min, ranges_LCDM_max, model = 'LCDM', rd_num = rd_num, z_num = z_num)\n",
    "    #l.get_settings() #returns the settings z_num, rd_num of the given likelihood\n",
    "    #use only the flat priors with ranges defined above...\n",
    "    #return l.logprobability_flat_prior()\n",
    "    #... or add also the Gaussian prior from BBN:\n",
    "    return l.logprobability_gauss_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_LCDM = [Omega_m_preset, omega_baryon_preset, 67.27, a, b, MB, -0.05, beta_prime, s]\n",
    "\n",
    "# calculates the BIC for LCDM: in this case, we compare to the preset values. The BIC is a function of the data set:\n",
    "BIC_LCDM = lambda theta, data_sets_var: np.log(sum([len(d.get_data()) for d in data_sets_var])) * len(theta) -2*lnprob_LCDM(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = 9, 512, 1000\n",
    "pos0 = np.random.uniform(ranges_LCDM_min, ranges_LCDM_max, (nwalkers,len(ranges_LCDM_max)))\n",
    "\n",
    "#pool = Pool(cpu_count())\n",
    "#write = HDFBackend('chains/testing/LCDM' + data_sets_str + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "#sampler = EnsembleSampler(nwalkers, ndim, lnprob_LCDM, pool=pool)#, backend=write)\n",
    "\n",
    "#sampler.run_mcmc(pos0, nsteps, progress=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCDM_sampler = HDFBackend('chains/LCDM' + data_sets_str + str(nwalkers) + 'x' + str(nsteps) + '.h5', read_only=True)\n",
    "#LCDM_sampler = sampler\n",
    "\n",
    "nsteps, nwalkers, ndim = LCDM_sampler.get_chain().shape\n",
    "\n",
    "labs = [r'$\\Omega_m$', r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$\\alpha^\\prime$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "while Nmin < nsteps and np.all(LCDM_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCDM_samples = LCDM_sampler.get_chain()\n",
    "\n",
    "# Delete walkers which haven't moved from initiatial position:\n",
    "\n",
    "dellist = np.unique(np.where(np.isclose(LCDM_samples[-1] - LCDM_samples[0], 0))[0])\n",
    "LCDM_samples = np.delete(LCDM_samples, np.unique(dellist), axis=1)\n",
    "\n",
    "# plot the convergence:\n",
    "\n",
    "f, ax = plt.subplots(len(LCDM_samples.T), 1, figsize=(6,3*len(LCDM_samples.T)))\n",
    "\n",
    "for i in range(len(LCDM_samples.T)):\n",
    "    ax[i].plot(LCDM_samples.T[i].T, lw=0.5)\n",
    "    ax[i].plot([Nmin, Nmin], [min(LCDM_samples.T[i].flatten()), max(LCDM_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "    ax[i].text(Nmin, min(LCDM_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "#plt.savefig('plots/convergence_LCDM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCDM_samples = LCDM_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "meanLCDM = np.mean(LCDM_samples, axis=0)\n",
    "stdLCDM = np.var(LCDM_samples, axis=0)\n",
    "maxLCDM=[]\n",
    "for i in range(len(meanLCDM)):\n",
    "    like = np.histogram(LCDM_samples.T[i], bins=1000)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxLCDM.append(max_val)\n",
    "\n",
    "# LCDM_samples[:,0] = LCDM_samples[:,0] * LCDM_samples[:,2]**2 / 100**2\n",
    "\n",
    "\n",
    "fig = corner(LCDM_samples[:,:3], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)), range=[(0.28,0.35),(0.01,0.08), (64,70)],\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=20, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "#              truths=maxLCDM)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig('plots/LCDM' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(LCDM_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "omegam, stdmp, stdmm = v[0]\n",
    "\n",
    "omegab, stdbp, stdbm = v[1]\n",
    "H0, stdhp, stdhm = v[2]\n",
    "    \n",
    "    \n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "best_fit_cosmo_LCDM = cosmology(omegam=maxLCDM[0],omegac=1-maxLCDM[0], omegab = maxLCDM[1], Hzero=maxLCDM[2], z_num = z_num, rd_num=rd_num)\n",
    "SNdata.set_param(v.T[0][-6:-2])\n",
    "Qdata.set_param(v.T[0][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_m = .3*(1+z)**3\n",
    "rho_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the energy densities over time for LCDM best fit\n",
    "\n",
    "z = np.arange(0.01, 20000.0, .1)\n",
    "rho_m = .3*(1+z)**3\n",
    "rho_CC = .7 * z**0\n",
    "rho_r = omega_gamma_preset*(1 + 7/8 * (4/11)**(4/3) * 3.046) *(1+z)**4\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.loglog(z, rho_m, label=r'matter')\n",
    "ax.loglog(z, rho_r, label=r'$\\Omega_r(z)$')\n",
    "ax.loglog(z, rho_CC, label=r'$\\Omega_\\Lambda(z)$')\n",
    "\n",
    "#ax.set_title('$\\\\Omega_i(z)$ of $\\Lambda$CDM ', fontsize=18)\n",
    "\n",
    "ax.set(xlabel='z')\n",
    "ax.set_xlim(0.01,20000)\n",
    "#ax1.set_ylabel(r'\\\\Omega(z)$ of $\\Lambda$CDM')\n",
    "#ax.set_ylim(.01,20000)\n",
    "#plt.yticks((.001,.1,10,1000,100000,10000000))\n",
    "#plt.xticks((.1,1,10,100,1000,10000))\n",
    "#ax.get_xaxis().set_major_formatter(FormatStrFormatter())\n",
    "ax.yaxis.set_minor_formatter(FormatStrFormatter('%.0f'))\n",
    "ax.grid('--',which='major',axis='x', dashes=(5,5))\n",
    "ax.grid('--',which='both',axis='y', dashes=(5,5))\n",
    "ax.legend()\n",
    "\n",
    "#ax.grid('--', dashes=(5,5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCDM.z_star()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_lcdm = BIC_LCDM(v.T[0],data_sets)\n",
    "\n",
    "print('BIC(LCDM) = ' + str(bic_lcdm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "\n",
    "if 'BAO'  in data_set_names or 'CMB' in data_set_names:    \n",
    "    ax1.set_title(r'$\\Omega_m = {%1.3f}^{+%1.3f}_{-%1.3f},\\, H_0 = {%1.1f}^{+%1.1f}_{-%1.1f}\\,\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}$' % (omegam, stdmp,stdmm, H0, stdhm, stdhp))\n",
    "else:\n",
    "    ax1.set_title(r'$\\Omega_m = {%1.3f}^{+%1.3f}_{-%1.3f}$' % (omegam, stdmp,stdmm))\n",
    "    \n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=0, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(best_fit_cosmo_LCDM).T[0], BAOdata.distance_modulus(best_fit_cosmo_LCDM).T[1], yerr=BAOdata.delta_distance_modulus(best_fit_cosmo_LCDM), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_cosmo_LCDM.distance_modulus(zPlot), c='k', label=r'best fit')\n",
    "ax1.fill_between(zPlot, cosmology(omegam+stdmp,1-omegam-stdmp, omegab=omegab+stdbp, Hzero=H0+stdhp).distance_modulus(zPlot), cosmology(omegam-stdmm,1-omegam+stdmm, omegab=omegab-stdbm, Hzero=H0-stdhm).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset, Hzero=100*h).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_cosmo_LCDM.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .06, r'$\\mathrm{BIC}(\\Lambda\\mathrm{CDM}) = %1.0f$' % (BIC_LCDM(v.T[0],data_sets)), ha='right', va='bottom', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('plots/Hubble_LCDM' + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we load and analyse all chains separately. Results are a list of best fit parameters and a full posterior plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCDM_chains = {}\n",
    "LCDM_chains['SN'] = HDFBackend('chains/LCDM_SN_512x1000.h5')\n",
    "LCDM_chains['SN_Q'] = HDFBackend('chains/LCDM_SN_Quasars_512x1000.h5')\n",
    "LCDM_chains['SN_Q_BAO'] = HDFBackend('chains/LCDM_SN_Quasars_BAO_512x1000.h5')\n",
    "LCDM_chains['SN_BAO_CMB'] = HDFBackend('chains/LCDM_SN_CMB_512x1000.h5')\n",
    "LCDM_chains['SN_Q_BAO_CMB'] = HDFBackend('chains/LCDM_SN_Quasars_BAO_CMB_512x1000.h5')\n",
    "LCDM_chains['BAO'] = HDFBackend('chains/LCDM_BAO_512x1000.h5')\n",
    "LCDM_chains['CMB'] = HDFBackend('chains/LCDM_CMB_512x1000.h5')\n",
    "LCDM_chains['BAO_CMB'] = HDFBackend('chains/LCDM_BAO_CMB_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_combinations = ['SN','SN_Q','SN_Q_BAO','SN_Q_BAO_CMB','SN_BAO_CMB','BAO','CMB','BAO_CMB']\n",
    "data_set_combin_obs = {}\n",
    "data_set_combin_obs['SN'] = [SNdata]\n",
    "data_set_combin_obs['SN_Q'] = [SNdata,Qdata]\n",
    "data_set_combin_obs['SN_Q_BAO'] = [SNdata,Qdata,BAOdata]\n",
    "data_set_combin_obs['SN_BAO_CMB'] = [SNdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['SN_Q_BAO_CMB'] = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['BAO'] = [BAOdata]\n",
    "data_set_combin_obs['CMB'] = [CMBdata]\n",
    "data_set_combin_obs['BAO_CMB'] = [BAOdata,CMBdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertValsToTeX(vec):\n",
    "    if not isinstance(vec,np.ndarray):\n",
    "        return '$' + str(vec) + '$' \n",
    "    elif len(vec) == 3:\n",
    "        return '$' + str(vec[0]) + '^{+' + str(vec[1]) + '}_{-' + str(vec[2]) + '}$' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of best fit paramters and calculate the BIC for LCDM\n",
    "\n",
    "bic_lcdmlist = {}\n",
    "\n",
    "printlist = []\n",
    "\n",
    "for set_name in data_set_combinations:\n",
    "    sample = LCDM_chains[set_name].get_chain()\n",
    "    Nmin = 300\n",
    "    while Nmin < nsteps and np.all(LCDM_chains[set_name].get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "    dellist = np.unique(np.where(np.isclose(sample[-1] - sample[0], 0))[0])\n",
    "    sample = np.delete(sample, np.unique(dellist), axis=1)[Nmin:, :].reshape((-1, ndim))\n",
    "    \n",
    "    data_sets = data_set_combin_obs[set_name]\n",
    "    \n",
    "    vtemp = np.percentile(sample,[16, 50, 84], axis = 0)\n",
    "    vtemp = np.asarray([vtemp[1], vtemp[2]-vtemp[1],vtemp[1]-vtemp[0]]).T\n",
    "    \n",
    "    bic_lcdmlist[set_name] = BIC_LCDM(vtemp.T[0], data_set_combin_obs[set_name])\n",
    "    \n",
    "    printvec = set_name + ':\\n' +  '   Om_m:' + str(np.round(vtemp[0],4)) +'\\n'+'   Om_b:' + str(np.round(vtemp[1],4)*100)+'\\n'+'   H0:  ' + str(np.round(vtemp[2],2))+'\\n'+'   BIC: ' + str(np.round(bic_lcdmlist[set_name]))+'\\n'\n",
    "    print(printvec)\n",
    "    \n",
    "    #prepare the list of best fit parameters for TeX-export:\n",
    "    printlist = np.append(printlist,\n",
    "                          np.array([[set_name,\n",
    "                                    convertValsToTeX(np.round(vtemp[0],4)),\n",
    "                                    convertValsToTeX(np.round(vtemp[1]*100,2)),\n",
    "                                    convertValsToTeX(np.round(vtemp[2],2)),\n",
    "                                    convertValsToTeX(np.round(bic_lcdmlist[set_name]))]]))\n",
    "\n",
    "    \n",
    "    #TeXvec = set_name + ':\\n' +  '   Om_m:' + str(np.round(vtemp[0],4)) +'\\n'+'   Om_b:' + str(np.round(vtemp[1],4)*100)+'\\n'+'   H0:  ' + str(np.round(vtemp[2],2))+'\\n'+'   BIC: ' + str(np.round(bic_lcdmlist[set_name]))+'\\n'\n",
    "    #TeXlist += printvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save BIC of LCDM for later comparison with other models:\n",
    "np.save('LCDM_BIC', bic_lcdmlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportTab=np.array([printlist[0:5],printlist[5:10],printlist[10:15],printlist[15:20]]).T\n",
    "np.savetxt(u\"LCDM_values.txt\", exportTab, fmt=u'%s' , delimiter=u\" & \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "for sampler in LCDM_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print('Nmin=',Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_LCDM_min=[0, 0, 60., -5, -10, -30, -.5, 0, 0]\n",
    "ranges_LCDM_max=[1, 0.1, 80., 5, 10, -10, .5, 10, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the posteriors\n",
    "\n",
    "#samples = LCDM_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['SN'])),:].reshape((-1, LCDM_chains['SN'].get_chain().shape[-1]))\n",
    "#fig=corner(samples[:,:3], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "#           labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "#            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "#            range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "samples = LCDM_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['SN_Q'])),:].reshape((-1, LCDM_chains['SN_Q'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:3], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='blue', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "samples = LCDM_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['BAO'])),:].reshape((-1, LCDM_chains['BAO'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:3], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "samples = LCDM_chains['CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['CMB'])),:].reshape((-1, LCDM_chains['CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:3], levels=(1-np.exp( -0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange'], alpha=0.4),\n",
    "            fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "samples = LCDM_chains['SN_Q_BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['SN_Q_BAO_CMB'])),:].reshape((-1, LCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:3], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='black', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "\n",
    "# samples = LCDM_chains['SN_BAO_CMB'].get_chain()[Nmin:,:].reshape((-1, LCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "# corner(samples[:,:3], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='k', \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgray', 'gray'], alpha=0.4),\n",
    "#             fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_LCDM.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_plot = [(0.2,.4), (0.04,0.06), (65,70)]\n",
    "\n",
    "samples = LCDM_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['BAO'])),:].reshape((-1, LCDM_chains['BAO'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:3], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            range=range_plot)\n",
    "\n",
    "samples = LCDM_chains['CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['CMB'])),:].reshape((-1, LCDM_chains['CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:3], levels=(1-np.exp( -0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange'], alpha=0.4),\n",
    "            fig=fig, range=range_plot)\n",
    "\n",
    "samples = LCDM_chains['BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['BAO_CMB'])),:].reshape((-1, LCDM_chains['BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:3], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='cyan', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            fig=fig, range=range_plot)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('plots/posterior_LCDM.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LCDM, we also generate the full posterior distribution plot, with marginalised parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = LCDM_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['SN'])),:].reshape((-1, LCDM_chains['SN'].get_chain().shape[-1]))\n",
    "fig=corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "            range=[(0.15,.5), (0.03,0.07), (62,75), (0,0.3), (0,5), (-22,-18), (-1,1) ,(5,10), (1,2)])\n",
    "\n",
    "samples = LCDM_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['SN_Q'])),:].reshape((-1, LCDM_chains['SN_Q'].get_chain().shape[-1]))\n",
    "corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='blue', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75), (0,0.3), (0,5), (-22,-18), (-1,1) ,(5,10), (1,2)])\n",
    "\n",
    "samples = LCDM_chains['SN_Q_BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(LCDM_chains['SN_Q_BAO_CMB'])),:].reshape((-1, LCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples, levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='black', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75), (0,0.3), (0,5), (-22,-18), (-1,1) ,(5,10), (1,2)])\n",
    "\n",
    "\n",
    "#samples = LCDM_chains['SN_BAO_CMB'].get_chain()[Nmin:,:].reshape((-1, LCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "#corner(samples[:,:3], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='k', \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgray', 'gray'], alpha=0.4),\n",
    "#             fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "#plt.tick_params(axis='both', which='minor', labelsize=8)\n",
    "\n",
    "\n",
    "plt.savefig('plots/posterior_LCDM_full.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: k$\\Lambda$LCDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which data sets to include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'kLCDM'\n",
    "CMBdata = CMB_data(model, 'Planck18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_kLCDM_min=[0, 0, 0, 60., -5, -10, -30, -.5, 0, 0]\n",
    "ranges_kLCDM_max=[1, 1.5, .1, 80., 5, 10, -10, .5, 10, 3]\n",
    "def lnprob_kLCDM(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_kLCDM_min, ranges_kLCDM_max, model = 'kLCDM', rd_num = rd_num, z_num = z_num)\n",
    "    return l.logprobability_gauss_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_kLCDM = [Omega_m_preset, Omega_c_preset, omega_baryon_preset, 67.27, a, b, MB, -0.05, beta_prime, s]\n",
    "\n",
    "BIC_kLCDM = lambda theta, data_sets_var: np.log(sum([len(d.get_data()) for d in data_sets_var])) * len(theta) -2*lnprob_kLCDM(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = 10, 512, 1000\n",
    "pos0 = np.random.uniform(ranges_kLCDM_min, ranges_kLCDM_max, (nwalkers,len(ranges_kLCDM_max)))\n",
    "\n",
    "#pool = Pool(cpu_count())\n",
    "#write = HDFBackend('chains/testing/150120_kLCDM_v2_znum_TCMB_anard' + data_sets_str + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "#sampler = EnsembleSampler(nwalkers, ndim, lnprob_kLCDM, pool=pool)#, backend=write)\n",
    "\n",
    "#sampler.run_mcmc(pos0, nsteps, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kLCDM_sampler = HDFBackend('chains/kLCDM' + data_sets_str + str(nwalkers) + 'x' + str(nsteps) + '.h5', read_only=True)\n",
    "#kLCDM_sampler = sampler\n",
    "\n",
    "nsteps, nwalkers, ndim = kLCDM_sampler.get_chain().shape\n",
    "\n",
    "labs = [r'$\\Omega_m$', r'$\\Omega_\\Lambda$', r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$\\alpha^\\prime$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "while Nmin < nsteps and np.all(kLCDM_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kLCDM_samples = kLCDM_sampler.get_chain()\n",
    "\n",
    "dellist = np.unique(np.where(np.isclose(kLCDM_samples[-1] - kLCDM_samples[0], 0))[0])\n",
    "kLCDM_samples = np.delete(kLCDM_samples, np.unique(dellist), axis=1)\n",
    "\n",
    "f, ax = plt.subplots(len(kLCDM_samples.T), 1, figsize=(6,3*len(kLCDM_samples.T)))\n",
    "\n",
    "for i in range(len(kLCDM_samples.T)):\n",
    "    ax[i].plot(kLCDM_samples.T[i].T, lw=0.5)\n",
    "    ax[i].plot([Nmin, Nmin], [min(kLCDM_samples.T[i].flatten()), max(kLCDM_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "    ax[i].text(Nmin, min(kLCDM_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/convergence_kLCDM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kLCDM_samples = kLCDM_samples[Nmin:].reshape((-1, ndim))\n",
    "#kLCDM_samples = kLCDM_samples.reshape((-1, ndim))\n",
    "\n",
    "# Delete walkers which haven't moved from initiatial position:\n",
    "\n",
    "dellist = np.unique(np.where(np.isclose(kLCDM_samples[-1] - kLCDM_samples[0], 0))[0])\n",
    "kLCDM_samples = np.delete(kLCDM_samples, np.unique(dellist), axis=1)\n",
    "\n",
    "\n",
    "meankLCDM = np.mean(kLCDM_samples, axis=0)\n",
    "stdkLCDM = np.var(kLCDM_samples, axis=0)\n",
    "maxkLCDM=[]\n",
    "for i in range(len(meankLCDM)):\n",
    "    like = np.histogram(kLCDM_samples.T[i], bins=500)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxkLCDM.append(max_val)\n",
    "\n",
    "fig = corner(kLCDM_samples[:,:4], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)), range=[(0,0.8),(0,1),(0,.1), (60,80)],\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "#              truths=maxkLCDM)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/kLCDM' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(kLCDM_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "omegam, stdmp, stdmm = v[0]\n",
    "omegac, stdcp, stdcm = v[1]\n",
    "\n",
    "omegab, stdbp, stdbm = v[2]\n",
    "H0, stdhp, stdhm = v[3]\n",
    "    \n",
    "    \n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "best_fit_cosmo_kLCDM = cosmology(*maxkLCDM[:2], omegab = maxkLCDM[2],  omegag=omega_gamma_preset, Hzero=maxkLCDM[3])\n",
    "SNdata.set_param(v.T[0][4:8])\n",
    "Qdata.set_param(v.T[0][8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "\n",
    "if 'BAO'  in data_set_names or 'CMB' in data_set_names:    \n",
    "    ax1.set_title(r'$\\Omega_m = {%1.3f}^{+%1.3f}_{-%1.3f},\\, \\Omega_\\Lambda = {%1.3f}^{+%1.3f}_{-%1.3f},\\, H_0 = {%1.2f}^{+%1.2f}_{-%1.2f} \\,\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}$' % (omegam, stdmp,stdmm, omegac, stdcp, stdcm, H0, stdhm, stdhp))\n",
    "else:\n",
    "    ax1.set_title(r'$\\Omega_m = {%1.3f}^{+%1.3f}_{-%1.3f},\\, \\Omega_\\Lambda = {%1.3f}^{+%1.3f}_{-%1.3f}$' % (omegam, stdmp,stdmm, omegac, stdcp, stdcm))\n",
    "\n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=0, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(best_fit_cosmo_kLCDM).T[0], BAOdata.distance_modulus(best_fit_cosmo_kLCDM).T[1], yerr=BAOdata.delta_distance_modulus(best_fit_cosmo_kLCDM), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_cosmo_kLCDM.distance_modulus(zPlot), c='k', label=r'best fit')\n",
    "ax1.fill_between(zPlot, cosmology(omegam+stdmp,omegac+stdcp, omegab=omegab+stdbp, Hzero=H0+stdhp).distance_modulus(zPlot), cosmology(omegam-stdmm,omegac-stdcm, omegab=omegab-stdbm, Hzero=H0-stdhm).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_cosmo_kLCDM.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .06, r'$\\Delta \\mathrm{BIC}(k\\Lambda\\mathrm{CDM}) = %1.0f$' % (BIC_kLCDM(v.T[0],data_sets) - bic_lcdm), ha='right', va='bottom', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/Hubble_kLCDM' + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kLCDM_chains = {}\n",
    "kLCDM_chains['SN'] = HDFBackend('chains/kLCDM_SN_512x1000.h5')\n",
    "kLCDM_chains['SN_Q'] = HDFBackend('chains/kLCDM_SN_Quasars_512x1000.h5')\n",
    "kLCDM_chains['SN_Q_BAO'] = HDFBackend('chains/kLCDM_SN_Quasars_BAO_512x1000.h5')\n",
    "#kLCDM_chains['SN_BAO_CMB'] = HDFBackend('chains/kLCDM_SN_BAO_CMB_512x1000.h5')\n",
    "kLCDM_chains['SN_Q_BAO_CMB'] = HDFBackend('chains/kLCDM_SN_Quasars_BAO_CMB_512x1000.h5')\n",
    "kLCDM_chains['BAO'] = HDFBackend('chains/kLCDM_BAO_512x1000.h5')\n",
    "kLCDM_chains['CMB'] = HDFBackend('chains/kLCDM_CMB_512x1000.h5')\n",
    "kLCDM_chains['BAO_CMB'] = HDFBackend('chains/kLCDM_BAO_CMB_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_combinations = ['SN','SN_Q','SN_Q_BAO','SN_Q_BAO_CMB','BAO','CMB','BAO_CMB']\n",
    "data_set_combin_obs = {}\n",
    "data_set_combin_obs['BAO_CMB'] = [BAOdata,CMBdata]\n",
    "data_set_combin_obs['SN'] = [SNdata]\n",
    "data_set_combin_obs['SN_Q'] = [SNdata,Qdata]\n",
    "data_set_combin_obs['SN_Q_BAO'] = [SNdata,Qdata,BAOdata]\n",
    "data_set_combin_obs['SN_BAO_CMB'] = [SNdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['SN_Q_BAO_CMB'] = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['BAO'] = [BAOdata]\n",
    "data_set_combin_obs['CMB'] = [CMBdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertValsToTeX(vec):\n",
    "    if not isinstance(vec,np.ndarray):\n",
    "        return '$' + str(vec) + '$' \n",
    "    elif len(vec) == 3:\n",
    "        return '$' + str(vec[0]) + '^{+' + str(vec[1]) + '}_{-' + str(vec[2]) + '}$' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of BICs calculated for LCDM\n",
    "bic_lcdmlist = np.load('LCDM_BIC.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of best fit paramters and calculate the Delta BIC of kLCDM with respect to LCDM\n",
    "\n",
    "printlist = []\n",
    "\n",
    "for set_name in data_set_combinations:\n",
    "    sample = kLCDM_chains[set_name].get_chain()\n",
    "    Nmin = 300\n",
    "    while Nmin < nsteps and np.all(kLCDM_chains[set_name].get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "    dellist = np.unique(np.where(np.isclose(sample[-1] - sample[0], 0))[0])\n",
    "    sample = np.delete(sample, np.unique(dellist), axis=1)[Nmin:, :].reshape((-1, ndim))\n",
    "    \n",
    "    data_sets = data_set_combin_obs[set_name]\n",
    "    \n",
    "    vtemp = np.percentile(sample,[16, 50, 84], axis = 0)\n",
    "    vtemp = np.asarray([vtemp[1], vtemp[2]-vtemp[1],vtemp[1]-vtemp[0]]).T\n",
    "    print(set_name + ':')\n",
    "    print('   Om_m:' + str(np.round(vtemp[0],4)))\n",
    "    print('   Om_c:' + str(np.round(vtemp[1],4)))\n",
    "    print('   Om_b:' + str(np.round(vtemp[2],5)*100))\n",
    "    print('   H0:  ' + str(np.round(vtemp[3],2)))\n",
    "    print('   dBIC:' + str(np.round(BIC_kLCDM(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name])))\n",
    "    \n",
    "    #prepare the list of best fit parameters for TeX-export:\n",
    "    printlist = np.append(printlist,\n",
    "                          np.array([[set_name,\n",
    "                                    convertValsToTeX(np.round(vtemp[0],3)),\n",
    "                                    convertValsToTeX(np.round(vtemp[1],3)),\n",
    "                                    convertValsToTeX(np.round(vtemp[2]*100,2)),\n",
    "                                    convertValsToTeX(np.round(vtemp[3],2)),\n",
    "                                    convertValsToTeX(np.round(BIC_kLCDM(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name]))]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportTab=np.array([printlist[0:6],printlist[6:12],printlist[12:18],printlist[18:24]]).T\n",
    "np.savetxt(u\"kLCDM_values.txt\", exportTab, fmt=u'%s' , delimiter=u\" & \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "for sampler in kLCDM_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print('Nmin=',Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rangekLCDM = [(0,.6), (0.5,1.1),  (0.03,0.07), (62,75)]\n",
    "\n",
    "#samples = kLCDM_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kLCDM_chains['SN'])),:].reshape((-1, kLCDM_chains['SN'].get_chain().shape[-1]))\n",
    "#fig=corner(samples[:,:4], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "#            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "#            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "#            range=[(0,.6), (0,1.25), (0.03,0.07), (62,75)])\n",
    "\n",
    "samples = kLCDM_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kLCDM_chains['SN_Q'])),:].reshape((-1, kLCDM_chains['SN_Q'].get_chain().shape[-1]))\n",
    "fig = corner(samples[:,:4], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='blue', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            range=rangekLCDM)\n",
    "\n",
    "samples = kLCDM_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kLCDM_chains['BAO'])),:].reshape((-1, kLCDM_chains['BAO'].get_chain().shape[-1]))\n",
    "corner(samples[:,:4], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            fig=fig, range=rangekLCDM)\n",
    "\n",
    "samples = kLCDM_chains['CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kLCDM_chains['CMB'])),:].reshape((-1, kLCDM_chains['CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:4], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange'], alpha=0.4),\n",
    "            fig=fig, range=rangekLCDM)\n",
    "\n",
    "samples = kLCDM_chains['SN_Q_BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kLCDM_chains['SN_Q_BAO_CMB'])),:].reshape((-1, kLCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:4], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='black', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            fig=fig, range=rangekLCDM)\n",
    "\n",
    "\n",
    "# samples = kLCDM_chains['SN_BAO_CMB'].get_chain()[Nmin:,:].reshape((-1, kLCDM_chains['SN_BAO_CMB'].get_chain().shape[-1]))\n",
    "# corner(samples[:,:4], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='k', \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgray', 'gray'], alpha=0.4),\n",
    "#             fig=fig, range=[(0,.6), (0,1.25), (0.03,0.07), (62,75)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_kLCDM.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_range = [(0,.6), (0,1.25), (0.03,0.07), (60,80)]\n",
    "\n",
    "samples = kLCDM_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kLCDM_chains['BAO'])),:].reshape((-1, kLCDM_chains['BAO'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:4], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            range=posterior_range)\n",
    "\n",
    "samples = kLCDM_chains['CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kLCDM_chains['CMB'])),:].reshape((-1, kLCDM_chains['CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:4], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange'], alpha=0.4),\n",
    "            fig=fig, range=posterior_range)\n",
    "\n",
    "\n",
    "\n",
    "samples = kLCDM_chains['BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kLCDM_chains['BAO_CMB'])),:].reshape((-1, kLCDM_chains['BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:4], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='cyan', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            fig=fig, range=posterior_range)\n",
    "\n",
    "\n",
    "\n",
    "#samples = kLCDM_chains['SN_Q_BAO_CMB'].get_chain()[Nmin:,:].reshape((-1, kLCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "#corner(samples[:,:4], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='k', \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgray', 'gray'], alpha=0.4),\n",
    "#             fig=fig, range=posterior_range)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('plots/posterior_kLCDM.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples = kLCDM_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kLCDM_chains['SN'])),:].reshape((-1, kLCDM_chains['SN'].get_chain().shape[-1]))\n",
    "#fig=corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "#            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "#            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "#            range=[(0.15,.5), (0.5,1.0), (0.03,0.07), (62,75), (0,0.3), (0,5), (-22,-18), (-1,1) ,(5,10), (1,2)])\n",
    "\n",
    "samples = kLCDM_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kLCDM_chains['SN_Q'])),:].reshape((-1, kLCDM_chains['SN_Q'].get_chain().shape[-1]))\n",
    "fig=corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='blue', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            range=[(0.15,.5), (0.5,1.0), (0.03,0.07), (62,75), (0,0.3), (0,5), (-22,-18), (-1,1) ,(5,10), (1,2)])\n",
    "\n",
    "samples = kLCDM_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kLCDM_chains['BAO'])),:].reshape((-1, kLCDM_chains['BAO'].get_chain().shape[-1]))\n",
    "corner(samples, levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            fig=fig, range=[(0.15,.5), (0.5,1.0), (0.03,0.07), (62,75), (0,0.3), (0,5), (-22,-18), (-1,1) ,(5,10), (1,2)])\n",
    "\n",
    "samples = kLCDM_chains['CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kLCDM_chains['CMB'])),:].reshape((-1, kLCDM_chains['CMB'].get_chain().shape[-1]))\n",
    "corner(samples, levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='yellow', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightyellow', 'yellow'], alpha=0.4),\n",
    "            fig=fig, range=[(0.15,.5), (0.5,1.0), (0.03,0.07), (62,75), (0,0.3), (0,5), (-22,-18), (-1,1) ,(5,10), (1,2)])\n",
    "\n",
    "\n",
    "samples = kLCDM_chains['SN_Q_BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kLCDM_chains['SN_Q_BAO_CMB'])),:].reshape((-1, kLCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples, levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='cyan', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            fig=fig, range=[(0.15,.5), (0.5,1.0), (0.03,0.07), (62,75), (0,0.3), (0,5), (-22,-18), (-1,1) ,(5,10), (1,2)])\n",
    "\n",
    "\n",
    "#samples = LCDM_chains['SN_BAO_CMB'].get_chain()[Nmin:,:].reshape((-1, LCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "#corner(samples[:,:3], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='k', \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgray', 'gray'], alpha=0.4),\n",
    "#             fig=fig, range=[(0.15,.5), (0.03,0.07), (62,75)])\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "#plt.tick_params(axis='both', which='minor', labelsize=8)\n",
    "\n",
    "\n",
    "#plt.savefig('plots/posterior_kLCDM_full.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: $w\\Lambda$LCDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which data sets to include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'wLCDM'\n",
    "CMBdata = CMB_data(model, 'Planck18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [SNdata, Qdata, BAOdata, CMBdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_wLCDM_min=[0, 0, 0, 60., -2.5, -5, -10, -30, -.5, 0, 0]\n",
    "ranges_wLCDM_max=[1, 1.5, 0.1, 80., -1/3., 5, 10, -10, .5, 10, 3]\n",
    "def lnprob_wLCDM(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_wLCDM_min, ranges_wLCDM_max, model = 'wLCDM', rd_num = rd_num, z_num = z_num)\n",
    "    return l.logprobability_gauss_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_wLCDM = lambda theta, data_sets_var: np.log(sum([len(d.get_data()) for d in data_sets_var])) * len(theta) -2*lnprob_wLCDM(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = 10, 512, 1000\n",
    "pos0 = np.random.uniform(ranges_wLCDM_min, ranges_wLCDM_max, (nwalkers,len(ranges_wLCDM_max)))\n",
    "\n",
    "# pool = Pool(cpu_count())\n",
    "# write = HDFBackend('chains/LCDM_' + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "# sampler = EnsembleSampler(nwalkers, ndim, lnprob_wLCDM, pool=pool)#, backend=write)\n",
    "# \n",
    "# sampler.run_mcmc();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wLCDM_sampler = HDFBackend('chains/wLCDM' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "#LCDM_sampler = sampler\n",
    "\n",
    "nsteps, nwalkers, ndim = wLCDM_sampler.get_chain().shape\n",
    "\n",
    "labs = [r'$\\Omega_m$', r'$\\Omega_\\Lambda$', r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$w$', r'$\\alpha^\\prime$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "while Nmin < nsteps and np.all(wLCDM_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wLCDM_samples = wLCDM_sampler.get_chain()\n",
    "\n",
    "dellist = np.unique(np.where(np.isclose(wLCDM_samples[-1] - wLCDM_samples[0], 0))[0])\n",
    "wLCDM_samples = np.delete(wLCDM_samples, np.unique(dellist), axis=1)\n",
    "\n",
    "f, ax = plt.subplots(len(wLCDM_samples.T), 1, figsize=(6,3*len(wLCDM_samples.T)))\n",
    "\n",
    "for i in range(len(wLCDM_samples.T)):\n",
    "    ax[i].plot(wLCDM_samples.T[i].T, lw=0.5)\n",
    "    ax[i].plot([Nmin, Nmin], [min(wLCDM_samples.T[i].flatten()), max(wLCDM_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "    ax[i].text(Nmin, min(wLCDM_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/convergence_wLCDM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wLCDM_samples = wLCDM_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "meanwLCDM = np.mean(wLCDM_samples, axis=0)\n",
    "stdwLCDM = np.var(wLCDM_samples, axis=0)\n",
    "maxwLCDM=[]\n",
    "for i in range(len(meanwLCDM)):\n",
    "    like = np.histogram(wLCDM_samples.T[i], bins=50)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxwLCDM.append(max_val)\n",
    "\n",
    "fig = corner(wLCDM_samples[:,:5], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "             range=[(0.2,0.4),(.6,.8),(0.04,0.055),(64,74),(-1.2,-.8)],\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=30, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "# #              truths=maxwLCDM)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_wLCDM' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(wLCDM_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "omegam, stdmp, stdmm = v[0]\n",
    "omegac, stdcp, stdcm = v[1]\n",
    "omegab, stdbp, stdbm = v[2]\n",
    "H0, stdhp, stdhm = v[3]\n",
    "w, wp, wm = v[4]\n",
    "\n",
    "\n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "# omegam, omegac, w = maxwLCDM[0], maxwLCDM[1], maxwLCDM[2]\n",
    "best_fit_cosmo_wLCDM = cosmology(*maxwLCDM[:2], omegab = maxwLCDM[2], Hzero=maxwLCDM[3], w=maxwLCDM[4])\n",
    "SNdata.set_param(v.T[0][-6:-2])\n",
    "Qdata.set_param(v.T[0][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_wlcdm = BIC_wLCDM(v.T[0],data_sets)\n",
    "\n",
    "print('BIC(wLCDM) = ' + str(bic_wlcdm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "\n",
    "if 'BAO'  in data_set_names or 'CMB' in data_set_names:    \n",
    "    ax1.set_title(r'$\\Omega_m = {%1.3f}^{+%1.3f}_{-%1.3f},\\, \\Omega_\\Lambda = {%1.3f}^{+%1.3f}_{-%1.3f},\\, w = {%1.3f}^{+%1.3f}_{-%1.3f},\\, H_0 =  {%1.1f}^{+%1.1f}_{-%1.1f}\\,\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}$' % (omegam, stdmp,stdmm, omegac, stdcp,stdcm, w, wp, wm, H0, stdhp,stdhm), fontsize=17)\n",
    "else:\n",
    "    ax1.set_title(r'$\\Omega_m = {%1.2f}^{+%1.2f}_{-%1.2f},\\, \\Omega_\\Lambda = {%1.2f}^{+%1.2f}_{-%1.2f},\\, w = ,%1.2f}^{+%1.2f}_{-%1.2f}$' % (omegam, stdmp,stdmm, omegac, stdcp,stdcm, w, wp, wm))\n",
    "\n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=-1, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=-1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(best_fit_cosmo_wLCDM).T[0], BAOdata.distance_modulus(best_fit_cosmo_wLCDM).T[1], yerr=BAOdata.delta_distance_modulus(best_fit_cosmo_wLCDM), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=1, label=r'BAO')\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_cosmo_wLCDM.distance_modulus(zPlot), c='k', label=r'best fit')\n",
    "ax1.fill_between(zPlot, cosmology(omegam+stdmp,omegac+stdcp, omegab=omegab+stdbp, w = w+wp, Hzero=H0+stdhp).distance_modulus(zPlot), cosmology(omegam-stdmm,omegac-stdcm, omegab=omegab-stdbm, Hzero=H0-stdhm, w=w-wm).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend(loc=4)\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_cosmo_wLCDM.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .06, r'$\\Delta\\mathrm{BIC}(w\\Lambda\\mathrm{CDM}) = %1.0f$' % (BIC_wLCDM(v.T[0],data_sets) - bic_lcdm), ha='right', va='bottom', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/Hubble_wLCDM' + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wLCDM_chains = {}\n",
    "wLCDM_chains['SN'] = HDFBackend('chains/wLCDM_SN_512x1000.h5')\n",
    "wLCDM_chains['SN_Q'] = HDFBackend('chains/wLCDM_SN_Quasars_512x1000.h5')\n",
    "wLCDM_chains['SN_Q_BAO'] = HDFBackend('chains/wLCDM_SN_Quasars_BAO_512x1000.h5')\n",
    "wLCDM_chains['SN_Q_BAO_CMB'] = HDFBackend('chains/wLCDM_SN_Quasars_BAO_CMB_512x1000.h5')\n",
    "#wLCDM_chains['SN_BAO_CMB'] = HDFBackend('chains/wLCDM_SN_BAO_CMB_512x1000.h5')\n",
    "wLCDM_chains['BAO'] = HDFBackend('chains/wLCDM_BAO_512x1000.h5')\n",
    "wLCDM_chains['CMB'] = HDFBackend('chains/wLCDM_CMB_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_combinations = ['SN','SN_Q','SN_Q_BAO','SN_Q_BAO_CMB','BAO','CMB']\n",
    "data_set_combin_obs = {}\n",
    "data_set_combin_obs['SN'] = [SNdata]\n",
    "data_set_combin_obs['SN_Q'] = [SNdata,Qdata]\n",
    "data_set_combin_obs['SN_Q_BAO'] = [SNdata,Qdata,BAOdata]\n",
    "data_set_combin_obs['SN_BAO_CMB'] = [SNdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['SN_Q_BAO_CMB'] = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['BAO'] = [BAOdata]\n",
    "data_set_combin_obs['CMB'] = [CMBdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertValsToTeX(vec):\n",
    "    if not isinstance(vec,np.ndarray):\n",
    "        return '$' + str(vec) + '$' \n",
    "    elif len(vec) == 3:\n",
    "        return '$' + str(vec[0]) + '^{+' + str(vec[1]) + '}_{-' + str(vec[2]) + '}$' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of BICs calculated for LCDM\n",
    "bic_lcdmlist = np.load('LCDM_BIC.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of best fit paramters and calculate the Delta BIC of kLCDM with respect to LCDM\n",
    "\n",
    "printlist = []\n",
    "\n",
    "\n",
    "for set_name in data_set_combinations:\n",
    "    sample = wLCDM_chains[set_name].get_chain()\n",
    "    Nmin = 300\n",
    "    while Nmin < nsteps and np.all(wLCDM_chains[set_name].get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "    dellist = np.unique(np.where(np.isclose(sample[-1] - sample[0], 0))[0])\n",
    "    sample = np.delete(sample, np.unique(dellist), axis=1)[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "    data_sets = data_set_combin_obs[set_name]\n",
    "    \n",
    "    vtemp = np.percentile(sample,[16, 50, 84], axis = 0)\n",
    "    vtemp = np.asarray([vtemp[1], vtemp[2]-vtemp[1],vtemp[1]-vtemp[0]]).T\n",
    "    print(set_name + ':')\n",
    "    print('   Om_m:' + str(np.round(vtemp[0],4)))\n",
    "    print('   Om_c:' + str(np.round(vtemp[1],4)))\n",
    "    print('   Om_b:' + str(np.round(vtemp[2],4)*100))\n",
    "    print('   H0:  ' + str(np.round(vtemp[3],2)))\n",
    "    print('   w:   ' + str(np.round(vtemp[4],3)))\n",
    "    print('   dBIC:' + str(np.round(BIC_wLCDM(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name])))\n",
    "    \n",
    "    #prepare the list of best fit parameters for TeX-export:\n",
    "    printlist = np.append(printlist,\n",
    "                          np.array([[set_name,\n",
    "                                    convertValsToTeX(np.round(vtemp[0],3)),\n",
    "                                    convertValsToTeX(np.round(vtemp[1],3)),\n",
    "                                    convertValsToTeX(np.round(vtemp[2]*100,2)),\n",
    "                                    convertValsToTeX(np.round(vtemp[3],2)),\n",
    "                                    convertValsToTeX(np.round(vtemp[4],3)),\n",
    "                                    convertValsToTeX(np.round(BIC_wLCDM(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name]))]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportTab=np.array([printlist[0:7],printlist[7:14],printlist[14:21],printlist[21:28]]).T\n",
    "np.savetxt(u\"wLCDM_values.txt\", exportTab, fmt=u'%s' , delimiter=u\" & \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 300\n",
    "for sampler in wLCDM_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print('Nmin=',Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples = wLCDM_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(wLCDM_chains['SN'])),:].reshape((-1, wLCDM_chains['SN'].get_chain().shape[-1]))\n",
    "#fig=corner(samples[:,:5], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "#            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "#            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "#            range=[(0,.6), (0,1.5), (0.03,0.07), (62,75), (-1.5, -0.5)])\n",
    "\n",
    "samples = wLCDM_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(wLCDM_chains['SN_Q'])),:].reshape((-1, wLCDM_chains['SN_Q'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:5], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='blue', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            range=[(0,.6), (0,1.5), (0.03,0.07), (62,75), (-1.5, -0.5)])\n",
    "\n",
    "samples = wLCDM_chains['CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(wLCDM_chains['CMB'])),:].reshape((-1, wLCDM_chains['CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:5], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange'], alpha=0.4),\n",
    "            fig=fig, range=[(0,.6), (0,1.5), (0.03,0.07), (62,75), (-1.5, -0.5)])\n",
    "\n",
    "\n",
    "samples = wLCDM_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(wLCDM_chains['BAO'])),:].reshape((-1, wLCDM_chains['BAO'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:5], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            fig=fig, range=[(0,.6), (0,1.5), (0.03,0.07), (62,75), (-1.5, -0.5)])\n",
    "\n",
    "samples = wLCDM_chains['SN_Q_BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(wLCDM_chains['SN_Q_BAO_CMB'])),:].reshape((-1, wLCDM_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:5], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='black', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            fig=fig, range=[(0,.6), (0,1.5), (0.03,0.07), (62,75), (-1.5, -0.5)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# samples = wLCDM_chains['SN_BAO_CMB'].get_chain()[Nmin:,:].reshape((-1, wLCDM_chains['SN_BAO_CMB'].get_chain().shape[-1]))\n",
    "# corner(samples[:,:5], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#             labels=labs, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='k', \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgray', 'gray'], alpha=0.4),\n",
    "#             fig=fig, range=[(0,.6), (0,1.5), (0.03,0.07), (62,75), (-1.5, -0.5)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_wLCDM.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Bigravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'bigravity'\n",
    "CMBdata = CMB_data(model, 'Planck18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chose the data sets to analyse:\n",
    "data_sets = [SNdata, Qdata, BAOdata, CMBdata]\n",
    "\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_bigravity_min=[-10,-10,-10, .1, 0, 60, -5, -10, -30, -.5, 0, 0]\n",
    "ranges_bigravity_max=[ 10, 10, 10, .5,.1, 80,  5,  10, -10, .5, 10, 3]\n",
    "\n",
    "#Define the signs of the B parameters (needed because we sample log10(B))\n",
    "#B_signs = [+1, +1, +1]\n",
    "B_signs = [+1, -1, +1]\n",
    "#B_signs = [+1, +1, -1]\n",
    "#B_signs = [+1, -1, -1]\n",
    "\n",
    "def lnprob_bigravity(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_bigravity_min, ranges_bigravity_max, model = 'bigravity', rd_num = rd_num, z_num = z_num, B_signs=B_signs)\n",
    "    return l.logprobability_gauss_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_bigravity = lambda theta, data_sets_var: np.log(sum([len(d.get_data()) for d in data_sets_var])) * len(theta) -2*lnprob_bigravity(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndim, nwalkers, nsteps = len(ranges_bigravity_max), 30, 60\n",
    "#pos0 = np.random.uniform(ranges_bigravity_min, ranges_bigravity_max, (nwalkers,len(ranges_bigravity_max)))\n",
    "# initialise pos0 vector where the three log10B_i have a random 0 or 1 as imaginary part\n",
    "#ndim, nwalkers, nsteps = len(ranges_bigravity_max), 30, 60\n",
    "#pos0 = np.random.uniform(ranges_bigravity_min, ranges_bigravity_max, (nwalkers,len(ranges_bigravity_max))) + 0.j\n",
    "#\n",
    "#\n",
    "#for line in range(0,len(pos0)):\n",
    "#    pos0[line] += np.concatenate((1.j*np.random.uniform(-1,1, size=3),np.zeros(len(ranges_bigravity_max)-3)),axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = len(ranges_bigravity_max), 100, 500\n",
    "pos0 = np.random.uniform(ranges_bigravity_min, ranges_bigravity_max, (nwalkers,len(ranges_bigravity_max)))\n",
    "\n",
    "#B signs to sring for name of h5 file:\n",
    "Bsgn_string = ''.join([str(sign) for sign in B_signs])\n",
    "\n",
    "#pool = Pool(cpu_count())\n",
    "#write = HDFBackend('chains/bigravity_log10B_B' + Bsgn_string + '_' + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "#bigravity_sampler = EnsembleSampler(nwalkers, ndim, lnprob_bigravity, pool=pool, backend=write)\n",
    "\n",
    "#bigravity_sampler.run_mcmc(pos0, nsteps, progress=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load chain corresponding to B_signs\n",
    "\n",
    "if B_signs == [+1, +1, +1]:\n",
    "    bigravity_sampler = HDFBackend('chains/bigravity_log10B_B111' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "    print('Chain log10B_B111 loaded')\n",
    "    \n",
    "elif B_signs == [+1, -1, +1]:\n",
    "    bigravity_sampler = HDFBackend('chains/bigravity_log10B_B1-11' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "    print('Chain log10B_B1-11 loaded')\n",
    "    \n",
    "elif B_signs == [+1, +1, -1]:\n",
    "    bigravity_sampler = HDFBackend('chains/bigravity_log10B_B11-1' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "    print('Chain log10B_B11-1 loaded')\n",
    "    \n",
    "elif B_signs == [+1, -1, -1]:\n",
    "    bigravity_sampler = HDFBackend('chains/bigravity_log10B_B1-1-1' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "    print('Chain log10B_B1-1-1 loaded')\n",
    "    \n",
    "nsteps, nwalkers, ndim = bigravity_sampler.get_chain().shape\n",
    "\n",
    "labs = [r'$\\log_{10}B_1$', r'$\\log_{10}B_2$',r'$\\log_{10}B_3$', r'$\\Omega_m$',r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$\\alpha^\\prime$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigravity_samples = bigravity_sampler.get_chain()\n",
    "\n",
    "dellist = np.unique(np.where(np.isclose(bigravity_samples[-1] - bigravity_samples[0], 0))[0])\n",
    "\n",
    "bigravity_samples = np.delete(bigravity_samples, np.unique(dellist), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 900\n",
    "while Nmin < nsteps and np.all(bigravity_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(len(bigravity_samples.T), 1, figsize=(6,3*len(bigravity_samples.T)))\n",
    "\n",
    "for i in range(len(bigravity_samples.T)):\n",
    "    ax[i].plot(bigravity_samples.T[i].T, lw=0.5)\n",
    "#     ax[i].plot([Nmin, Nmin], [min(bigravity_samples.T[i].flatten()), max(bigravity_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "#     ax[i].text(Nmin, min(bigravity_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/convergence_bigravity' + Bsgn_string + '.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if this fails w/ error \"more dimensions than samples!\", replace Nmin by a lower number for testing\n",
    "#bigravity_samples = bigravity_samples[0:, :].reshape((-1, ndim))\n",
    "bigravity_samples = bigravity_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "meanbigravity = np.mean(bigravity_samples, axis=0)\n",
    "stdbigravity = np.var(bigravity_samples, axis=0)\n",
    "maxbigravity=[]\n",
    "for i in range(len(meanbigravity)):\n",
    "    like = np.histogram(bigravity_samples.T[i], bins=1000)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxbigravity.append(max_val)\n",
    "\n",
    "fig = corner(bigravity_samples[:,:6], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),# range=[(0,0.8),(0.01,0.08), (60,80)],\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=20, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "#              truths=maxLCDM)\n",
    "\n",
    "Bsgn_string = ''.join([str(sign) for sign in B_signs])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('plots/posterior_bigravity_log10B_B' + Bsgn_string + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(bigravity_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "logB1, stdlB1p, stdlB1m = v[0]\n",
    "logB2, stdlB2p, stdlB2m = v[1]\n",
    "logB3, stdlB3p, stdlB3m = v[2]\n",
    "\n",
    "omegam, stdmp, stdmm = v[3]\n",
    "omegab, stdbp, stdbm = v[4]\n",
    "H0, stdhp, stdhm = v[5]\n",
    "\n",
    "#if ndim == 9:\n",
    "#    logB1, B2, Bb3 = 1.,1.,-1.,1.\n",
    "#elif ndim >=9:\n",
    "#    B1, B2, B3 = v[0:3].T[0]\n",
    "\n",
    "\n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "best_fit_bigravitycosmo = bigravity_cosmology(logB1, logB2, logB3, omegam,1-omegam-omega_gamma_preset, omegag=omega_gamma_preset, omegab=omegab, Hzero=H0, B_signs=B_signs, verbose=False)\n",
    "SNdata.set_param(v.T[0][-6:-2])\n",
    "Qdata.set_param(v.T[0][-2:])\n",
    "\n",
    "# Calculate physical graviton mass of best fit cosmology:\n",
    "mg = best_fit_bigravitycosmo.graviton_mass(1-omegam-omega_gamma_preset)\n",
    "# Calculate error of physical graviton mass:\n",
    "delmg = best_fit_bigravitycosmo.del_graviton_mass(1-omegam-omega_gamma_preset,stdhp,(stdlB1p+stdlB1m)/2,(stdlB2p+stdlB2m)/2,(stdlB3p+stdlB3m)/2)\n",
    "\n",
    "# Graviton mass in best fit bigravity:\n",
    "print(mg)\n",
    "print(delmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbicosmo = bigravity_cosmology(logB1+4, logB2+4, logB3+4, omegam,1-omegam-omega_gamma_preset, omegag=omega_gamma_preset, omegab=omegab, Hzero=H0, B_signs=B_signs, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbicosmo.graviton_mass(1-omegam-omega_gamma_preset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit_bigravitycosmo.graviton_mass(1-omegam-omega_gamma_preset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's show that Bigravity reproduces LCDM at high-z using the best fit parameters:\n",
    "test_cosmo_LCDM = cosmology(omegam, omegac=1-omegam, omegab=omegab, omegag=omega_gamma_preset, Hzero=H0)\n",
    "\n",
    "# plot y(z) for best fit\n",
    "z = np.arange(0.001, 1000.0, .01)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "\n",
    "ax.semilogx(z, best_fit_bigravitycosmo.H(z)/test_cosmo_LCDM.H(z))\n",
    "\n",
    "ax.set_title('$H(z)$ of bigravity / $H(z)$ of $\\Lambda$CDM ', fontsize=18)\n",
    "\n",
    "ax.set(xlabel='z')\n",
    "ax.set_xlim(0.001,1000)\n",
    "plt.xticks((.001,.01,.1,1,10,100,1000))\n",
    "\n",
    "#plt.yticks(np.arange(1., 1.00005, .00001))\n",
    "#ax.get_xaxis().set_major_formatter(FormatStrFormatter())\n",
    "ax.yaxis.set_minor_formatter(FormatStrFormatter('%.0f'))\n",
    "ax.grid('--',which='major',axis='x', dashes=(5,5))\n",
    "ax.grid('--',which='both',axis='y', dashes=(5,5))\n",
    "\n",
    "\n",
    "#ax.grid('--', dashes=(5,5))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('plots/bigra_' + Bsgn_string +'_best_fit_H_over_LCDM.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot y(z) for best fit\n",
    "z = np.arange(0.1, 1000.0, 0.01)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogx(z, best_fit_bigravitycosmo.Bianchi(z))\n",
    "\n",
    "ax.set_title('Bigravity best fit cosmology', fontsize=18)\n",
    "\n",
    "ax.set(xlabel='z', ylabel='y(z)')\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('plots/bigra_' + Bsgn_string +'_best_fit_y' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_bi = BIC_bigravity(v.T[0],data_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of BICs calculated for LCDM\n",
    "bic_lcdmlist = np.load('LCDM_BIC.npy').item()\n",
    "bic_lcdm = bic_lcdmlist['_'.join([name for name in data_set_names]).replace('Quasars','Q')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_bi-bic_lcdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "\n",
    "if 'BAO'  in data_set_names or 'CMB' in data_set_names:    \n",
    "    ax1.set_title(r'$\\Omega_m = {%1.3f}^{+%1.3f}_{-%1.3f},\\, H_0 =  {%1.1f}^{+%1.1f}_{-%1.1f}\\,\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}$' % (omegam, stdmp,stdmm, H0, stdhp,stdhm), fontsize=18)\n",
    "else:\n",
    "    ax1.set_title(r'$\\Omega_m = {%1.2f}^{+%1.2f}_{-%1.2f}$' % (omegam, stdmp,stdmm), fontsize=18)\n",
    "\n",
    "labelstr = '\\log_{10}('+ str(B_signs[0]).replace(\"1\",\"\") +'B_1,'+ str(B_signs[1]).replace(\"1\",\"\") +'B_2,'+ str(B_signs[2]).replace(\"1\",\"\") +'B_3)'\n",
    "ax1.text(0.5, 0.96, r'$'+labelstr+' = {%1.1f}^{+%1.1f}_{-%1.1f},  {%1.1f}^{+%1.1f}_{-%1.1f},  {%1.1f}^{+%1.1f}_{-%1.1f}$' % (logB1, stdlB1p, stdlB1m, logB2, stdlB2p, stdlB2m, logB3, stdlB3p, stdlB3m),\n",
    "         ha='center', va='top', fontsize=13, transform=ax1.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "         #,\\,m_g = ({%1.2f}\\pm {%1.2f}) \\\\times 10^{%1.0f} \\,\\mathrm{eV}\n",
    "         #, mg/(10**np.floor(np.log10(mg))),delmg/(10**np.floor(np.log10(mg))), np.floor(np.log10(mg))\n",
    "\n",
    "\n",
    "\n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=-1, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=-1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(best_fit_bigravitycosmo).T[0], BAOdata.distance_modulus(best_fit_bigravitycosmo).T[1], yerr=BAOdata.delta_distance_modulus(best_fit_bigravitycosmo), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=-1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_bigravitycosmo.distance_modulus(zPlot), c='k', label=r'fit')\n",
    "ax1.fill_between(zPlot, bigravity_cosmology(logB1+stdlB1p, logB2+stdlB2p, logB3+stdlB3p, omegam + stdmp, 1- omegam - stdmp, omegab=omegab+stdbp, Hzero=H0+stdhp, B_signs = B_signs).distance_modulus(zPlot), bigravity_cosmology(logB1+stdlB1m, logB2+stdlB2m, logB3+stdlB3m, omegam - stdmm, 1-omegam + stdmm, omegab=omegab-stdbm, Hzero=H0-stdhm, B_signs = B_signs).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset, Hzero=H0).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend(loc=4, fontsize=16)\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_bigravitycosmo.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .93, r'$\\Delta \\mathrm{BIC}(\\mathrm{bigravity}) = %1.0f$' % (BIC_bigravity(v.T[0],data_sets) - bic_lcdm), ha='right', va='top', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/Hubble_bigravity_' + Bsgn_string + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set B signs to load:\n",
    "B_signs = [1,1,-1]\n",
    "\n",
    "# Define probability with these signs:\n",
    "\n",
    "def lnprob_bigravity(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_bigravity_min, ranges_bigravity_max, model = 'bigravity', rd_num = rd_num, z_num = z_num, B_signs=B_signs)\n",
    "    return l.logprobability_gauss_prior()\n",
    "\n",
    "BIC_bigravity = lambda theta, data_sets_var: np.log(sum([len(d.get_data()) for d in data_sets_var])) * len(theta) -2*lnprob_bigravity(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all chains\n",
    "data_set_combinations = ['SN','SN_Q','SN_Q_BAO','SN_Q_BAO_CMB','BAO','CMB']\n",
    "data_set_names = ['SN','SN_Quasars','SN_Quasars_BAO','SN_Quasars_BAO_CMB','BAO','CMB']\n",
    "\n",
    "Bsgn_string = ''.join([str(sign) for sign in B_signs])\n",
    "\n",
    "labs = [r'$\\log_{10}('+ str(B_signs[0]).replace(\"1\",\"\") +'B_1)$', r'$\\log_{10}('+ str(B_signs[1]).replace(\"1\",\"\") +'B_2)$',r'$\\log_{10}('+ str(B_signs[2]).replace(\"1\",\"\") +'B_3)$',r'$\\Omega_m$', r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$\\alpha^\\prime$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']\n",
    "\n",
    "bigravity_chains = {}\n",
    "for i in range(0,len(data_set_combinations)):\n",
    "    bigravity_chains[data_set_combinations[i]] = HDFBackend('chains/bigravity_log10B_B' + Bsgn_string + '_' + str(data_set_names[i]) + '_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_combin_obs = {}\n",
    "data_set_combin_obs['SN'] = [SNdata]\n",
    "data_set_combin_obs['SN_Q'] = [SNdata,Qdata]\n",
    "data_set_combin_obs['SN_Q_BAO'] = [SNdata,Qdata,BAOdata]\n",
    "#data_set_combin_obs['SN_BAO_CMB'] = [SNdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['SN_Q_BAO_CMB'] = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['BAO'] = [BAOdata]\n",
    "data_set_combin_obs['CMB'] = [CMBdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of BICs calculated for LCDM\n",
    "bic_lcdmlist = np.load('LCDM_BIC.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of best fit paramters and calculate the Delta BIC of bigra with respect to LCDM\n",
    "\n",
    "printlist = []\n",
    "\n",
    "print('B signs: ', B_signs)\n",
    "\n",
    "for set_name in data_set_combinations:\n",
    "    sample = bigravity_chains[set_name].get_chain()\n",
    "    Nmin = 900\n",
    "    while Nmin < nsteps and np.all(bigravity_chains[set_name].get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "    dellist = np.unique(np.where(np.isclose(sample[-1] - sample[0], 0))[0])\n",
    "    sample = np.delete(sample, np.unique(dellist), axis=1)[Nmin:, :].reshape((-1, ndim))\n",
    "    \n",
    "    data_sets = data_set_combin_obs[set_name]\n",
    "    \n",
    "    vtemp = np.percentile(sample,[16, 50, 84], axis = 0)\n",
    "    vtemp = np.asarray([vtemp[1], vtemp[2]-vtemp[1],vtemp[1]-vtemp[0]]).T\n",
    "    print(set_name + ':')\n",
    "    print('   Om_m:    ' + str(np.round(vtemp[3],4)))\n",
    "    print('   Om_b:    ' + str(np.round(vtemp[4],4)*100))\n",
    "    print('   H0:      ' + str(np.round(vtemp[5],2)))\n",
    "    print('   log10B1: ' + str(np.round(vtemp[0],3)))\n",
    "    print('   log10B2: ' + str(np.round(vtemp[1],3)))\n",
    "    print('   log10B3: ' + str(np.round(vtemp[2],3)))\n",
    "    print('   dBIC:    ' + str(np.round(BIC_bigravity(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name])))\n",
    "    #print(vtemp.T[0])\n",
    "    \n",
    "    #prepare the list of best fit parameters for TeX-export:\n",
    "    printlist = np.append(printlist,\n",
    "                          np.array([[set_name,\n",
    "                                    convertValsToTeX(np.round(vtemp[3],4)),\n",
    "                                    #convertValsToTeX(np.round(vtemp[1],3)),\n",
    "                                    convertValsToTeX(np.round(vtemp[4]*100,2)),\n",
    "                                    convertValsToTeX(np.round(vtemp[5],2)),\n",
    "                                    convertValsToTeX(np.round(vtemp[0],3)),\n",
    "                                    convertValsToTeX(np.round(vtemp[1],3)),\n",
    "                                    convertValsToTeX(np.round(vtemp[2],3)),\n",
    "                                    convertValsToTeX(np.round(BIC_bigravity(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name]))]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportTab=np.array([printlist[0:8],printlist[8:16],printlist[16:24],printlist[24:32]]).T\n",
    "np.savetxt(u\"bigra_values_log10B_B\" + Bsgn_string +\".txt\", exportTab, fmt=u'%s' , delimiter=u\" & \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 900\n",
    "for sampler in bigravity_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print(\"Nmin = \", Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_plot = [(-10,10),(-10,10),(-10,10),(0.2,.4), (0.03,0.07), (64,73)]\n",
    "\n",
    "#samples = bigravity_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(bigravity_chains['SN'])),:].reshape((-1, bigravity_chains['SN'].get_chain().shape[-1]))\n",
    "#fig=corner(samples[:,4:7], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "#            labels=labs[4:7], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "#            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "#            range=[(0,1), (0.03,0.07), (60,73)])\n",
    "\n",
    "samples = bigravity_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(bigravity_chains['SN_Q'])),:].reshape((-1, bigravity_chains['SN_Q'].get_chain().shape[-1]))\n",
    "fig = corner(samples[:,0:6], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs[0:6], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='blue', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            range=range_plot)\n",
    "\n",
    "\n",
    "\n",
    "samples = bigravity_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(bigravity_chains['BAO'])),:].reshape((-1, bigravity_chains['BAO'].get_chain().shape[-1]))\n",
    "corner(samples[:,0:6], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs[0:7], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            fig=fig, range=range_plot)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "samples = bigravity_chains['CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(bigravity_chains['CMB'])),:].reshape((-1, bigravity_chains['CMB'].get_chain().shape[-1]))\n",
    "fig = corner(samples[:,:6], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "           labels=labs[:7], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange', \n",
    "           fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange'], alpha=0.4),\n",
    "           fig=fig,\n",
    "           range=range_plot)\n",
    "\n",
    "samples = bigravity_chains['SN_Q_BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(bigravity_chains['SN_Q_BAO_CMB'])),:].reshape((-1, bigravity_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,0:6], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs[0:7], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='black',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green'], alpha=0.4),\n",
    "            fig=fig, range=range_plot)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_bigravity_log10B_B' + Bsgn_string +'.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: kBigravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'kbigravity'\n",
    "CMBdata = CMB_data(model, 'Planck18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [SNdata, Qdata, BAOdata, CMBdata]\n",
    "#data_sets = [SNdata, Qdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_kbigravity_min=[-10,-10,-10, 0, 0, 0, 60, -5, -10, -30, -.5, 0, 0]\n",
    "ranges_kbigravity_max=[ 10, 10, 10, 1, 1.5, .1, 80, 5, 10, -10, .5, 10, 3]\n",
    "\n",
    "#Define the signs of the B parameters (needed because we sample log10(B))\n",
    "#B_signs = [+1, +1, +1]\n",
    "#B_signs = [+1, -1, +1]\n",
    "#B_signs = [+1, +1, -1]\n",
    "B_signs = [+1, -1, -1]\n",
    "\n",
    "Bsgn_string = ''.join([str(sign) for sign in B_signs])\n",
    "\n",
    "def lnprob_kbigravity(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_kbigravity_min, ranges_kbigravity_max, model = 'kbigravity', rd_num = rd_num, z_num = z_num, B_signs=B_signs)\n",
    "    return l.logprobability_gauss_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_kbigravity = lambda theta, data_sets_var: np.log(sum([len(d.get_data()) for d in data_sets_var])) * len(theta) -2*lnprob_kbigravity(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndim, nwalkers, nsteps = len(ranges_kbigravity_max), 512, 1000\n",
    "#pos0 = np.random.uniform(ranges_kbigravity_min, ranges_kbigravity_max, (nwalkers,len(ranges_kbigravity_max)))\n",
    "\n",
    "\n",
    "#pool = Pool(cpu_count())\n",
    "#write = HDFBackend('chains/kbigravity_' + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "#kbigravity_sampler = EnsembleSampler(nwalkers, ndim, lnprob_kbigravity, pool=pool)#, backend=write)\n",
    "\n",
    "#kbigravity_sampler.run_mcmc(pos0, nsteps, progress=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load chain corresponding to B_signs\n",
    "\n",
    "if B_signs == [+1, +1, +1]:\n",
    "    kbigravity_sampler = HDFBackend('chains/kbigravity_log10B_B111' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "    print('Chain log10B_B111 loaded')\n",
    "    \n",
    "elif B_signs == [+1, -1, +1]:\n",
    "    kbigravity_sampler = HDFBackend('chains/kbigravity_log10B_B1-11' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "    print('Chain log10B_B1-11 loaded')\n",
    "    \n",
    "elif B_signs == [+1, +1, -1]:\n",
    "    kbigravity_sampler = HDFBackend('chains/kbigravity_log10B_B11-1' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "    print('Chain log10B_B11-1 loaded')\n",
    "    \n",
    "elif B_signs == [+1, -1, -1]:\n",
    "    kbigravity_sampler = HDFBackend('chains/kbigravity_log10B_B1-1-1' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "    print('Chain log10B_B1-1-1 loaded')\n",
    "nsteps, nwalkers, ndim = kbigravity_sampler.get_chain().shape\n",
    "\n",
    "labs = [r'$\\log_{10}B_1$', r'$\\log_{10}B_2$',r'$\\log_{10}B_3$',r'$\\Omega_m$',  r'$\\Omega_\\Lambda$', r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$\\alpha^\\prime$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 900\n",
    "while Nmin < nsteps and np.all(kbigravity_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbigravity_samples = kbigravity_sampler.get_chain()\n",
    "\n",
    "dellist = np.unique(np.where(np.isclose(kbigravity_samples[-1] - kbigravity_samples[0], 0))[0])\n",
    "\n",
    "kbigravity_samples = np.delete(kbigravity_samples, np.unique(dellist), axis=1)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(len(kbigravity_samples.T), 1, figsize=(6,3*len(kbigravity_samples.T)))\n",
    "\n",
    "for i in range(len(kbigravity_samples.T)):\n",
    "    ax[i].plot(kbigravity_samples.T[i].T, lw=0.5)\n",
    "    ax[i].plot([Nmin, Nmin], [min(kbigravity_samples.T[i].flatten()), max(kbigravity_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "    ax[i].text(Nmin, min(kbigravity_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "Bsgn_string = ''.join([str(sign) for sign in B_signs])\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/convergence_kbigravity' + Bsgn_string + '.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 1$\\sigma$ and 2$\\sigma$ contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if this fails w/ error \"more dimensions than samples!\", replace Nmin by a lower number for testing\n",
    "#bigravity_samples = bigravity_samples[0:, :].reshape((-1, ndim))\n",
    "kbigravity_samples = kbigravity_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "meankbigravity = np.mean(kbigravity_samples, axis=0)\n",
    "stdkbigravity = np.var(kbigravity_samples, axis=0)\n",
    "maxkbigravity=[]\n",
    "for i in range(len(meankbigravity)):\n",
    "    like = np.histogram(kbigravity_samples.T[i], bins=1000)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxkbigravity.append(max_val)\n",
    "\n",
    "fig = corner(kbigravity_samples[:,:7], quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),# range=[(0,0.8),(0.01,0.08), (60,80)],\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=20, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "#              truths=maxLCDM)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('plots/posterior_kbigravity_log10B_B' + Bsgn_string + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(kbigravity_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "logB1, stdlB1p, stdlB1m = v[0]\n",
    "logB2, stdlB2p, stdlB2m = v[1]\n",
    "logB3, stdlB3p, stdlB3m = v[2]\n",
    "\n",
    "omegam, stdmp, stdmm = v[3]\n",
    "omegac, stdcp, stdcm = v[4]\n",
    "omegab, stdbp, stdbm = v[5]\n",
    "H0, stdhp, stdhm = v[6]\n",
    "\n",
    "\n",
    "\n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "best_fit_kbigravitycosmo = bigravity_cosmology(logB1, logB2, logB3, omegam, omegac, omegag=omega_gamma_preset, omegab=omegab, Hzero=H0, B_signs=B_signs)\n",
    "SNdata.set_param(v.T[0][-6:-2])\n",
    "Qdata.set_param(v.T[0][-2:])\n",
    "\n",
    "# Calculate physical graviton mass of best fit cosmology:\n",
    "mg = best_fit_kbigravitycosmo.graviton_mass(omegac)\n",
    "# Calculate error of physical graviton mass:\n",
    "delmg = best_fit_kbigravitycosmo.del_graviton_mass(omegac,stdhp,(stdlB1p+stdlB1m)/2,(stdlB2p+stdlB2m)/2,(stdlB3p+stdlB3m)/2)\n",
    "\n",
    "# Graviton mass in best fit bigravity:\n",
    "print(mg)\n",
    "print(delmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's show that kBigravity reproduces kLCDM at high-z using the best fit parameters:\n",
    "test_cosmo_kLCDM = cosmology(omegam, omegac, omegab=omegab, omegag=omega_gamma_preset, Hzero=H0)\n",
    "\n",
    "# plot y(z) for best fit\n",
    "z = np.arange(0.001, 1000.0, .01)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#ax.ticklabel_format(useOffset=False)\n",
    "\n",
    "ax.semilogx(z, best_fit_kbigravitycosmo.H(z)/test_cosmo_kLCDM.H(z))\n",
    "\n",
    "ax.set_title('$H(z)$ of $k$Bigravity / $H(z)$ of $k\\Lambda$CDM', fontsize=18, y=1.1)\n",
    "\n",
    "ax.set(xlabel='z')\n",
    "ax.set_xlim(0.001,1000)\n",
    "#ax.set_ylim(.984, 1.001,)\n",
    "plt.xticks((.001,.01,.1,1,10,100,1000))\n",
    "#plt.yticks(np.arange(.985, 1.001, .005))\n",
    "#ax.yaxis.set_major_formatter(FormatStrFormatter('%.10f'))\n",
    "#ax.yaxis.set_minor_formatter(FormatStrFormatter('%.10f'))\n",
    "ax.grid('--',which='major',axis='x', dashes=(5,5))\n",
    "ax.grid('--',which='both',axis='y', dashes=(5,5))\n",
    "\n",
    "#ax.grid('--', dashes=(5,5))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('plots/kbigra_' + Bsgn_string +'_best_fit_H_over_kLCDM.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot y(z) for best fit parameters\n",
    "z = np.arange(-1, 30, 0.01)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(z, best_fit_kbigravitycosmo.Bianchi(z))\n",
    "\n",
    "ax.set_title('kBigravity best fit cosmology', fontsize=18)\n",
    "\n",
    "ax.set(xlabel='z', ylabel='y(z)')\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('plots/kbigra_best_fit_y' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_kbi = BIC_kbigravity(v.T[0],data_sets)\n",
    "\n",
    "print('BIC(kBigravity) = ' + str(bic_kbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of BICs calculated for LCDM\n",
    "bic_lcdmlist = np.load('LCDM_BIC.npy').item()\n",
    "bic_lcdm = bic_lcdmlist['_'.join([name for name in data_set_names]).replace('Quasars','Q')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_kbi -bic_lcdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "\n",
    "if 'BAO'  in data_set_names or 'CMB' in data_set_names:    \n",
    "    ax1.set_title(r'$\\Omega_m = {%1.3f}^{+%1.3f}_{-%1.3f},\\, \\Omega_\\Lambda = {%1.3f}^{+%1.3f}_{-%1.3f},\\, H_0 =  {%1.1f}^{+%1.1f}_{-%1.1f}\\,\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}$' % (omegam, stdmp,stdmm, omegac, stdcp,stdcm, H0, stdhp,stdhm), fontsize=18)\n",
    "else:\n",
    "    ax1.set_title(r'$\\Omega_m = {%1.2f}^{+%1.2f}_{-%1.2f}\\,,\\Omega_\\Lambda = {%1.2f}^{+%1.2f}_{-%1.2f}$' % (omegam, stdmp,stdmm, omegac, stdcp,stdcm), fontsize=18)\n",
    "\n",
    "labelstr = '\\log_{10}('+ str(B_signs[0]).replace(\"1\",\"\") +'B_1,'+ str(B_signs[1]).replace(\"1\",\"\") +'B_2,'+ str(B_signs[2]).replace(\"1\",\"\") +'B_3)'\n",
    "ax1.text(0.5, 0.96, r'$'+labelstr+' = {%1.1f}^{+%1.1f}_{-%1.1f},  {%1.1f}^{+%1.1f}_{-%1.1f},  {%1.1f}^{+%1.1f}_{-%1.1f}$' % (logB1, stdlB1p, stdlB1m, logB2, stdlB2p, stdlB2m, logB3, stdlB3p, stdlB3m),\n",
    "         ha='center', va='top', fontsize=13, transform=ax1.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "         #,\\,m_g = ({%1.2f}\\pm {%1.2f}) \\\\times 10^{%1.0f} \\,\\mathrm{eV}\n",
    "         #, mg/(10**np.floor(np.log10(mg))),delmg/(10**np.floor(np.log10(mg))), np.floor(np.log10(mg))\n",
    "   \n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=-1, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=-1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(best_fit_kbigravitycosmo).T[0], BAOdata.distance_modulus(best_fit_kbigravitycosmo).T[1], yerr=BAOdata.delta_distance_modulus(best_fit_kbigravitycosmo), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=-1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_kbigravitycosmo.distance_modulus(zPlot), c='k', label=r'fit')\n",
    "ax1.fill_between(zPlot, bigravity_cosmology(logB1+stdlB1p, logB2+stdlB2p, logB3+stdlB3p, omegam + stdmp, omegac + stdcp, omegab=omegab+stdbp, Hzero=H0+stdhp, B_signs = B_signs).distance_modulus(zPlot), bigravity_cosmology(logB1+stdlB1m, logB2+stdlB2m, logB3+stdlB3m, omegam - stdmm, omegac - stdcm, omegab=omegab-stdbm, Hzero=H0-stdhm,B_signs = B_signs).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset, Hzero=H0).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "ax1.plot(zPlot, cosmology(omegam, omegac, Hzero=H0).distance_modulus(zPlot), ls = ':', c='lightgray', label=r'$\\Lambda\\mathrm{CDM}(\\Omega_m, \\Omega_\\Lambda)$')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend(loc=4, fontsize=16)\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_kbigravitycosmo.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .06, r'$\\Delta \\mathrm{BIC}(\\mathrm{kBigravity}) = %1.0f$' % (BIC_kbigravity(v.T[0],data_sets) - bic_lcdm), ha='right', va='bottom', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/Hubble_kbigravity' + Bsgn_string  + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set B signs to load:\n",
    "B_signs = [1,-1,1]\n",
    "\n",
    "# Define probability with these signs:\n",
    "\n",
    "def lnprob_kbigravity(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_kbigravity_min, ranges_kbigravity_max, model = 'kbigravity', rd_num = rd_num, z_num = z_num, B_signs=B_signs)\n",
    "    return l.logprobability_gauss_prior()\n",
    "\n",
    "BIC_kbigravity = lambda theta, data_sets_var: np.log(sum([len(d.get_data()) for d in data_sets_var])) * len(theta) -2*lnprob_kbigravity(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all chains\n",
    "data_set_combinations = ['SN','SN_Q','SN_Q_BAO','SN_Q_BAO_CMB','BAO','CMB']\n",
    "data_set_names = ['SN','SN_Quasars','SN_Quasars_BAO','SN_Quasars_BAO_CMB','BAO','CMB']\n",
    "\n",
    "Bsgn_string = ''.join([str(sign) for sign in B_signs])\n",
    "\n",
    "labs = [r'$\\log_{10}('+ str(B_signs[0]).replace(\"1\",\"\") +'B_1)$', r'$\\log_{10}('+ str(B_signs[1]).replace(\"1\",\"\") +'B_2)$',r'$\\log_{10}('+ str(B_signs[2]).replace(\"1\",\"\") +'B_3)$',r'$\\Omega_m$',  r'$\\Omega_\\Lambda$', r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$\\alpha^\\prime$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']\n",
    "\n",
    "kbigravity_chains = {}\n",
    "for i in range(0,len(data_set_combinations)):\n",
    "    kbigravity_chains[data_set_combinations[i]] = HDFBackend('chains/kbigravity_log10B_B' + Bsgn_string + '_' + str(data_set_names[i]) + '_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_combin_obs = {}\n",
    "data_set_combin_obs['SN'] = [SNdata]\n",
    "data_set_combin_obs['SN_Q'] = [SNdata,Qdata]\n",
    "data_set_combin_obs['SN_Q_BAO'] = [SNdata,Qdata,BAOdata]\n",
    "#data_set_combin_obs['SN_BAO_CMB'] = [SNdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['SN_Q_BAO_CMB'] = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "data_set_combin_obs['BAO'] = [BAOdata]\n",
    "data_set_combin_obs['CMB'] = [CMBdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of BICs calculated for LCDM\n",
    "bic_lcdmlist = np.load('LCDM_BIC.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of best fit paramters and calculate the Delta BIC of kbigra with respect to LCDM\n",
    "\n",
    "printlist = []\n",
    "\n",
    "print('B signs: ', B_signs)\n",
    "\n",
    "for set_name in data_set_combinations:\n",
    "    sample = kbigravity_chains[set_name].get_chain()\n",
    "    Nmin = 900\n",
    "    while Nmin < nsteps and np.all(kbigravity_chains[set_name].get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "    dellist = np.unique(np.where(np.isclose(sample[-1] - sample[0], 0))[0])\n",
    "    sample = np.delete(sample, np.unique(dellist), axis=1)[Nmin:, :].reshape((-1, ndim))\n",
    "    \n",
    "    data_sets = data_set_combin_obs[set_name]\n",
    "    \n",
    "    vtemp = np.percentile(sample,[16, 50, 84], axis = 0)\n",
    "    vtemp = np.asarray([vtemp[1], vtemp[2]-vtemp[1],vtemp[1]-vtemp[0]]).T\n",
    "    print(set_name + ':')\n",
    "    print('   Om_m:    ' + str(np.round(vtemp[3],4)))\n",
    "    print('   Om_c:    ' + str(np.round(vtemp[4],4)))\n",
    "    print('   Om_b:    ' + str(np.round(vtemp[5],4)*100))\n",
    "    print('   H0:      ' + str(np.round(vtemp[6],2)))\n",
    "    print('   log10B1: ' + str(np.round(vtemp[0],3)))\n",
    "    print('   log10B2: ' + str(np.round(vtemp[1],3)))\n",
    "    print('   log10B3: ' + str(np.round(vtemp[2],3)))\n",
    "    print('   dBIC:   ' + str(np.round(BIC_kbigravity(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name])))\n",
    "    #print(Nmin)\n",
    "    \n",
    "    #prepare the list of best fit parameters for TeX-export:\n",
    "    printlist = np.append(printlist,\n",
    "                          np.array([[set_name,\n",
    "                                    convertValsToTeX(np.round(vtemp[3],4)),\n",
    "                                    convertValsToTeX(np.round(vtemp[4],4)),\n",
    "                                    convertValsToTeX(np.round(vtemp[5]*100,2)),\n",
    "                                    convertValsToTeX(np.round(vtemp[6],2)),\n",
    "                                    convertValsToTeX(np.round(vtemp[0],3)),\n",
    "                                    convertValsToTeX(np.round(vtemp[1],3)),\n",
    "                                    convertValsToTeX(np.round(vtemp[2],3)),\n",
    "                                    convertValsToTeX(np.round(BIC_kbigravity(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name]))]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportTab=np.array([printlist[0:9],printlist[9:18],printlist[18:27],printlist[27:36]]).T\n",
    "np.savetxt(u\"kbigra_values_log10B_B\" + Bsgn_string +\".txt\", exportTab, fmt=u'%s' , delimiter=u\" & \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 900\n",
    "for sampler in kbigravity_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print(\"Nmin = \", Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_plot = [(-10,10),(-10,10),(-10,10),(0.2,.4), (0,1.25), (0.03,0.07), (64,73)]\n",
    "\n",
    "#samples = kbigravity_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kbigravity_chains['SN'])),:].reshape((-1, kbigravity_chains['SN'].get_chain().shape[-1]))\n",
    "#fig=corner(samples[:,4:8], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "#            labels=labs[4:8], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "#            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "#            range=[(0,1), (0,1.25), (0.03,0.07), (60,75)])\n",
    "\n",
    "samples = kbigravity_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kbigravity_chains['SN_Q'])),:].reshape((-1, kbigravity_chains['SN_Q'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:7], levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs[:8], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='blue', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            range=range_plot)\n",
    "\n",
    "samples = kbigravity_chains['CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kbigravity_chains['CMB'])),:].reshape((-1, kbigravity_chains['CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:7], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs[:8], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange'], alpha=0.4),\n",
    "            fig=fig, range=range_plot)\n",
    "\n",
    "samples = kbigravity_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kbigravity_chains['BAO'])),:].reshape((-1, kbigravity_chains['BAO'].get_chain().shape[-1]))\n",
    "fig=corner(samples[:,:7], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs[:8], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "            fig=fig, range=range_plot)\n",
    "\n",
    "samples = kbigravity_chains['SN_Q_BAO_CMB'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(kbigravity_chains['SN_Q_BAO_CMB'])),:].reshape((-1, kbigravity_chains['SN_Q_BAO_CMB'].get_chain().shape[-1]))\n",
    "corner(samples[:,:7], levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs[:8], smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='black', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            fig=fig, range=range_plot)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_kbigravity_log10B_B' + Bsgn_string +'.pdf')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: Conformal Gravity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which data sets to include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'conformal'\n",
    "CMBdata = CMB_data(model, 'Planck18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [SNdata,Qdata]\n",
    "#data_sets = [BAOdata]\n",
    "data_set_names = [set.name for set in data_sets]\n",
    "data_sets_str = '_' + '_'.join([name for name in data_set_names]) + '_' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges_conformal_min=[0, 0, 0, 60, -5, -10, -30, -.5, 0, 0]\n",
    "ranges_conformal_max=[10, 100, 0.1, 3000, 5, 10, -10, .5, 10, 3]\n",
    "def lnprob_conformal(theta):\n",
    "    l = likelihood(theta, data_sets, ranges_conformal_min, ranges_conformal_max, model = 'conformal', rd_num = False, z_num = False)\n",
    "    return l.logprobability_gauss_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a reference BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_conformal = lambda theta, data_sets_var: np.log(sum([len(d.get_data()) for d in data_sets_var])) * len(theta) -2*lnprob_conformal(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the MCMC sampler  [arXiv:1202.3665]..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, nsteps = len(ranges_conformal_min), 512, 1000\n",
    "pos0 = np.random.uniform(ranges_conformal_min, ranges_conformal_max, (nwalkers,len(ranges_conformal_max)))\n",
    "\n",
    "#pool = Pool(cpu_count())\n",
    "#write = HDFBackend('chains/conformal_' + str(nwalkers) + 'x' + str(nsteps) + '.h5')\n",
    "#sampler = EnsembleSampler(nwalkers, ndim, lnprob_conformal, pool=pool)#, backend=write)\n",
    "\n",
    "#sampler.run_mcmc(pos0, nsteps, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or load existing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_sampler = HDFBackend('chains/conformal' + data_sets_str + '512x1000.h5', read_only=True)\n",
    "#conformal_sampler  = sampler\n",
    "\n",
    "nsteps, nwalkers, ndim = conformal_sampler.get_chain().shape\n",
    "\n",
    "labs_k=[r'$\\Omega_k$', r'$(\\kappa/\\mathrm{Gpc}^{-2})$', r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$\\alpha^\\prime$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']\n",
    "labs=[r'$(\\gamma_0/\\mathrm{Gpc}^{-1})$', r'$(\\kappa/\\mathrm{Gpc}^{-2})$', r'$\\Omega_b$', r'$H_0\\ [\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}]$', r'$\\alpha^\\prime$', r'$\\beta$', r'$M_B$', r'$\\Delta M_B$', r'$\\beta^\\prime$', r'$\\delta$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and visualise the convergence: $\\tau_f / n_\\mathrm{steps} < 1/30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 700\n",
    "while Nmin < nsteps and np.all(conformal_sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "    Nmin+=100\n",
    "    \n",
    "print('Nmin = {}'.format(Nmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_samples = conformal_sampler.get_chain()\n",
    "\n",
    "#conformal_samples = conformal_samples[:,np.where(conformal_samples[0].T[0] < .5)[0],:]\n",
    "\n",
    "dellist = np.unique(np.where(np.isclose(conformal_samples[-1] - conformal_samples[0], 0))[0])\n",
    "\n",
    "conformal_samples = np.delete(conformal_samples, np.unique(dellist), axis=1)\n",
    "\n",
    "f, ax = plt.subplots(len(conformal_samples.T), 1, figsize=(6,3*len(conformal_samples.T)))\n",
    "\n",
    "for i in range(len(conformal_samples.T)):\n",
    "    ax[i].plot(conformal_samples.T[i].T, lw=0.5)\n",
    "    ax[i].plot([Nmin, Nmin], [min(conformal_samples.T[i].flatten()), max(conformal_samples.T[i].flatten())], c='k', lw=1.5)\n",
    "    ax[i].text(Nmin, min(conformal_samples.T[i].flatten()), r'$n_\\mathrm{min}$', rotation=90, ha='right')\n",
    "    ax[i].set_ylabel(labs[i])\n",
    "    ax[i].set_xlabel('iteration')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/convergence_conformal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_samples = conformal_samples[Nmin:, :].reshape((-1, ndim))\n",
    "\n",
    "meanconformal = np.mean(conformal_samples, axis=0)\n",
    "stdconformal = np.var(conformal_samples, axis=0)\n",
    "maxconformal=[]\n",
    "for i in range(len(meanconformal)):\n",
    "    like = np.histogram(conformal_samples.T[i], bins=50)\n",
    "    i_max=np.argmax(like[0])\n",
    "    max_val = (like[1][i_max]+like[1][i_max+1])/2\n",
    "    maxconformal.append(max_val)\n",
    "\n",
    "    \n",
    "# conformal_samples.T[0] = (conformal_samples.T[0])**2 / 2 * cLight**2/(70./1E-3)**2\n",
    "fig = corner(conformal_samples, quantiles=(.16,.84),  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "             labels=labs, smooth=True, smooth1d=True, bins=20, plot_datapoints=False, fill_contours=True, contourf_kwargs=dict(colors=None, cmap='Greens'))#,\n",
    "# #              truths=maxconformal)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('plots/posterior_conformal' + data_sets_str[:-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.percentile(conformal_samples,[16, 50, 84], axis = 0)\n",
    "v = np.asarray([v[1], v[2]-v[1],v[1]-v[0]]).T\n",
    "\n",
    "gamma0, gamm0p, gamma0m = v[0]\n",
    "kappa, kappap, kappam = v[1]\n",
    "\n",
    "omegak = (gamma0)**2 / 2 * cosmology.cLight**2/(70./1E-3)**2\n",
    "stdkp, stdkm = np.array([gamm0p, gamma0m]) * (gamma0) * cosmology.cLight**2/(70./1E-3)**2#Gpc^-1\n",
    "\n",
    "\n",
    "omegab, stdbp, stdbm = v[2]\n",
    "H0, stdhp, stdhm = v[3]\n",
    "\n",
    "omegac = 1 - omegak\n",
    "stdcp = stdkm\n",
    "stdcm = stdkp\n",
    "#model\n",
    "z = SNdata.get_data().T[0]\n",
    "\n",
    "best_fit_conformalcosmo = cosmology(0, omegac, omegab=omegab, omegag=omega_gamma_preset, Hzero=H0)\n",
    "SNdata.set_param(v.T[0][-6:-2])\n",
    "Qdata.set_param(v.T[0][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=cosmology(omegam=.36,omegac=.8,omegab=0.0468,omegag=omega_gamma_preset,Hzero=68.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.com_sound_horizon(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit_cosmo_LCDM.com_sound_horizon(1089)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit_conformalcosmo.com_sound_horizon(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_CG = BIC_conformal(v.T[0],data_sets)\n",
    "\n",
    "print('BIC(CG) = ' + str(bic_CG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = sum([len(galaxy) for galaxy in RCdata.get_data()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_conformal(v.T[0],data_sets) - 141759 + n*np.log(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_CG-bic_lcdmlist['SN_Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(hspace=0)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0:2, 0])\n",
    "\n",
    "if 'RC' in data_set_names:\n",
    "    ax1.set_title(r'$\\Omega_\\Lambda = {%1.3f}^{+%1.3f}_{-%1.3f},\\, 1000\\,\\Omega_k = {%1.3f}^{+%1.3f}_{-%1.3f},\\, H_0 =  {%1.1f}^{+%1.1f}_{-%1.1f}\\,\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}$' % (omegac, stdcp,stdcm, 1000*omegak, 1000*stdkm, 1000*stdkp, H0, stdhp, stdhm), fontsize=18)\n",
    "else:\n",
    "    ax1.set_title(r'$\\Omega_\\Lambda = {%1.3f}^{+%1.3f}_{-%1.3f},\\, \\Omega_k = {%1.3f}^{+%1.3f}_{-%1.3f},\\, H_0 =  {%1.1f}^{+%1.1f}_{-%1.1f}\\,\\frac{\\mathrm{km}/s}{\\mathrm{Mpc}}$' % (omegac, stdcp,stdcm, omegak, stdkm, stdkp, H0, stdhp, stdhm), fontsize=18)\n",
    "\n",
    "if 'Quasars' in data_set_names:\n",
    "    ax1.errorbar(Qdata.distance_modulus().T[0], Qdata.distance_modulus().T[1], yerr=Qdata.delta_distance_modulus(), linestyle='none', marker='o', color='orange', ecolor='yellow', markersize=3, alpha=0.6, zorder=-1, label=r'quasars')\n",
    "if 'SN' in data_set_names:\n",
    "    ax1.errorbar(SNdata.distance_modulus().T[0], SNdata.distance_modulus().T[1], yerr=SNdata.delta_distance_modulus(), linestyle='none', marker='o', color='cyan', ecolor='blue', markersize=3, alpha=0.6, zorder=-1, label=r'SNe')\n",
    "if 'BAO' in data_set_names:\n",
    "    ax1.errorbar(BAOdata.distance_modulus(best_fit_conformalcosmo).T[0], BAOdata.distance_modulus(best_fit_conformalcosmo).T[1], yerr=BAOdata.delta_distance_modulus(best_fit_conformalcosmo), linestyle='none', marker='o', color='red', ecolor='black', markersize=3, alpha=0.6, zorder=1, label=r'BAO')\n",
    "\n",
    "\n",
    "\n",
    "zPlot = np.logspace(-3,np.log10(6),100)\n",
    "ax1.plot(zPlot, best_fit_conformalcosmo.distance_modulus(zPlot), c='k', label=r'best fit')\n",
    "ax1.fill_between(zPlot, cosmology(0,omegac+stdcp, omegab=omegab+stdbp, Hzero=H0 + stdhp).distance_modulus(zPlot), cosmology(0,omegac-stdcm, omegab=omegab-stdbm, Hzero=H0 - stdhm).distance_modulus(zPlot), color='gray', alpha=0.3)\n",
    "ax1.plot(zPlot, cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), ls = '--', c='gray', label=r'$\\Lambda$CDM')\n",
    "\n",
    "ax1.set_xlim(0.01,6)\n",
    "ax1.set_ylim(32,55)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(r'distance modulus $\\mu$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.grid('--', dashes=(5,5))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(gs[2, 0])\n",
    "\n",
    "ax2.plot(zPlot, best_fit_conformalcosmo.distance_modulus(zPlot) - cosmology(Omega_m_preset, Omega_c_preset).distance_modulus(zPlot), 'k')\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "ax2.set_xlim(0.01,6)\n",
    "\n",
    "ax2.text(0.97, .06, r'$\\Delta\\mathrm{BIC}(\\mathrm{CG}) = %1.0f$' % (BIC_conformal(v.T[0],data_sets) - bic_lcdmlist['SN_Q']), ha='right', va='bottom', transform=ax2.transAxes, bbox=dict(facecolor=(1,1,1,.8), edgecolor='lightgray', boxstyle='round'))\n",
    "\n",
    "\n",
    "ax2.grid('--', dashes=(5,5))\n",
    "ax2.set_xlabel(r'$z$')\n",
    "ax2.set_ylabel(r'$\\mu_\\mathrm{fit} - \\mu_{\\Lambda\\mathrm{CDM}}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/Hubble_conformal' + data_sets_str[:-1] + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fit of all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_chains = {}\n",
    "conformal_chains['SN'] = HDFBackend('chains/conformal_SN_512x1000.h5')\n",
    "conformal_chains['SN_Q'] = HDFBackend('chains/conformal_SN_Quasars_512x1000.h5')\n",
    "#conformal_chains['BAO'] = HDFBackend('chains/conformal_BAO_512x1000.h5')\n",
    "# conformal_chains['CMB'] = HDFBackend('chains/conformal_CMB_512x1000.h5')\n",
    "#conformal_chains['SN_Q_BAO'] = HDFBackend('chains/conformal_SN_Quasars_BAO_512x1000.h5')\n",
    "#conformal_chains['RC'] = HDFBackend('chains/conformal_RC_512x1000.h5')\n",
    "#conformal_chains['SN_RC'] = HDFBackend('chains/conformal_RC_SN_512x1000.h5')\n",
    "#conformal_chains['SN_Q_RC'] = HDFBackend('chains/conformal_RC_SN_Quasars_512x1000.h5')\n",
    "#conformal_chains['SN_Q_BAO_RC'] = HDFBackend('chains/conformal_RC_SN_Quasars_BAO_512x1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_combinations = ['SN','SN_Q','SN_Q_BAO']\n",
    "data_set_combin_obs = {}\n",
    "data_set_combin_obs['SN'] = [SNdata]\n",
    "data_set_combin_obs['SN_Q'] = [SNdata,Qdata]\n",
    "#data_set_combin_obs['SN_Q_BAO'] = [SNdata,Qdata,BAOdata]\n",
    "#data_set_combin_obs['SN_BAO_CMB'] = [SNdata,BAOdata,CMBdata]\n",
    "#data_set_combin_obs['SN_Q_BAO_CMB'] = [SNdata,Qdata,BAOdata,CMBdata]\n",
    "#data_set_combin_obs['BAO'] = [BAOdata]\n",
    "#data_set_combin_obs['CMB'] = [CMBdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of best fit paramters and calculate the Delta BIC of kLCDM with respect to LCDM\n",
    "\n",
    "printlist = []\n",
    "\n",
    "for set_name in data_set_combinations:\n",
    "    sample = conformal_chains[set_name].get_chain()\n",
    "    Nmin = 900\n",
    "    while Nmin < nsteps and np.all(conformal_chains[set_name].get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "    dellist = np.unique(np.where(np.isclose(sample[-1] - sample[0], 0))[0])\n",
    "    sample = np.delete(sample, np.unique(dellist), axis=1)[Nmin:, :].reshape((-1, ndim))\n",
    "    \n",
    "    data_sets = data_set_combin_obs[set_name]\n",
    "    \n",
    "    vtemp = np.percentile(sample,[16, 50, 84], axis = 0)\n",
    "    vtemp = np.asarray([vtemp[1], vtemp[2]-vtemp[1],vtemp[1]-vtemp[0]]).T\n",
    "    \n",
    "    gamma0, gamm0p, gamma0m = vtemp[0]\n",
    "\n",
    "    omegak = (gamma0)**2 / 2 * cosmology.cLight**2/(70./1E-3)**2\n",
    "    stdkp, stdkm = np.array([gamm0p, gamma0m]) * (gamma0) * cosmology.cLight**2/(70./1E-3)**2#Gpc^-1\n",
    "\n",
    "    print(set_name + ':')\n",
    "    print('   Om_k:   ' + str(np.round([omegak,stdkp,stdkm],4)))\n",
    "    print('   Om_b:   ' + str(np.round(vtemp[2],4)*100))\n",
    "    print('   kappa:  ' + str(np.round(vtemp[1],4)))\n",
    "    print('   H0:     ' + str(np.round(vtemp[3],1)))\n",
    "    print('   dBIC:   ' + str(np.round(BIC_conformal(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name])))\n",
    "    #print(vtemp.T[0])\n",
    "    \n",
    "    #prepare the list of best fit parameters for TeX-export:\n",
    "    printlist = np.append(printlist,\n",
    "                          np.array([[set_name,\n",
    "                                    convertValsToTeX(np.round(np.array([omegak,stdkp,stdkm]),4)),\n",
    "                                    #convertValsToTeX(np.round(vtemp[1],3)),\n",
    "                                    convertValsToTeX(np.round(vtemp[2]*100,2)),\n",
    "                                    convertValsToTeX(np.round(vtemp[1],4)),\n",
    "                                    convertValsToTeX(np.round(vtemp[3],1)),\n",
    "                                    convertValsToTeX(np.round(BIC_conformal(vtemp.T[0], data_set_combin_obs[set_name])-bic_lcdmlist[set_name]))]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportTab=np.array([printlist[0:6],printlist[6:12],printlist[12:18],printlist[18:24]]).T\n",
    "np.savetxt(u\"conformal_values.txt\", exportTab, fmt=u'%s' , delimiter=u\" & \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmin = 700\n",
    "for sampler in conformal_chains.values():\n",
    "    nsteps, nwalkers, ndim = sampler.get_chain().shape\n",
    "    while Nmin < nsteps and np.all(sampler.get_autocorr_time(tol=0,discard=Nmin)/(nsteps)*30 > 1):\n",
    "        Nmin+=100\n",
    "print('Nmin=',Nmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Rot curves -> exclude $\\kappa$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_range = [(.5,1.0), (0, .1), (60,84)]\n",
    "\n",
    "samples = conformal_chains['SN'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(conformal_chains['SN'])),:].reshape((-1, conformal_chains['SN'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples.T[0] = (samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2\n",
    "samples = np.array([samples.T[i] for i in (0,2,3)]).T\n",
    "fig=corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=np.delete(labs_k, 1), smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "            range=plot_range)\n",
    "\n",
    "\n",
    "\n",
    "samples = conformal_chains['SN_Q'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(conformal_chains['SN_Q'])),:].reshape((-1, conformal_chains['SN_Q'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples.T[0] = (samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2\n",
    "samples = np.array([samples.T[i] for i in (0,2,3)]).T\n",
    "corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)), color='blue',\n",
    "            labels=np.delete(labs_k, 1), smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            fig=fig,range=plot_range)\n",
    "\n",
    "\n",
    "#samples = conformal_chains['BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(conformal_chains['BAO'])),:].reshape((-1, conformal_chains['BAO'].get_chain().shape[-1]))\n",
    "#samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "#samples.T[0] = (samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2\n",
    "#samples = np.array([samples.T[i] for i in (0,2,3)]).T\n",
    "#fig=corner(samples, levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#            labels=np.delete(labs_k, 1), smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='red', \n",
    "#            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.4),\n",
    "#            fig=fig, range=plot_range)\n",
    "\n",
    "\n",
    "# samples = conformal_chains['CMB'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['CMB'].get_chain().shape[-1]))\n",
    "# samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "# samples = np.array([samples.T[i] for i in (0,2,3)]).T\n",
    "# corner(samples, levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#             labels=np.delete(labs_k, 1), smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange', \n",
    "#             fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange'], alpha=0.4),\n",
    "#             fig=fig)#, range=[(0,1), (50,300), (0, .1), (62,75)])\n",
    "\n",
    "#samples = conformal_chains['SN_Q_BAO'].get_chain()[Nmin:,np.delete(range(nwalkers), calcdellist(conformal_chains['SN_Q_BAO'])),:].reshape((-1, conformal_chains['SN_Q_BAO'].get_chain().shape[-1]))\n",
    "#samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "#samples.T[0] = (samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2\n",
    "#samples = np.array([samples.T[i] for i in (0,2,3)]).T\n",
    "#corner(samples, levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "#            labels=np.delete(labs_k, 1), smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='cyan', \n",
    "#            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "#            fig=fig, range=plot_range)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_conformal.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Rot curves -> include $\\kappa$ :\n",
    "Because CG is already severely restricted without RC, we do not eveninclude this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_k[0] = r'$\\log_{10}(\\Omega_k)$'\n",
    "\n",
    "samples = conformal_chains['SN_Q_BAO'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['SN_Q_BAO'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples = np.array([samples.T[i] for i in (0,1)]).T\n",
    "samples.T[0] = np.log10((samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2)\n",
    "fig=corner(samples, levels=(1-np.exp(-0.5*1),1-np.exp(-0.5*4)),\n",
    "            labels=labs_k, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='cyan', \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'cyan'], alpha=0.4),\n",
    "            range=[(-3,0), (50,250)])\n",
    "\n",
    "samples = conformal_chains['RC'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['RC'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples = np.array([samples.T[i] for i in (0,1)]).T\n",
    "samples.T[0] = np.log10((samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2)\n",
    "corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs_k, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='orange',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'yellow', 'orange']),\n",
    "            fig=fig, range=[(-3,0), (50,250)])\n",
    "\n",
    "\n",
    "samples = conformal_chains['SN_RC'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['SN_RC'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples = np.array([samples.T[i] for i in (0,1)]).T\n",
    "samples.T[0] = np.log10((samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2)\n",
    "corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)),\n",
    "            labels=labs_k, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, color='green',\n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightgreen', 'green']),\n",
    "            fig=fig, range=[(-3,0), (50,250)])\n",
    "\n",
    "samples = conformal_chains['SN_Q_RC'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['SN_Q_RC'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples = np.array([samples.T[i] for i in (0,1)]).T\n",
    "samples.T[0] = np.log10((samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2)\n",
    "corner(samples,  levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)), color='blue',\n",
    "            labels=labs_k, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'lightblue', 'blue'], alpha=0.6),\n",
    "            fig=fig, range=[(-3,0), (50,250)])\n",
    "\n",
    "samples = conformal_chains['SN_Q_BAO_RC'].get_chain()[Nmin:,:].reshape((-1, conformal_chains['SN_Q_BAO_RC'].get_chain().shape[-1]))\n",
    "samples = samples[np.where(samples.T[0] < .33)[0]]\n",
    "samples = np.array([samples.T[i] for i in (0,1)]).T\n",
    "samples.T[0] = np.log10((samples.T[0])**2 / 2 * cLight**2/(H0/1E-3)**2)\n",
    "corner(samples, levels=(1-np.exp(-0.5),1-np.exp(-0.5*4)), color='red',\n",
    "            labels=labs_k, smooth=True, smooth1d=True, bins=25, plot_datapoints=False, \n",
    "            fill_contours=True, contourf_kwargs=dict(colors=['white', 'pink', 'red'], alpha=0.6),\n",
    "            fig=fig, range=[(-3,0), (50,250)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/posterior_conformal_RC.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma0, kappa = v[0:2,0]\n",
    "print(gamma0, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GN =  4.301E3 #GN * 10^9 Msol / 1kpc in (km/s)^2\n",
    "\n",
    "def vhalo_square(r, Ms, rs): # units of 1E9 Msol\n",
    "    return GN * Ms * (np.log(1+r/rs) - r/(r+rs))/r\n",
    "\n",
    "def vCG_square(r, gamma0=gamma0, kappa=kappa): # units of 1E9 Msol\n",
    "    r = r / 1E6 #Gpc\n",
    "    return cLight**2 * gamma0 * r / 2 - kappa * cLight**2 * r**2\n",
    "\n",
    "def vlocal_square (r, r0, M0, gamma):\n",
    "        return GN * M0 * (r/r0)**2 * (i0(r/2/r0) * k0(r/2/r0) - i1(r/2/r0) * k1(r/2/r0)) + gamma * (r/r0)**2 * i1(r/2/r0) * k1(r/2/r0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(int(np.ceil(len(RCdata.get_data())/5)),5, figsize=(12,2.5*len(RCdata.get_data())/5))\n",
    "# f, ax = plt.subplots(1,5, figsize=(15,4))\n",
    "\n",
    "ax = ax.flatten()\n",
    "\n",
    "pDMList=[]\n",
    "chiDM=[]\n",
    "pCGList=[]\n",
    "chiCG=[]\n",
    "\n",
    "galaxies = RCdata.get_data()\n",
    "names = RCdata.get_names()\n",
    "\n",
    "for i in range(len(galaxies)):\n",
    "    visible = lambda r, YD, YB: interp1d(galaxies[i][:,0], galaxies[i][:,3]**2 + YD*galaxies[i][:,4]**2 + YB*galaxies[i][:,5]**2, kind='cubic')(r)\n",
    "    fitf_DM =  lambda r, YD, YB, Ms, rs,: visible(r, YD, YB) + vhalo_square(r, Ms,rs) \n",
    "    pDM, _ = curve_fit(fitf_DM, galaxies[i][:,0], galaxies[i][:,1]**2, sigma=galaxies[i][:,2]**2, p0=[1,1, 5, 2*max(galaxies[i][:,0])], bounds = ([.1,.1,0,1], [5,5,250,10*max(galaxies[i][:,0])]))\n",
    "    \n",
    "    \n",
    "    pGas, _ = curve_fit(vlocal_square,  galaxies[i][:,0], galaxies[i][:,3]**2, p0=[1,10,1], bounds=(0, 500))\n",
    "    pDisk, _ = curve_fit(vlocal_square,  galaxies[i][:,0], galaxies[i][:,4]**2, p0=[1,10,1], bounds=(0, 500))\n",
    "    visibleCG = lambda r, YD, YB: vlocal_square(r, *pGas) + YD * vlocal_square(r, *pDisk) + YD * interp1d(galaxies[i][:,0], galaxies[i][:,5]**2, kind='cubic')(r)\n",
    "    fitf_CG = lambda r, YD, YB: visibleCG(r, YD, YB) + vCG_square(r) \n",
    "    pCG, _ = curve_fit(fitf_CG, galaxies[i][:,0], galaxies[i][:,1]**2, sigma=galaxies[i][:,2]**2, p0=[1, 1])#, bounds = ([0.1,.1,0,0], [5,5,10,10]))\n",
    "\n",
    "    pDMList.append(pDM)\n",
    "    pCGList.append(pCG)\n",
    "    chiDM.append(np.sum( (galaxies[i][:,1] - fitf_DM(galaxies[i][:,0],*pDM)**.5)**2 / galaxies[i][:,2]**2))\n",
    "    chiCG.append(np.sum( (galaxies[i][:,1] - fitf_CG(galaxies[i][:,0],*pCG)**.5)**2 / galaxies[i][:,2]**2))\n",
    "    \n",
    "    \n",
    "    ax[i].set_title(names[i])\n",
    "    ax[i].set_xlabel(r'$r\\ [\\mathrm{kpc}]$')\n",
    "    ax[i].set_ylabel(r'$v\\ [\\mathrm{km}/ \\mathrm{s}]$')\n",
    "    ax[i].plot(galaxies[i][:,0], galaxies[i][:,3], c='lightgreen', lw=0.6, label='gas')\n",
    "    ax[i].plot(galaxies[i][:,0], np.sqrt(pDM[0])*galaxies[i][:,4], c='blue', lw=0.6, label='disk')\n",
    "    ax[i].plot(galaxies[i][:,0], np.sqrt(pDM[1])*galaxies[i][:,5], c='m', lw=0.6, label='bulge')\n",
    "    ax[i].plot(galaxies[i][:,0], vhalo_square(galaxies[i][:,0], *pDM[2:])**.5, c='maroon', ls=':') \n",
    "    ax[i].plot(galaxies[i][:,0], vCG_square(galaxies[i][:,0])**.5, c='y', ls='-.') \n",
    "    ax[i].plot(galaxies[i][:,0], np.sqrt(galaxies[i][:,3]**2 + pDM[0]*galaxies[i][:,4]**2 + pDM[1]*galaxies[i][:,5]**2 + vhalo_square(galaxies[i][:,0], *pDM[2:])), c='r')\n",
    "    ax[i].plot(galaxies[i][:,0], np.sqrt(galaxies[i][:,3]**2 +  pCG[0]*galaxies[i][:,4]**2 +  pCG[1]*galaxies[i][:,5]**2+ vCG_square(galaxies[i][:,0], *pCG[2:])), c='orange')\n",
    "    ax[i].errorbar(galaxies[i][:,0], galaxies[i][:,1], yerr=galaxies[i][:,2], c='k', fmt='o', markersize=3)\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/SPARC_DM.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_CG_RT = np.sum(np.array(chiCG)[~np.isnan(chiCG)])\n",
    "# bic_CG_RT += (3*n + 2)*np.log(n)\n",
    "bic_CG_RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_lcdm_RT =  np.sum(np.array(chiDM)[~np.isnan(chiCG)])\n",
    "# bic_lcdm_RT += 4*n*np.log(n)\n",
    "bic_lcdm_RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bic_CG_RT - bic_lcdm_RT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
